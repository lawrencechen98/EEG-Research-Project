{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EEG_RNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "YqVsLqb9be_E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "HRfj3sKybvwH",
        "colab_type": "code",
        "outputId": "67169eef-e290-4b40-c2c9-087898058bdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "# authenticate with Google Drive to load data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "86zyzQwUdBW9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QPG86KYabyoe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "drive_service = build('drive', 'v3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gomTQobbbe_G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "data_dir = 'gdrive/My Drive/EEG_Project/'\n",
        "X_test = np.load(data_dir + \"X_test.npy\")\n",
        "y_test = np.load(data_dir + \"y_test.npy\")\n",
        "person_train_valid = np.load(data_dir + \"person_train_valid.npy\")\n",
        "X_train_valid = np.load(data_dir + \"X_train_valid.npy\")\n",
        "y_train_valid = np.load(data_dir + \"y_train_valid.npy\")\n",
        "person_test = np.load(data_dir + \"person_test.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BvwOl-zFbe_J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Ignore EOG data from last 3 of 25 electrodes\n",
        "# Transpose data so that the second dimension is timesteps\n",
        "X_test = X_test[:, :-3, :]\n",
        "X_test = X_test.transpose([0, 2, 1])\n",
        "X_train_valid = X_train_valid[:, :-3, :]\n",
        "X_train_valid = X_train_valid.transpose([0, 2, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K8KBmk6Nbe_M",
        "colab_type": "code",
        "outputId": "a25d7859-3767-422a-f896-e42887861e49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
        "print ('Test data shape: {}'.format(X_test.shape))\n",
        "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
        "print ('Test target shape: {}'.format(y_test.shape))\n",
        "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
        "print ('Person test shape: {}'.format(person_test.shape))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training/Valid data shape: (2115, 1000, 22)\n",
            "Test data shape: (443, 1000, 22)\n",
            "Training/Valid target shape: (2115,)\n",
            "Test target shape: (443,)\n",
            "Person train/valid shape: (2115, 1)\n",
            "Person test shape: (443, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J-Pvtunhbe_R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t6b_1B5Zw9R_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "scaler = preprocessing.StandardScaler()\n",
        "\n",
        "X_reshaped = np.reshape(X_train_valid, (X_train_valid.shape[0]*X_train_valid.shape[1], X_train_valid.shape[2]))\n",
        "scaler.fit(X_reshaped)\n",
        "\n",
        "X_reshaped = scaler.transform(X_reshaped)\n",
        "X_train_valid = np.reshape(X_reshaped, (X_train_valid.shape[0], X_train_valid.shape[1], X_train_valid.shape[2]))\n",
        "\n",
        "X_test_reshaped = np.reshape(X_test, (X_test.shape[0]*X_test.shape[1], X_test.shape[2]))\n",
        "X_test_reshaped = scaler.transform(X_test_reshaped)\n",
        "X_test = np.reshape(X_test_reshaped, (X_test.shape[0], X_test.shape[1], X_test.shape[2]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0T84aOZaQmnx",
        "colab_type": "code",
        "outputId": "048f921b-3dee-4e1c-93d9-b9b4e7197db1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(X_test[3, :, 14])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff071e780b8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAD4CAYAAAAjKGdbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njQbE/wcSZ9wBdnCBxwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "geKxpquFZ5B7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Create Training/Validation Dataset, with Subsampling and Resampling "
      ]
    },
    {
      "metadata": {
        "id": "JTkUEeZpbe_U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HC6qHQzmbe_Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Turn labels into categories, i.e. y values of 0-3\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(y_train_valid)\n",
        "y_train_valid_classes = le.transform(y_train_valid)\n",
        "y_test_classes = le.transform(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MyFJ6n56be_c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rand_idx = np.random.permutation(X_train_valid.shape[0])\n",
        "split = int(X_train_valid.shape[0] * 0.80)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s_m3uW9sbe_g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create randomized train and validation dataset split\n",
        "X_train = X_train_valid[rand_idx][:split]\n",
        "y_train = y_train_valid_classes[rand_idx][:split]\n",
        "person_train = person_train_valid[rand_idx][:split]\n",
        "\n",
        "X_valid = X_train_valid[rand_idx][split:]\n",
        "y_valid = y_train_valid_classes[rand_idx][split:]\n",
        "person_valid = person_train_valid[rand_idx][split:]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iFvU--qoV6Wy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Downsample and resample data\n",
        "from scipy import signal\n",
        "\n",
        "X_train_downsampled = np.concatenate((X_train[:, 0::10, :], X_train[:, 1::10, :], X_train[:, 2::10, :], X_train[:, 3::10, :], X_train[:, 4::10, :], X_train[:, 5::10, :], X_train[:, 6::10, :], X_train[:, 7::10, :], X_train[:, 8::10, :], X_train[:, 9::10, :]))\n",
        "X_train_processed = signal.resample(X_train_downsampled, 40, axis=1)\n",
        "y_train_processed = np.concatenate((y_train, y_train, y_train, y_train, y_train, y_train, y_train, y_train, y_train, y_train))\n",
        "person_train_processed = np.concatenate((person_train, person_train, person_train, person_train, person_train, person_train, person_train, person_train, person_train, person_train))\n",
        "\n",
        "X_valid_downsampled = np.concatenate((X_valid[:, 0::10, :], X_valid[:, 1::10, :], X_valid[:, 2::10, :], X_valid[:, 3::10, :], X_valid[:, 4::10, :], X_valid[:, 5::10, :], X_valid[:, 6::10, :], X_valid[:, 7::10, :], X_valid[:, 8::10, :], X_valid[:, 9::10, :]))\n",
        "X_valid_processed = signal.resample(X_valid_downsampled, 40, axis=1)\n",
        "y_valid_processed = np.concatenate((y_valid, y_valid, y_valid, y_valid, y_valid, y_valid, y_valid, y_valid, y_valid, y_valid))\n",
        "person_valid_processed = np.concatenate((person_valid, person_valid, person_valid, person_valid, person_valid, person_valid, person_valid, person_valid, person_valid, person_valid))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "moUzLlZ478Y0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a35f123-a221-4c93-dafc-6f47f6fa2748"
      },
      "cell_type": "code",
      "source": [
        "# Do the same for test set\n",
        "X_test_downsampled = np.concatenate((X_test[:, 0::10, :], X_test[:, 1::10, :], X_test[:, 2::10, :], X_test[:, 3::10, :], X_test[:, 4::10, :], X_test[:, 5::10, :], X_test[:, 6::10, :], X_test[:, 7::10, :], X_test[:, 8::10, :], X_test[:, 9::10, :]))\n",
        "X_test_processed = signal.resample(X_test_downsampled, 40, axis=1)\n",
        "y_test_processed = np.concatenate((y_test_classes, y_test_classes, y_test_classes, y_test_classes, y_test_classes, y_test_classes, y_test_classes, y_test_classes, y_test_classes, y_test_classes))\n",
        "person_test_processed = np.concatenate((person_test, person_test, person_test, person_test, person_test, person_test, person_test, person_test, person_test, person_test))\n",
        "\n",
        "X_test_processed.shape"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4430, 40, 22)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "metadata": {
        "id": "7K61u78-XPWL",
        "colab_type": "code",
        "outputId": "0d19a94e-9bb9-453c-8a18-07f43509c986",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "num_trials = X_train_processed.shape[0]\n",
        "num_timesteps = X_train_processed.shape[1]\n",
        "num_features = X_train_processed.shape[2]\n",
        "\n",
        "print(X_train_processed.shape)\n",
        "print(y_train_processed.shape)\n",
        "print(X_valid_processed.shape)\n",
        "print(y_valid_processed.shape)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16920, 40, 22)\n",
            "(16920,)\n",
            "(4230, 40, 22)\n",
            "(4230,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OTzZkk9svvzO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "063fa411-3e3b-4332-91eb-5dfaa59d3f48"
      },
      "cell_type": "code",
      "source": [
        "plt.plot(X_train_processed[0, :, 1])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff06e7333c8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD4CAYAAADmWv3KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndn0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "fDfDo3draFK6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Build RNN Model (With Keras)"
      ]
    },
    {
      "metadata": {
        "id": "e-f1FXAQbe_j",
        "colab_type": "code",
        "outputId": "54e4a166-547b-47e6-8385-5353747dde60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout, Activation\n",
        "from keras import optimizers\n",
        "from keras import regularizers\n",
        "from keras.layers.normalization import BatchNormalization"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "42sIegvvbe_l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "checkpoint_path = data_dir + 'checkpoints/EEG_RNN.ckpt'\n",
        "model_json_path = data_dir + 'checkpoints/EEG_RNN.json'\n",
        "import keras.callbacks\n",
        "\n",
        "# Create checkpoint callback\n",
        "cp_callback = keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
        "                                                 save_weights_only=True, \n",
        "                                                 monitor='val_loss',\n",
        "                                                 save_best_only=True, \n",
        "                                                 mode='auto',\n",
        "                                                 verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b7DhhF7wbe_o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Build model architecture\n",
        "model = Sequential()\n",
        "\n",
        "model.add(LSTM(30, recurrent_dropout=0.25, kernel_regularizer=regularizers.l2(0.01), input_shape=(num_timesteps, num_features), return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(LSTM(16, dropout=0.5, recurrent_dropout=0.5, kernel_regularizer=regularizers.l2(0.03)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# model.add(Dense(8, kernel_regularizer=regularizers.l2(0.01)))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.6))\n",
        "\n",
        "model.add(Dense(4, activation='softmax', kernel_regularizer=regularizers.l2(0.05)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ANXexDGeYOT_",
        "colab_type": "code",
        "outputId": "76fae835-6eae-44fa-e057-5218c2319f52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "with open(model_json_path, 'w') as f:\n",
        "    f.write(model.to_json())\n",
        "#model.load_weights(checkpoint_path)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_19 (LSTM)               (None, 40, 30)            6360      \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 40, 30)            120       \n",
            "_________________________________________________________________\n",
            "lstm_20 (LSTM)               (None, 16)                3008      \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 16)                64        \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 4)                 68        \n",
            "=================================================================\n",
            "Total params: 9,620\n",
            "Trainable params: 9,528\n",
            "Non-trainable params: 92\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dXMO2FUUaLxX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train RNN Model"
      ]
    },
    {
      "metadata": {
        "id": "VaBt345Kbe_r",
        "colab_type": "code",
        "outputId": "03f16318-2a3f-4556-fac9-3fef808b4390",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68034
        }
      },
      "cell_type": "code",
      "source": [
        "# Fit model on training set, validate with validation data\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(X_train_processed, y_train_processed, validation_data=(X_valid_processed, y_valid_processed), epochs=1000, batch_size=512, verbose=2, callbacks = [cp_callback])"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 16920 samples, validate on 4230 samples\n",
            "Epoch 1/1000\n",
            " - 18s - loss: 4.1674 - acc: 0.2561 - val_loss: 3.1159 - val_acc: 0.2558\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 1.24986\n",
            "Epoch 2/1000\n",
            " - 8s - loss: 3.6075 - acc: 0.2513 - val_loss: 2.7713 - val_acc: 0.2470\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 1.24986\n",
            "Epoch 3/1000\n",
            " - 8s - loss: 3.1520 - acc: 0.2562 - val_loss: 2.5293 - val_acc: 0.2357\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 1.24986\n",
            "Epoch 4/1000\n",
            " - 8s - loss: 2.8122 - acc: 0.2582 - val_loss: 2.3088 - val_acc: 0.2404\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 1.24986\n",
            "Epoch 5/1000\n",
            " - 8s - loss: 2.5496 - acc: 0.2502 - val_loss: 2.1358 - val_acc: 0.2319\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 1.24986\n",
            "Epoch 6/1000\n",
            " - 8s - loss: 2.3029 - acc: 0.2572 - val_loss: 1.9988 - val_acc: 0.2395\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 1.24986\n",
            "Epoch 7/1000\n",
            " - 8s - loss: 2.1313 - acc: 0.2584 - val_loss: 1.8852 - val_acc: 0.2317\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 1.24986\n",
            "Epoch 8/1000\n",
            " - 8s - loss: 1.9831 - acc: 0.2661 - val_loss: 1.7966 - val_acc: 0.2317\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.24986\n",
            "Epoch 9/1000\n",
            " - 8s - loss: 1.8821 - acc: 0.2586 - val_loss: 1.7246 - val_acc: 0.2390\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.24986\n",
            "Epoch 10/1000\n",
            " - 8s - loss: 1.7909 - acc: 0.2550 - val_loss: 1.6675 - val_acc: 0.2355\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.24986\n",
            "Epoch 11/1000\n",
            " - 8s - loss: 1.7160 - acc: 0.2612 - val_loss: 1.6238 - val_acc: 0.2279\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 1.24986\n",
            "Epoch 12/1000\n",
            " - 8s - loss: 1.6578 - acc: 0.2654 - val_loss: 1.5876 - val_acc: 0.2286\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 1.24986\n",
            "Epoch 13/1000\n",
            " - 8s - loss: 1.6148 - acc: 0.2577 - val_loss: 1.5574 - val_acc: 0.2305\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 1.24986\n",
            "Epoch 14/1000\n",
            " - 8s - loss: 1.5749 - acc: 0.2611 - val_loss: 1.5307 - val_acc: 0.2291\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 1.24986\n",
            "Epoch 15/1000\n",
            " - 8s - loss: 1.5446 - acc: 0.2624 - val_loss: 1.5105 - val_acc: 0.2324\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.24986\n",
            "Epoch 16/1000\n",
            " - 8s - loss: 1.5212 - acc: 0.2607 - val_loss: 1.4950 - val_acc: 0.2291\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 1.24986\n",
            "Epoch 17/1000\n",
            " - 8s - loss: 1.4942 - acc: 0.2712 - val_loss: 1.4801 - val_acc: 0.2326\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 1.24986\n",
            "Epoch 18/1000\n",
            " - 8s - loss: 1.4840 - acc: 0.2642 - val_loss: 1.4688 - val_acc: 0.2279\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1.24986\n",
            "Epoch 19/1000\n",
            " - 8s - loss: 1.4687 - acc: 0.2677 - val_loss: 1.4575 - val_acc: 0.2298\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 1.24986\n",
            "Epoch 20/1000\n",
            " - 8s - loss: 1.4550 - acc: 0.2725 - val_loss: 1.4494 - val_acc: 0.2236\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.24986\n",
            "Epoch 21/1000\n",
            " - 8s - loss: 1.4448 - acc: 0.2777 - val_loss: 1.4431 - val_acc: 0.2262\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.24986\n",
            "Epoch 22/1000\n",
            " - 8s - loss: 1.4362 - acc: 0.2780 - val_loss: 1.4366 - val_acc: 0.2407\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.24986\n",
            "Epoch 23/1000\n",
            " - 8s - loss: 1.4307 - acc: 0.2745 - val_loss: 1.4314 - val_acc: 0.2303\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.24986\n",
            "Epoch 24/1000\n",
            " - 8s - loss: 1.4238 - acc: 0.2828 - val_loss: 1.4270 - val_acc: 0.2267\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.24986\n",
            "Epoch 25/1000\n",
            " - 8s - loss: 1.4199 - acc: 0.2771 - val_loss: 1.4236 - val_acc: 0.2260\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.24986\n",
            "Epoch 26/1000\n",
            " - 8s - loss: 1.4151 - acc: 0.2829 - val_loss: 1.4193 - val_acc: 0.2220\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.24986\n",
            "Epoch 27/1000\n",
            " - 8s - loss: 1.4095 - acc: 0.2817 - val_loss: 1.4154 - val_acc: 0.2494\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.24986\n",
            "Epoch 28/1000\n",
            " - 8s - loss: 1.4063 - acc: 0.2909 - val_loss: 1.4138 - val_acc: 0.2348\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.24986\n",
            "Epoch 29/1000\n",
            " - 8s - loss: 1.4034 - acc: 0.2884 - val_loss: 1.4112 - val_acc: 0.2428\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.24986\n",
            "Epoch 30/1000\n",
            " - 8s - loss: 1.4020 - acc: 0.2890 - val_loss: 1.4083 - val_acc: 0.2525\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.24986\n",
            "Epoch 31/1000\n",
            " - 8s - loss: 1.3988 - acc: 0.2901 - val_loss: 1.4062 - val_acc: 0.2624\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 1.24986\n",
            "Epoch 32/1000\n",
            " - 8s - loss: 1.3958 - acc: 0.2937 - val_loss: 1.4035 - val_acc: 0.2733\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 1.24986\n",
            "Epoch 33/1000\n",
            " - 8s - loss: 1.3927 - acc: 0.3039 - val_loss: 1.4007 - val_acc: 0.2721\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 1.24986\n",
            "Epoch 34/1000\n",
            " - 8s - loss: 1.3896 - acc: 0.3103 - val_loss: 1.3920 - val_acc: 0.2946\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 1.24986\n",
            "Epoch 35/1000\n",
            " - 8s - loss: 1.3805 - acc: 0.3229 - val_loss: 1.3704 - val_acc: 0.3364\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 1.24986\n",
            "Epoch 36/1000\n",
            " - 8s - loss: 1.3672 - acc: 0.3402 - val_loss: 1.3406 - val_acc: 0.3530\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.24986\n",
            "Epoch 37/1000\n",
            " - 8s - loss: 1.3582 - acc: 0.3478 - val_loss: 1.3359 - val_acc: 0.3570\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.24986\n",
            "Epoch 38/1000\n",
            " - 8s - loss: 1.3556 - acc: 0.3533 - val_loss: 1.3300 - val_acc: 0.3565\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 1.24986\n",
            "Epoch 39/1000\n",
            " - 8s - loss: 1.3470 - acc: 0.3650 - val_loss: 1.3285 - val_acc: 0.3600\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 1.24986\n",
            "Epoch 40/1000\n",
            " - 8s - loss: 1.3442 - acc: 0.3658 - val_loss: 1.3166 - val_acc: 0.3754\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 1.24986\n",
            "Epoch 41/1000\n",
            " - 8s - loss: 1.3374 - acc: 0.3745 - val_loss: 1.3073 - val_acc: 0.3728\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 1.24986\n",
            "Epoch 42/1000\n",
            " - 8s - loss: 1.3356 - acc: 0.3724 - val_loss: 1.3097 - val_acc: 0.3823\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 1.24986\n",
            "Epoch 43/1000\n",
            " - 8s - loss: 1.3300 - acc: 0.3767 - val_loss: 1.3164 - val_acc: 0.3674\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 1.24986\n",
            "Epoch 44/1000\n",
            " - 8s - loss: 1.3275 - acc: 0.3823 - val_loss: 1.2897 - val_acc: 0.3993\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 1.24986\n",
            "Epoch 45/1000\n",
            " - 8s - loss: 1.3251 - acc: 0.3817 - val_loss: 1.2930 - val_acc: 0.3995\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 1.24986\n",
            "Epoch 46/1000\n",
            " - 8s - loss: 1.3190 - acc: 0.3939 - val_loss: 1.2982 - val_acc: 0.3927\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 1.24986\n",
            "Epoch 47/1000\n",
            " - 8s - loss: 1.3189 - acc: 0.3914 - val_loss: 1.2814 - val_acc: 0.4116\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 1.24986\n",
            "Epoch 48/1000\n",
            " - 8s - loss: 1.3154 - acc: 0.3913 - val_loss: 1.2892 - val_acc: 0.4099\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 1.24986\n",
            "Epoch 49/1000\n",
            " - 8s - loss: 1.3112 - acc: 0.3985 - val_loss: 1.2873 - val_acc: 0.4090\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 1.24986\n",
            "Epoch 50/1000\n",
            " - 8s - loss: 1.3092 - acc: 0.3973 - val_loss: 1.2749 - val_acc: 0.4189\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 1.24986\n",
            "Epoch 51/1000\n",
            " - 8s - loss: 1.3137 - acc: 0.3954 - val_loss: 1.2881 - val_acc: 0.4033\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 1.24986\n",
            "Epoch 52/1000\n",
            " - 8s - loss: 1.3083 - acc: 0.3976 - val_loss: 1.2805 - val_acc: 0.4040\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 1.24986\n",
            "Epoch 53/1000\n",
            " - 8s - loss: 1.3155 - acc: 0.3912 - val_loss: 1.2795 - val_acc: 0.4168\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 1.24986\n",
            "Epoch 54/1000\n",
            " - 8s - loss: 1.3110 - acc: 0.3921 - val_loss: 1.2968 - val_acc: 0.3820\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 1.24986\n",
            "Epoch 55/1000\n",
            " - 8s - loss: 1.3041 - acc: 0.3956 - val_loss: 1.2630 - val_acc: 0.4215\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 1.24986\n",
            "Epoch 56/1000\n",
            " - 8s - loss: 1.3047 - acc: 0.4009 - val_loss: 1.2803 - val_acc: 0.4132\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 1.24986\n",
            "Epoch 57/1000\n",
            " - 8s - loss: 1.3060 - acc: 0.3940 - val_loss: 1.2791 - val_acc: 0.4017\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 1.24986\n",
            "Epoch 58/1000\n",
            " - 8s - loss: 1.3010 - acc: 0.4019 - val_loss: 1.2815 - val_acc: 0.3950\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 1.24986\n",
            "Epoch 59/1000\n",
            " - 8s - loss: 1.2981 - acc: 0.4060 - val_loss: 1.2705 - val_acc: 0.4187\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 1.24986\n",
            "Epoch 60/1000\n",
            " - 8s - loss: 1.2961 - acc: 0.3992 - val_loss: 1.2685 - val_acc: 0.4201\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 1.24986\n",
            "Epoch 61/1000\n",
            " - 8s - loss: 1.2966 - acc: 0.3988 - val_loss: 1.2801 - val_acc: 0.4000\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 1.24986\n",
            "Epoch 62/1000\n",
            " - 8s - loss: 1.2923 - acc: 0.4035 - val_loss: 1.2735 - val_acc: 0.4113\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 1.24986\n",
            "Epoch 63/1000\n",
            " - 8s - loss: 1.2998 - acc: 0.3986 - val_loss: 1.2600 - val_acc: 0.4265\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 1.24986\n",
            "Epoch 64/1000\n",
            " - 8s - loss: 1.2936 - acc: 0.4048 - val_loss: 1.2681 - val_acc: 0.4194\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 1.24986\n",
            "Epoch 65/1000\n",
            " - 8s - loss: 1.2935 - acc: 0.4021 - val_loss: 1.2933 - val_acc: 0.3905\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 1.24986\n",
            "Epoch 66/1000\n",
            " - 8s - loss: 1.2941 - acc: 0.3983 - val_loss: 1.2571 - val_acc: 0.4151\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 1.24986\n",
            "Epoch 67/1000\n",
            " - 8s - loss: 1.2934 - acc: 0.3975 - val_loss: 1.2706 - val_acc: 0.4137\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 1.24986\n",
            "Epoch 68/1000\n",
            " - 8s - loss: 1.2903 - acc: 0.4040 - val_loss: 1.2840 - val_acc: 0.3965\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 1.24986\n",
            "Epoch 69/1000\n",
            " - 8s - loss: 1.2895 - acc: 0.4055 - val_loss: 1.2454 - val_acc: 0.4364\n",
            "\n",
            "Epoch 00069: val_loss improved from 1.24986 to 1.24541, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 70/1000\n",
            " - 8s - loss: 1.2821 - acc: 0.4086 - val_loss: 1.2534 - val_acc: 0.4291\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 1.24541\n",
            "Epoch 71/1000\n",
            " - 8s - loss: 1.2852 - acc: 0.4066 - val_loss: 1.2623 - val_acc: 0.4173\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 1.24541\n",
            "Epoch 72/1000\n",
            " - 8s - loss: 1.2869 - acc: 0.4063 - val_loss: 1.2556 - val_acc: 0.4267\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 1.24541\n",
            "Epoch 73/1000\n",
            " - 8s - loss: 1.2911 - acc: 0.4063 - val_loss: 1.2654 - val_acc: 0.4109\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 1.24541\n",
            "Epoch 74/1000\n",
            " - 8s - loss: 1.2874 - acc: 0.4053 - val_loss: 1.2475 - val_acc: 0.4298\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 1.24541\n",
            "Epoch 75/1000\n",
            " - 8s - loss: 1.2801 - acc: 0.4151 - val_loss: 1.2754 - val_acc: 0.3924\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 1.24541\n",
            "Epoch 76/1000\n",
            " - 8s - loss: 1.2793 - acc: 0.4151 - val_loss: 1.2674 - val_acc: 0.4069\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 1.24541\n",
            "Epoch 77/1000\n",
            " - 8s - loss: 1.2825 - acc: 0.4102 - val_loss: 1.2542 - val_acc: 0.4158\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 1.24541\n",
            "Epoch 78/1000\n",
            " - 8s - loss: 1.2788 - acc: 0.4148 - val_loss: 1.2868 - val_acc: 0.3849\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 1.24541\n",
            "Epoch 79/1000\n",
            " - 8s - loss: 1.2768 - acc: 0.4102 - val_loss: 1.2644 - val_acc: 0.3976\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 1.24541\n",
            "Epoch 80/1000\n",
            " - 8s - loss: 1.2798 - acc: 0.4134 - val_loss: 1.2713 - val_acc: 0.3927\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 1.24541\n",
            "Epoch 81/1000\n",
            " - 8s - loss: 1.2780 - acc: 0.4152 - val_loss: 1.2949 - val_acc: 0.3801\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 1.24541\n",
            "Epoch 82/1000\n",
            " - 8s - loss: 1.2771 - acc: 0.4136 - val_loss: 1.2656 - val_acc: 0.4035\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 1.24541\n",
            "Epoch 83/1000\n",
            " - 8s - loss: 1.2825 - acc: 0.4088 - val_loss: 1.2781 - val_acc: 0.3983\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 1.24541\n",
            "Epoch 84/1000\n",
            " - 8s - loss: 1.2726 - acc: 0.4118 - val_loss: 1.2525 - val_acc: 0.4206\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 1.24541\n",
            "Epoch 85/1000\n",
            " - 8s - loss: 1.2783 - acc: 0.4117 - val_loss: 1.2743 - val_acc: 0.3974\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 1.24541\n",
            "Epoch 86/1000\n",
            " - 8s - loss: 1.2735 - acc: 0.4188 - val_loss: 1.2680 - val_acc: 0.4033\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 1.24541\n",
            "Epoch 87/1000\n",
            " - 8s - loss: 1.2727 - acc: 0.4174 - val_loss: 1.2715 - val_acc: 0.3965\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 1.24541\n",
            "Epoch 88/1000\n",
            " - 8s - loss: 1.2727 - acc: 0.4152 - val_loss: 1.2782 - val_acc: 0.3913\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 1.24541\n",
            "Epoch 89/1000\n",
            " - 8s - loss: 1.2688 - acc: 0.4177 - val_loss: 1.2492 - val_acc: 0.4139\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 1.24541\n",
            "Epoch 90/1000\n",
            " - 8s - loss: 1.2757 - acc: 0.4129 - val_loss: 1.2494 - val_acc: 0.4246\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 1.24541\n",
            "Epoch 91/1000\n",
            " - 8s - loss: 1.2674 - acc: 0.4206 - val_loss: 1.2869 - val_acc: 0.3771\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 1.24541\n",
            "Epoch 92/1000\n",
            " - 8s - loss: 1.2695 - acc: 0.4183 - val_loss: 1.2790 - val_acc: 0.3894\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 1.24541\n",
            "Epoch 93/1000\n",
            " - 8s - loss: 1.2695 - acc: 0.4184 - val_loss: 1.2480 - val_acc: 0.4182\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 1.24541\n",
            "Epoch 94/1000\n",
            " - 8s - loss: 1.2727 - acc: 0.4174 - val_loss: 1.2690 - val_acc: 0.4021\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 1.24541\n",
            "Epoch 95/1000\n",
            " - 8s - loss: 1.2666 - acc: 0.4174 - val_loss: 1.2650 - val_acc: 0.4021\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 1.24541\n",
            "Epoch 96/1000\n",
            " - 8s - loss: 1.2689 - acc: 0.4215 - val_loss: 1.2669 - val_acc: 0.3976\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 1.24541\n",
            "Epoch 97/1000\n",
            " - 8s - loss: 1.2657 - acc: 0.4220 - val_loss: 1.2718 - val_acc: 0.4038\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 1.24541\n",
            "Epoch 98/1000\n",
            " - 8s - loss: 1.2667 - acc: 0.4202 - val_loss: 1.2792 - val_acc: 0.3858\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 1.24541\n",
            "Epoch 99/1000\n",
            " - 8s - loss: 1.2706 - acc: 0.4177 - val_loss: 1.2762 - val_acc: 0.3931\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 1.24541\n",
            "Epoch 100/1000\n",
            " - 8s - loss: 1.2631 - acc: 0.4220 - val_loss: 1.2535 - val_acc: 0.4196\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 1.24541\n",
            "Epoch 101/1000\n",
            " - 8s - loss: 1.2665 - acc: 0.4255 - val_loss: 1.2514 - val_acc: 0.4111\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 1.24541\n",
            "Epoch 102/1000\n",
            " - 8s - loss: 1.2687 - acc: 0.4223 - val_loss: 1.2599 - val_acc: 0.4078\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 1.24541\n",
            "Epoch 103/1000\n",
            " - 8s - loss: 1.2654 - acc: 0.4221 - val_loss: 1.2940 - val_acc: 0.3726\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 1.24541\n",
            "Epoch 104/1000\n",
            " - 8s - loss: 1.2654 - acc: 0.4200 - val_loss: 1.2654 - val_acc: 0.4109\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 1.24541\n",
            "Epoch 105/1000\n",
            " - 8s - loss: 1.2612 - acc: 0.4265 - val_loss: 1.2998 - val_acc: 0.3667\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 1.24541\n",
            "Epoch 106/1000\n",
            " - 8s - loss: 1.2661 - acc: 0.4190 - val_loss: 1.2891 - val_acc: 0.3809\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 1.24541\n",
            "Epoch 107/1000\n",
            " - 8s - loss: 1.2603 - acc: 0.4243 - val_loss: 1.2534 - val_acc: 0.4142\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 1.24541\n",
            "Epoch 108/1000\n",
            " - 8s - loss: 1.2594 - acc: 0.4234 - val_loss: 1.2683 - val_acc: 0.3967\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 1.24541\n",
            "Epoch 109/1000\n",
            " - 8s - loss: 1.2555 - acc: 0.4315 - val_loss: 1.2784 - val_acc: 0.3896\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 1.24541\n",
            "Epoch 110/1000\n",
            " - 8s - loss: 1.2625 - acc: 0.4254 - val_loss: 1.2539 - val_acc: 0.4165\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 1.24541\n",
            "Epoch 111/1000\n",
            " - 8s - loss: 1.2579 - acc: 0.4246 - val_loss: 1.2918 - val_acc: 0.3742\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 1.24541\n",
            "Epoch 112/1000\n",
            " - 8s - loss: 1.2579 - acc: 0.4262 - val_loss: 1.2630 - val_acc: 0.4026\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 1.24541\n",
            "Epoch 113/1000\n",
            " - 8s - loss: 1.2610 - acc: 0.4266 - val_loss: 1.2334 - val_acc: 0.4355\n",
            "\n",
            "Epoch 00113: val_loss improved from 1.24541 to 1.23344, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 114/1000\n",
            " - 8s - loss: 1.2671 - acc: 0.4190 - val_loss: 1.2850 - val_acc: 0.3842\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 1.23344\n",
            "Epoch 115/1000\n",
            " - 8s - loss: 1.2602 - acc: 0.4285 - val_loss: 1.2458 - val_acc: 0.4258\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 1.23344\n",
            "Epoch 116/1000\n",
            " - 8s - loss: 1.2580 - acc: 0.4302 - val_loss: 1.2633 - val_acc: 0.4040\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 1.23344\n",
            "Epoch 117/1000\n",
            " - 8s - loss: 1.2550 - acc: 0.4293 - val_loss: 1.2520 - val_acc: 0.4128\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 1.23344\n",
            "Epoch 118/1000\n",
            " - 8s - loss: 1.2583 - acc: 0.4251 - val_loss: 1.2676 - val_acc: 0.4014\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 1.23344\n",
            "Epoch 119/1000\n",
            " - 8s - loss: 1.2603 - acc: 0.4272 - val_loss: 1.2573 - val_acc: 0.4085\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 1.23344\n",
            "Epoch 120/1000\n",
            " - 8s - loss: 1.2598 - acc: 0.4268 - val_loss: 1.2606 - val_acc: 0.4095\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 1.23344\n",
            "Epoch 121/1000\n",
            " - 8s - loss: 1.2591 - acc: 0.4270 - val_loss: 1.2417 - val_acc: 0.4277\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 1.23344\n",
            "Epoch 122/1000\n",
            " - 8s - loss: 1.2561 - acc: 0.4296 - val_loss: 1.2730 - val_acc: 0.3953\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 1.23344\n",
            "Epoch 123/1000\n",
            " - 8s - loss: 1.2600 - acc: 0.4264 - val_loss: 1.2526 - val_acc: 0.4104\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 1.23344\n",
            "Epoch 124/1000\n",
            " - 8s - loss: 1.2619 - acc: 0.4287 - val_loss: 1.2423 - val_acc: 0.4248\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 1.23344\n",
            "Epoch 125/1000\n",
            " - 8s - loss: 1.2558 - acc: 0.4296 - val_loss: 1.2674 - val_acc: 0.4005\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 1.23344\n",
            "Epoch 126/1000\n",
            " - 8s - loss: 1.2544 - acc: 0.4331 - val_loss: 1.2668 - val_acc: 0.4033\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 1.23344\n",
            "Epoch 127/1000\n",
            " - 8s - loss: 1.2566 - acc: 0.4268 - val_loss: 1.2723 - val_acc: 0.3941\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 1.23344\n",
            "Epoch 128/1000\n",
            " - 8s - loss: 1.2577 - acc: 0.4292 - val_loss: 1.2529 - val_acc: 0.4144\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 1.23344\n",
            "Epoch 129/1000\n",
            " - 8s - loss: 1.2510 - acc: 0.4313 - val_loss: 1.2738 - val_acc: 0.3943\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 1.23344\n",
            "Epoch 130/1000\n",
            " - 8s - loss: 1.2517 - acc: 0.4314 - val_loss: 1.2496 - val_acc: 0.4142\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 1.23344\n",
            "Epoch 131/1000\n",
            " - 8s - loss: 1.2568 - acc: 0.4301 - val_loss: 1.2772 - val_acc: 0.3931\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 1.23344\n",
            "Epoch 132/1000\n",
            " - 8s - loss: 1.2491 - acc: 0.4378 - val_loss: 1.2663 - val_acc: 0.4012\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 1.23344\n",
            "Epoch 133/1000\n",
            " - 8s - loss: 1.2527 - acc: 0.4348 - val_loss: 1.2711 - val_acc: 0.3908\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 1.23344\n",
            "Epoch 134/1000\n",
            " - 8s - loss: 1.2530 - acc: 0.4326 - val_loss: 1.2763 - val_acc: 0.3908\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 1.23344\n",
            "Epoch 135/1000\n",
            " - 8s - loss: 1.2456 - acc: 0.4380 - val_loss: 1.2724 - val_acc: 0.3861\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 1.23344\n",
            "Epoch 136/1000\n",
            " - 8s - loss: 1.2576 - acc: 0.4302 - val_loss: 1.2607 - val_acc: 0.4043\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 1.23344\n",
            "Epoch 137/1000\n",
            " - 8s - loss: 1.2496 - acc: 0.4329 - val_loss: 1.2650 - val_acc: 0.4033\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 1.23344\n",
            "Epoch 138/1000\n",
            " - 8s - loss: 1.2508 - acc: 0.4284 - val_loss: 1.2725 - val_acc: 0.4014\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 1.23344\n",
            "Epoch 139/1000\n",
            " - 8s - loss: 1.2515 - acc: 0.4303 - val_loss: 1.2769 - val_acc: 0.3903\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 1.23344\n",
            "Epoch 140/1000\n",
            " - 8s - loss: 1.2467 - acc: 0.4401 - val_loss: 1.2758 - val_acc: 0.3920\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 1.23344\n",
            "Epoch 141/1000\n",
            " - 8s - loss: 1.2472 - acc: 0.4346 - val_loss: 1.2646 - val_acc: 0.4057\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 1.23344\n",
            "Epoch 142/1000\n",
            " - 8s - loss: 1.2476 - acc: 0.4349 - val_loss: 1.2667 - val_acc: 0.3979\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 1.23344\n",
            "Epoch 143/1000\n",
            " - 8s - loss: 1.2463 - acc: 0.4395 - val_loss: 1.2692 - val_acc: 0.3993\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 1.23344\n",
            "Epoch 144/1000\n",
            " - 8s - loss: 1.2458 - acc: 0.4433 - val_loss: 1.2811 - val_acc: 0.3835\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 1.23344\n",
            "Epoch 145/1000\n",
            " - 8s - loss: 1.2424 - acc: 0.4426 - val_loss: 1.2698 - val_acc: 0.3955\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 1.23344\n",
            "Epoch 146/1000\n",
            " - 8s - loss: 1.2485 - acc: 0.4346 - val_loss: 1.2687 - val_acc: 0.3983\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 1.23344\n",
            "Epoch 147/1000\n",
            " - 8s - loss: 1.2433 - acc: 0.4406 - val_loss: 1.2499 - val_acc: 0.4151\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 1.23344\n",
            "Epoch 148/1000\n",
            " - 8s - loss: 1.2451 - acc: 0.4446 - val_loss: 1.2739 - val_acc: 0.3920\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 1.23344\n",
            "Epoch 149/1000\n",
            " - 8s - loss: 1.2482 - acc: 0.4400 - val_loss: 1.2754 - val_acc: 0.3920\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 1.23344\n",
            "Epoch 150/1000\n",
            " - 8s - loss: 1.2493 - acc: 0.4395 - val_loss: 1.2531 - val_acc: 0.4080\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 1.23344\n",
            "Epoch 151/1000\n",
            " - 8s - loss: 1.2434 - acc: 0.4366 - val_loss: 1.2620 - val_acc: 0.4021\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 1.23344\n",
            "Epoch 152/1000\n",
            " - 8s - loss: 1.2437 - acc: 0.4411 - val_loss: 1.2893 - val_acc: 0.3832\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 1.23344\n",
            "Epoch 153/1000\n",
            " - 8s - loss: 1.2442 - acc: 0.4406 - val_loss: 1.2364 - val_acc: 0.4374\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 1.23344\n",
            "Epoch 154/1000\n",
            " - 8s - loss: 1.2525 - acc: 0.4325 - val_loss: 1.2940 - val_acc: 0.3726\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 1.23344\n",
            "Epoch 155/1000\n",
            " - 8s - loss: 1.2460 - acc: 0.4415 - val_loss: 1.2631 - val_acc: 0.3998\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 1.23344\n",
            "Epoch 156/1000\n",
            " - 8s - loss: 1.2416 - acc: 0.4384 - val_loss: 1.2588 - val_acc: 0.4028\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 1.23344\n",
            "Epoch 157/1000\n",
            " - 8s - loss: 1.2410 - acc: 0.4439 - val_loss: 1.2696 - val_acc: 0.3976\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 1.23344\n",
            "Epoch 158/1000\n",
            " - 8s - loss: 1.2377 - acc: 0.4433 - val_loss: 1.2449 - val_acc: 0.4255\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 1.23344\n",
            "Epoch 159/1000\n",
            " - 8s - loss: 1.2398 - acc: 0.4425 - val_loss: 1.2381 - val_acc: 0.4260\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 1.23344\n",
            "Epoch 160/1000\n",
            " - 8s - loss: 1.2480 - acc: 0.4369 - val_loss: 1.2515 - val_acc: 0.4092\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 1.23344\n",
            "Epoch 161/1000\n",
            " - 8s - loss: 1.2346 - acc: 0.4463 - val_loss: 1.2287 - val_acc: 0.4364\n",
            "\n",
            "Epoch 00161: val_loss improved from 1.23344 to 1.22871, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 162/1000\n",
            " - 8s - loss: 1.2424 - acc: 0.4428 - val_loss: 1.2896 - val_acc: 0.3818\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 1.22871\n",
            "Epoch 163/1000\n",
            " - 8s - loss: 1.2414 - acc: 0.4418 - val_loss: 1.2654 - val_acc: 0.4040\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 1.22871\n",
            "Epoch 164/1000\n",
            " - 8s - loss: 1.2389 - acc: 0.4460 - val_loss: 1.2708 - val_acc: 0.3967\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 1.22871\n",
            "Epoch 165/1000\n",
            " - 8s - loss: 1.2370 - acc: 0.4454 - val_loss: 1.2552 - val_acc: 0.4047\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 1.22871\n",
            "Epoch 166/1000\n",
            " - 8s - loss: 1.2352 - acc: 0.4462 - val_loss: 1.2693 - val_acc: 0.3969\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 1.22871\n",
            "Epoch 167/1000\n",
            " - 8s - loss: 1.2344 - acc: 0.4483 - val_loss: 1.2588 - val_acc: 0.4033\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 1.22871\n",
            "Epoch 168/1000\n",
            " - 8s - loss: 1.2341 - acc: 0.4465 - val_loss: 1.2453 - val_acc: 0.4173\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 1.22871\n",
            "Epoch 169/1000\n",
            " - 8s - loss: 1.2396 - acc: 0.4481 - val_loss: 1.2488 - val_acc: 0.4125\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 1.22871\n",
            "Epoch 170/1000\n",
            " - 8s - loss: 1.2320 - acc: 0.4499 - val_loss: 1.2469 - val_acc: 0.4206\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 1.22871\n",
            "Epoch 171/1000\n",
            " - 8s - loss: 1.2318 - acc: 0.4503 - val_loss: 1.2842 - val_acc: 0.3799\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 1.22871\n",
            "Epoch 172/1000\n",
            " - 8s - loss: 1.2377 - acc: 0.4460 - val_loss: 1.2759 - val_acc: 0.3929\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 1.22871\n",
            "Epoch 173/1000\n",
            " - 8s - loss: 1.2370 - acc: 0.4488 - val_loss: 1.2680 - val_acc: 0.3983\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 1.22871\n",
            "Epoch 174/1000\n",
            " - 8s - loss: 1.2441 - acc: 0.4447 - val_loss: 1.2662 - val_acc: 0.4031\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 1.22871\n",
            "Epoch 175/1000\n",
            " - 8s - loss: 1.2391 - acc: 0.4470 - val_loss: 1.2426 - val_acc: 0.4225\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 1.22871\n",
            "Epoch 176/1000\n",
            " - 8s - loss: 1.2346 - acc: 0.4471 - val_loss: 1.2512 - val_acc: 0.4097\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 1.22871\n",
            "Epoch 177/1000\n",
            " - 8s - loss: 1.2350 - acc: 0.4468 - val_loss: 1.2591 - val_acc: 0.4024\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 1.22871\n",
            "Epoch 178/1000\n",
            " - 8s - loss: 1.2317 - acc: 0.4508 - val_loss: 1.2437 - val_acc: 0.4118\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 1.22871\n",
            "Epoch 179/1000\n",
            " - 8s - loss: 1.2367 - acc: 0.4515 - val_loss: 1.2721 - val_acc: 0.3924\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 1.22871\n",
            "Epoch 180/1000\n",
            " - 8s - loss: 1.2350 - acc: 0.4515 - val_loss: 1.2344 - val_acc: 0.4305\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 1.22871\n",
            "Epoch 181/1000\n",
            " - 8s - loss: 1.2385 - acc: 0.4480 - val_loss: 1.2762 - val_acc: 0.3915\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 1.22871\n",
            "Epoch 182/1000\n",
            " - 8s - loss: 1.2299 - acc: 0.4518 - val_loss: 1.2839 - val_acc: 0.3851\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 1.22871\n",
            "Epoch 183/1000\n",
            " - 8s - loss: 1.2351 - acc: 0.4501 - val_loss: 1.2657 - val_acc: 0.4007\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 1.22871\n",
            "Epoch 184/1000\n",
            " - 8s - loss: 1.2330 - acc: 0.4531 - val_loss: 1.2596 - val_acc: 0.4045\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 1.22871\n",
            "Epoch 185/1000\n",
            " - 8s - loss: 1.2386 - acc: 0.4485 - val_loss: 1.2420 - val_acc: 0.4241\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 1.22871\n",
            "Epoch 186/1000\n",
            " - 8s - loss: 1.2326 - acc: 0.4540 - val_loss: 1.2320 - val_acc: 0.4366\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 1.22871\n",
            "Epoch 187/1000\n",
            " - 8s - loss: 1.2294 - acc: 0.4548 - val_loss: 1.2738 - val_acc: 0.3922\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 1.22871\n",
            "Epoch 188/1000\n",
            " - 8s - loss: 1.2456 - acc: 0.4461 - val_loss: 1.2611 - val_acc: 0.4109\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 1.22871\n",
            "Epoch 189/1000\n",
            " - 8s - loss: 1.2349 - acc: 0.4517 - val_loss: 1.2473 - val_acc: 0.4123\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 1.22871\n",
            "Epoch 190/1000\n",
            " - 8s - loss: 1.2284 - acc: 0.4551 - val_loss: 1.2599 - val_acc: 0.4052\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 1.22871\n",
            "Epoch 191/1000\n",
            " - 8s - loss: 1.2320 - acc: 0.4529 - val_loss: 1.2659 - val_acc: 0.4061\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 1.22871\n",
            "Epoch 192/1000\n",
            " - 8s - loss: 1.2300 - acc: 0.4545 - val_loss: 1.2803 - val_acc: 0.3882\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 1.22871\n",
            "Epoch 193/1000\n",
            " - 8s - loss: 1.2249 - acc: 0.4583 - val_loss: 1.2460 - val_acc: 0.4260\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 1.22871\n",
            "Epoch 194/1000\n",
            " - 8s - loss: 1.2295 - acc: 0.4553 - val_loss: 1.2427 - val_acc: 0.4175\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 1.22871\n",
            "Epoch 195/1000\n",
            " - 8s - loss: 1.2296 - acc: 0.4540 - val_loss: 1.2385 - val_acc: 0.4265\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 1.22871\n",
            "Epoch 196/1000\n",
            " - 8s - loss: 1.2282 - acc: 0.4596 - val_loss: 1.3066 - val_acc: 0.3671\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 1.22871\n",
            "Epoch 197/1000\n",
            " - 8s - loss: 1.2291 - acc: 0.4563 - val_loss: 1.2555 - val_acc: 0.4194\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 1.22871\n",
            "Epoch 198/1000\n",
            " - 8s - loss: 1.2258 - acc: 0.4569 - val_loss: 1.2440 - val_acc: 0.4274\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 1.22871\n",
            "Epoch 199/1000\n",
            " - 8s - loss: 1.2292 - acc: 0.4584 - val_loss: 1.2533 - val_acc: 0.4187\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 1.22871\n",
            "Epoch 200/1000\n",
            " - 8s - loss: 1.2240 - acc: 0.4584 - val_loss: 1.2283 - val_acc: 0.4397\n",
            "\n",
            "Epoch 00200: val_loss improved from 1.22871 to 1.22825, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 201/1000\n",
            " - 8s - loss: 1.2278 - acc: 0.4542 - val_loss: 1.2361 - val_acc: 0.4277\n",
            "\n",
            "Epoch 00201: val_loss did not improve from 1.22825\n",
            "Epoch 202/1000\n",
            " - 8s - loss: 1.2246 - acc: 0.4622 - val_loss: 1.2200 - val_acc: 0.4426\n",
            "\n",
            "Epoch 00202: val_loss improved from 1.22825 to 1.21995, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 203/1000\n",
            " - 8s - loss: 1.2347 - acc: 0.4557 - val_loss: 1.2429 - val_acc: 0.4277\n",
            "\n",
            "Epoch 00203: val_loss did not improve from 1.21995\n",
            "Epoch 204/1000\n",
            " - 8s - loss: 1.2253 - acc: 0.4552 - val_loss: 1.2405 - val_acc: 0.4286\n",
            "\n",
            "Epoch 00204: val_loss did not improve from 1.21995\n",
            "Epoch 205/1000\n",
            " - 8s - loss: 1.2213 - acc: 0.4642 - val_loss: 1.2248 - val_acc: 0.4456\n",
            "\n",
            "Epoch 00205: val_loss did not improve from 1.21995\n",
            "Epoch 206/1000\n",
            " - 8s - loss: 1.2286 - acc: 0.4599 - val_loss: 1.2499 - val_acc: 0.4217\n",
            "\n",
            "Epoch 00206: val_loss did not improve from 1.21995\n",
            "Epoch 207/1000\n",
            " - 8s - loss: 1.2206 - acc: 0.4640 - val_loss: 1.2646 - val_acc: 0.4085\n",
            "\n",
            "Epoch 00207: val_loss did not improve from 1.21995\n",
            "Epoch 208/1000\n",
            " - 8s - loss: 1.2274 - acc: 0.4585 - val_loss: 1.2406 - val_acc: 0.4359\n",
            "\n",
            "Epoch 00208: val_loss did not improve from 1.21995\n",
            "Epoch 209/1000\n",
            " - 8s - loss: 1.2270 - acc: 0.4587 - val_loss: 1.2458 - val_acc: 0.4184\n",
            "\n",
            "Epoch 00209: val_loss did not improve from 1.21995\n",
            "Epoch 210/1000\n",
            " - 8s - loss: 1.2212 - acc: 0.4608 - val_loss: 1.2664 - val_acc: 0.4078\n",
            "\n",
            "Epoch 00210: val_loss did not improve from 1.21995\n",
            "Epoch 211/1000\n",
            " - 8s - loss: 1.2242 - acc: 0.4618 - val_loss: 1.2494 - val_acc: 0.4194\n",
            "\n",
            "Epoch 00211: val_loss did not improve from 1.21995\n",
            "Epoch 212/1000\n",
            " - 8s - loss: 1.2232 - acc: 0.4629 - val_loss: 1.2413 - val_acc: 0.4279\n",
            "\n",
            "Epoch 00212: val_loss did not improve from 1.21995\n",
            "Epoch 213/1000\n",
            " - 8s - loss: 1.2218 - acc: 0.4650 - val_loss: 1.2331 - val_acc: 0.4409\n",
            "\n",
            "Epoch 00213: val_loss did not improve from 1.21995\n",
            "Epoch 214/1000\n",
            " - 8s - loss: 1.2217 - acc: 0.4649 - val_loss: 1.2340 - val_acc: 0.4307\n",
            "\n",
            "Epoch 00214: val_loss did not improve from 1.21995\n",
            "Epoch 215/1000\n",
            " - 8s - loss: 1.2297 - acc: 0.4631 - val_loss: 1.2400 - val_acc: 0.4243\n",
            "\n",
            "Epoch 00215: val_loss did not improve from 1.21995\n",
            "Epoch 216/1000\n",
            " - 8s - loss: 1.2215 - acc: 0.4620 - val_loss: 1.2337 - val_acc: 0.4338\n",
            "\n",
            "Epoch 00216: val_loss did not improve from 1.21995\n",
            "Epoch 217/1000\n",
            " - 8s - loss: 1.2258 - acc: 0.4609 - val_loss: 1.2317 - val_acc: 0.4548\n",
            "\n",
            "Epoch 00217: val_loss did not improve from 1.21995\n",
            "Epoch 218/1000\n",
            " - 8s - loss: 1.2170 - acc: 0.4695 - val_loss: 1.2240 - val_acc: 0.4511\n",
            "\n",
            "Epoch 00218: val_loss did not improve from 1.21995\n",
            "Epoch 219/1000\n",
            " - 8s - loss: 1.2188 - acc: 0.4700 - val_loss: 1.2374 - val_acc: 0.4371\n",
            "\n",
            "Epoch 00219: val_loss did not improve from 1.21995\n",
            "Epoch 220/1000\n",
            " - 8s - loss: 1.2155 - acc: 0.4684 - val_loss: 1.2548 - val_acc: 0.4194\n",
            "\n",
            "Epoch 00220: val_loss did not improve from 1.21995\n",
            "Epoch 221/1000\n",
            " - 8s - loss: 1.2213 - acc: 0.4657 - val_loss: 1.2579 - val_acc: 0.4196\n",
            "\n",
            "Epoch 00221: val_loss did not improve from 1.21995\n",
            "Epoch 222/1000\n",
            " - 8s - loss: 1.2212 - acc: 0.4717 - val_loss: 1.2589 - val_acc: 0.4189\n",
            "\n",
            "Epoch 00222: val_loss did not improve from 1.21995\n",
            "Epoch 223/1000\n",
            " - 8s - loss: 1.2131 - acc: 0.4767 - val_loss: 1.2336 - val_acc: 0.4426\n",
            "\n",
            "Epoch 00223: val_loss did not improve from 1.21995\n",
            "Epoch 224/1000\n",
            " - 8s - loss: 1.2122 - acc: 0.4714 - val_loss: 1.2232 - val_acc: 0.4558\n",
            "\n",
            "Epoch 00224: val_loss did not improve from 1.21995\n",
            "Epoch 225/1000\n",
            " - 8s - loss: 1.2248 - acc: 0.4615 - val_loss: 1.2436 - val_acc: 0.4272\n",
            "\n",
            "Epoch 00225: val_loss did not improve from 1.21995\n",
            "Epoch 226/1000\n",
            " - 8s - loss: 1.2174 - acc: 0.4699 - val_loss: 1.2320 - val_acc: 0.4364\n",
            "\n",
            "Epoch 00226: val_loss did not improve from 1.21995\n",
            "Epoch 227/1000\n",
            " - 8s - loss: 1.2128 - acc: 0.4769 - val_loss: 1.2290 - val_acc: 0.4468\n",
            "\n",
            "Epoch 00227: val_loss did not improve from 1.21995\n",
            "Epoch 228/1000\n",
            " - 8s - loss: 1.2159 - acc: 0.4670 - val_loss: 1.2540 - val_acc: 0.4260\n",
            "\n",
            "Epoch 00228: val_loss did not improve from 1.21995\n",
            "Epoch 229/1000\n",
            " - 8s - loss: 1.2134 - acc: 0.4721 - val_loss: 1.2407 - val_acc: 0.4270\n",
            "\n",
            "Epoch 00229: val_loss did not improve from 1.21995\n",
            "Epoch 230/1000\n",
            " - 8s - loss: 1.2133 - acc: 0.4699 - val_loss: 1.2234 - val_acc: 0.4563\n",
            "\n",
            "Epoch 00230: val_loss did not improve from 1.21995\n",
            "Epoch 231/1000\n",
            " - 8s - loss: 1.2129 - acc: 0.4737 - val_loss: 1.2284 - val_acc: 0.4388\n",
            "\n",
            "Epoch 00231: val_loss did not improve from 1.21995\n",
            "Epoch 232/1000\n",
            " - 8s - loss: 1.2147 - acc: 0.4695 - val_loss: 1.2501 - val_acc: 0.4217\n",
            "\n",
            "Epoch 00232: val_loss did not improve from 1.21995\n",
            "Epoch 233/1000\n",
            " - 8s - loss: 1.2285 - acc: 0.4660 - val_loss: 1.2131 - val_acc: 0.4605\n",
            "\n",
            "Epoch 00233: val_loss improved from 1.21995 to 1.21311, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 234/1000\n",
            " - 8s - loss: 1.2201 - acc: 0.4744 - val_loss: 1.2513 - val_acc: 0.4246\n",
            "\n",
            "Epoch 00234: val_loss did not improve from 1.21311\n",
            "Epoch 235/1000\n",
            " - 8s - loss: 1.2082 - acc: 0.4764 - val_loss: 1.2141 - val_acc: 0.4577\n",
            "\n",
            "Epoch 00235: val_loss did not improve from 1.21311\n",
            "Epoch 236/1000\n",
            " - 8s - loss: 1.2207 - acc: 0.4700 - val_loss: 1.2323 - val_acc: 0.4489\n",
            "\n",
            "Epoch 00236: val_loss did not improve from 1.21311\n",
            "Epoch 237/1000\n",
            " - 8s - loss: 1.2124 - acc: 0.4702 - val_loss: 1.2391 - val_acc: 0.4359\n",
            "\n",
            "Epoch 00237: val_loss did not improve from 1.21311\n",
            "Epoch 238/1000\n",
            " - 8s - loss: 1.2307 - acc: 0.4572 - val_loss: 1.2285 - val_acc: 0.4499\n",
            "\n",
            "Epoch 00238: val_loss did not improve from 1.21311\n",
            "Epoch 239/1000\n",
            " - 8s - loss: 1.2110 - acc: 0.4761 - val_loss: 1.2211 - val_acc: 0.4440\n",
            "\n",
            "Epoch 00239: val_loss did not improve from 1.21311\n",
            "Epoch 240/1000\n",
            " - 8s - loss: 1.2180 - acc: 0.4732 - val_loss: 1.2142 - val_acc: 0.4629\n",
            "\n",
            "Epoch 00240: val_loss did not improve from 1.21311\n",
            "Epoch 241/1000\n",
            " - 8s - loss: 1.2086 - acc: 0.4732 - val_loss: 1.2047 - val_acc: 0.4704\n",
            "\n",
            "Epoch 00241: val_loss improved from 1.21311 to 1.20471, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 242/1000\n",
            " - 8s - loss: 1.2054 - acc: 0.4793 - val_loss: 1.2069 - val_acc: 0.4678\n",
            "\n",
            "Epoch 00242: val_loss did not improve from 1.20471\n",
            "Epoch 243/1000\n",
            " - 8s - loss: 1.2110 - acc: 0.4741 - val_loss: 1.2252 - val_acc: 0.4530\n",
            "\n",
            "Epoch 00243: val_loss did not improve from 1.20471\n",
            "Epoch 244/1000\n",
            " - 8s - loss: 1.2142 - acc: 0.4732 - val_loss: 1.2604 - val_acc: 0.4225\n",
            "\n",
            "Epoch 00244: val_loss did not improve from 1.20471\n",
            "Epoch 245/1000\n",
            " - 8s - loss: 1.2112 - acc: 0.4740 - val_loss: 1.2339 - val_acc: 0.4459\n",
            "\n",
            "Epoch 00245: val_loss did not improve from 1.20471\n",
            "Epoch 246/1000\n",
            " - 8s - loss: 1.2077 - acc: 0.4791 - val_loss: 1.2350 - val_acc: 0.4449\n",
            "\n",
            "Epoch 00246: val_loss did not improve from 1.20471\n",
            "Epoch 247/1000\n",
            " - 8s - loss: 1.2112 - acc: 0.4765 - val_loss: 1.2119 - val_acc: 0.4624\n",
            "\n",
            "Epoch 00247: val_loss did not improve from 1.20471\n",
            "Epoch 248/1000\n",
            " - 8s - loss: 1.2151 - acc: 0.4765 - val_loss: 1.2030 - val_acc: 0.4716\n",
            "\n",
            "Epoch 00248: val_loss improved from 1.20471 to 1.20296, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 249/1000\n",
            " - 8s - loss: 1.2088 - acc: 0.4786 - val_loss: 1.2012 - val_acc: 0.4686\n",
            "\n",
            "Epoch 00249: val_loss improved from 1.20296 to 1.20119, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 250/1000\n",
            " - 8s - loss: 1.2015 - acc: 0.4794 - val_loss: 1.2201 - val_acc: 0.4522\n",
            "\n",
            "Epoch 00250: val_loss did not improve from 1.20119\n",
            "Epoch 251/1000\n",
            " - 8s - loss: 1.2171 - acc: 0.4720 - val_loss: 1.2065 - val_acc: 0.4645\n",
            "\n",
            "Epoch 00251: val_loss did not improve from 1.20119\n",
            "Epoch 252/1000\n",
            " - 8s - loss: 1.2049 - acc: 0.4781 - val_loss: 1.2395 - val_acc: 0.4397\n",
            "\n",
            "Epoch 00252: val_loss did not improve from 1.20119\n",
            "Epoch 253/1000\n",
            " - 8s - loss: 1.2059 - acc: 0.4775 - val_loss: 1.1924 - val_acc: 0.4740\n",
            "\n",
            "Epoch 00253: val_loss improved from 1.20119 to 1.19243, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 254/1000\n",
            " - 8s - loss: 1.2098 - acc: 0.4791 - val_loss: 1.2240 - val_acc: 0.4466\n",
            "\n",
            "Epoch 00254: val_loss did not improve from 1.19243\n",
            "Epoch 255/1000\n",
            " - 8s - loss: 1.2097 - acc: 0.4780 - val_loss: 1.2152 - val_acc: 0.4565\n",
            "\n",
            "Epoch 00255: val_loss did not improve from 1.19243\n",
            "Epoch 256/1000\n",
            " - 8s - loss: 1.2051 - acc: 0.4810 - val_loss: 1.2192 - val_acc: 0.4522\n",
            "\n",
            "Epoch 00256: val_loss did not improve from 1.19243\n",
            "Epoch 257/1000\n",
            " - 8s - loss: 1.2070 - acc: 0.4774 - val_loss: 1.2107 - val_acc: 0.4589\n",
            "\n",
            "Epoch 00257: val_loss did not improve from 1.19243\n",
            "Epoch 258/1000\n",
            " - 8s - loss: 1.2058 - acc: 0.4787 - val_loss: 1.2128 - val_acc: 0.4624\n",
            "\n",
            "Epoch 00258: val_loss did not improve from 1.19243\n",
            "Epoch 259/1000\n",
            " - 8s - loss: 1.2190 - acc: 0.4743 - val_loss: 1.2531 - val_acc: 0.4191\n",
            "\n",
            "Epoch 00259: val_loss did not improve from 1.19243\n",
            "Epoch 260/1000\n",
            " - 8s - loss: 1.2087 - acc: 0.4804 - val_loss: 1.1978 - val_acc: 0.4780\n",
            "\n",
            "Epoch 00260: val_loss did not improve from 1.19243\n",
            "Epoch 261/1000\n",
            " - 8s - loss: 1.2041 - acc: 0.4807 - val_loss: 1.2072 - val_acc: 0.4667\n",
            "\n",
            "Epoch 00261: val_loss did not improve from 1.19243\n",
            "Epoch 262/1000\n",
            " - 8s - loss: 1.1967 - acc: 0.4872 - val_loss: 1.1927 - val_acc: 0.4740\n",
            "\n",
            "Epoch 00262: val_loss did not improve from 1.19243\n",
            "Epoch 263/1000\n",
            " - 8s - loss: 1.1987 - acc: 0.4868 - val_loss: 1.2158 - val_acc: 0.4513\n",
            "\n",
            "Epoch 00263: val_loss did not improve from 1.19243\n",
            "Epoch 264/1000\n",
            " - 8s - loss: 1.1996 - acc: 0.4839 - val_loss: 1.2007 - val_acc: 0.4686\n",
            "\n",
            "Epoch 00264: val_loss did not improve from 1.19243\n",
            "Epoch 265/1000\n",
            " - 8s - loss: 1.2013 - acc: 0.4813 - val_loss: 1.2441 - val_acc: 0.4312\n",
            "\n",
            "Epoch 00265: val_loss did not improve from 1.19243\n",
            "Epoch 266/1000\n",
            " - 8s - loss: 1.2085 - acc: 0.4830 - val_loss: 1.1981 - val_acc: 0.4662\n",
            "\n",
            "Epoch 00266: val_loss did not improve from 1.19243\n",
            "Epoch 267/1000\n",
            " - 8s - loss: 1.2066 - acc: 0.4830 - val_loss: 1.2291 - val_acc: 0.4400\n",
            "\n",
            "Epoch 00267: val_loss did not improve from 1.19243\n",
            "Epoch 268/1000\n",
            " - 8s - loss: 1.2030 - acc: 0.4885 - val_loss: 1.2080 - val_acc: 0.4584\n",
            "\n",
            "Epoch 00268: val_loss did not improve from 1.19243\n",
            "Epoch 269/1000\n",
            " - 8s - loss: 1.1996 - acc: 0.4860 - val_loss: 1.1944 - val_acc: 0.4749\n",
            "\n",
            "Epoch 00269: val_loss did not improve from 1.19243\n",
            "Epoch 270/1000\n",
            " - 8s - loss: 1.1986 - acc: 0.4872 - val_loss: 1.1791 - val_acc: 0.4849\n",
            "\n",
            "Epoch 00270: val_loss improved from 1.19243 to 1.17905, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 271/1000\n",
            " - 8s - loss: 1.2032 - acc: 0.4861 - val_loss: 1.1963 - val_acc: 0.4761\n",
            "\n",
            "Epoch 00271: val_loss did not improve from 1.17905\n",
            "Epoch 272/1000\n",
            " - 8s - loss: 1.2019 - acc: 0.4823 - val_loss: 1.1815 - val_acc: 0.4851\n",
            "\n",
            "Epoch 00272: val_loss did not improve from 1.17905\n",
            "Epoch 273/1000\n",
            " - 8s - loss: 1.1974 - acc: 0.4881 - val_loss: 1.1975 - val_acc: 0.4648\n",
            "\n",
            "Epoch 00273: val_loss did not improve from 1.17905\n",
            "Epoch 274/1000\n",
            " - 8s - loss: 1.1965 - acc: 0.4940 - val_loss: 1.1901 - val_acc: 0.4749\n",
            "\n",
            "Epoch 00274: val_loss did not improve from 1.17905\n",
            "Epoch 275/1000\n",
            " - 8s - loss: 1.1938 - acc: 0.4902 - val_loss: 1.2008 - val_acc: 0.4726\n",
            "\n",
            "Epoch 00275: val_loss did not improve from 1.17905\n",
            "Epoch 276/1000\n",
            " - 8s - loss: 1.1957 - acc: 0.4948 - val_loss: 1.1886 - val_acc: 0.4761\n",
            "\n",
            "Epoch 00276: val_loss did not improve from 1.17905\n",
            "Epoch 277/1000\n",
            " - 8s - loss: 1.1936 - acc: 0.4921 - val_loss: 1.2031 - val_acc: 0.4652\n",
            "\n",
            "Epoch 00277: val_loss did not improve from 1.17905\n",
            "Epoch 278/1000\n",
            " - 8s - loss: 1.2039 - acc: 0.4867 - val_loss: 1.1880 - val_acc: 0.4773\n",
            "\n",
            "Epoch 00278: val_loss did not improve from 1.17905\n",
            "Epoch 279/1000\n",
            " - 8s - loss: 1.1969 - acc: 0.4908 - val_loss: 1.1892 - val_acc: 0.4712\n",
            "\n",
            "Epoch 00279: val_loss did not improve from 1.17905\n",
            "Epoch 280/1000\n",
            " - 8s - loss: 1.1995 - acc: 0.4882 - val_loss: 1.1932 - val_acc: 0.4709\n",
            "\n",
            "Epoch 00280: val_loss did not improve from 1.17905\n",
            "Epoch 281/1000\n",
            " - 8s - loss: 1.1956 - acc: 0.4888 - val_loss: 1.2018 - val_acc: 0.4681\n",
            "\n",
            "Epoch 00281: val_loss did not improve from 1.17905\n",
            "Epoch 282/1000\n",
            " - 8s - loss: 1.2010 - acc: 0.4883 - val_loss: 1.1923 - val_acc: 0.4754\n",
            "\n",
            "Epoch 00282: val_loss did not improve from 1.17905\n",
            "Epoch 283/1000\n",
            " - 8s - loss: 1.2000 - acc: 0.4863 - val_loss: 1.1799 - val_acc: 0.4759\n",
            "\n",
            "Epoch 00283: val_loss did not improve from 1.17905\n",
            "Epoch 284/1000\n",
            " - 8s - loss: 1.1972 - acc: 0.4900 - val_loss: 1.1851 - val_acc: 0.4738\n",
            "\n",
            "Epoch 00284: val_loss did not improve from 1.17905\n",
            "Epoch 285/1000\n",
            " - 8s - loss: 1.1999 - acc: 0.4906 - val_loss: 1.1888 - val_acc: 0.4690\n",
            "\n",
            "Epoch 00285: val_loss did not improve from 1.17905\n",
            "Epoch 286/1000\n",
            " - 8s - loss: 1.1894 - acc: 0.4911 - val_loss: 1.2240 - val_acc: 0.4480\n",
            "\n",
            "Epoch 00286: val_loss did not improve from 1.17905\n",
            "Epoch 287/1000\n",
            " - 8s - loss: 1.1973 - acc: 0.4880 - val_loss: 1.2148 - val_acc: 0.4496\n",
            "\n",
            "Epoch 00287: val_loss did not improve from 1.17905\n",
            "Epoch 288/1000\n",
            " - 8s - loss: 1.1886 - acc: 0.4944 - val_loss: 1.1995 - val_acc: 0.4638\n",
            "\n",
            "Epoch 00288: val_loss did not improve from 1.17905\n",
            "Epoch 289/1000\n",
            " - 8s - loss: 1.1892 - acc: 0.4939 - val_loss: 1.1806 - val_acc: 0.4823\n",
            "\n",
            "Epoch 00289: val_loss did not improve from 1.17905\n",
            "Epoch 290/1000\n",
            " - 8s - loss: 1.2029 - acc: 0.4869 - val_loss: 1.1725 - val_acc: 0.4905\n",
            "\n",
            "Epoch 00290: val_loss improved from 1.17905 to 1.17249, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 291/1000\n",
            " - 8s - loss: 1.1987 - acc: 0.4874 - val_loss: 1.1806 - val_acc: 0.4863\n",
            "\n",
            "Epoch 00291: val_loss did not improve from 1.17249\n",
            "Epoch 292/1000\n",
            " - 8s - loss: 1.1896 - acc: 0.5007 - val_loss: 1.1920 - val_acc: 0.4851\n",
            "\n",
            "Epoch 00292: val_loss did not improve from 1.17249\n",
            "Epoch 293/1000\n",
            " - 8s - loss: 1.1920 - acc: 0.4954 - val_loss: 1.1808 - val_acc: 0.4813\n",
            "\n",
            "Epoch 00293: val_loss did not improve from 1.17249\n",
            "Epoch 294/1000\n",
            " - 8s - loss: 1.1959 - acc: 0.4930 - val_loss: 1.1800 - val_acc: 0.4811\n",
            "\n",
            "Epoch 00294: val_loss did not improve from 1.17249\n",
            "Epoch 295/1000\n",
            " - 8s - loss: 1.1928 - acc: 0.4909 - val_loss: 1.1898 - val_acc: 0.4766\n",
            "\n",
            "Epoch 00295: val_loss did not improve from 1.17249\n",
            "Epoch 296/1000\n",
            " - 8s - loss: 1.1856 - acc: 0.4961 - val_loss: 1.1985 - val_acc: 0.4650\n",
            "\n",
            "Epoch 00296: val_loss did not improve from 1.17249\n",
            "Epoch 297/1000\n",
            " - 8s - loss: 1.1940 - acc: 0.4902 - val_loss: 1.1802 - val_acc: 0.4849\n",
            "\n",
            "Epoch 00297: val_loss did not improve from 1.17249\n",
            "Epoch 298/1000\n",
            " - 8s - loss: 1.2001 - acc: 0.4891 - val_loss: 1.1892 - val_acc: 0.4716\n",
            "\n",
            "Epoch 00298: val_loss did not improve from 1.17249\n",
            "Epoch 299/1000\n",
            " - 8s - loss: 1.1900 - acc: 0.4946 - val_loss: 1.1932 - val_acc: 0.4657\n",
            "\n",
            "Epoch 00299: val_loss did not improve from 1.17249\n",
            "Epoch 300/1000\n",
            " - 8s - loss: 1.1840 - acc: 0.4991 - val_loss: 1.1867 - val_acc: 0.4697\n",
            "\n",
            "Epoch 00300: val_loss did not improve from 1.17249\n",
            "Epoch 301/1000\n",
            " - 8s - loss: 1.1879 - acc: 0.4937 - val_loss: 1.1769 - val_acc: 0.4820\n",
            "\n",
            "Epoch 00301: val_loss did not improve from 1.17249\n",
            "Epoch 302/1000\n",
            " - 8s - loss: 1.1921 - acc: 0.4947 - val_loss: 1.1917 - val_acc: 0.4801\n",
            "\n",
            "Epoch 00302: val_loss did not improve from 1.17249\n",
            "Epoch 303/1000\n",
            " - 8s - loss: 1.2051 - acc: 0.4848 - val_loss: 1.1837 - val_acc: 0.4749\n",
            "\n",
            "Epoch 00303: val_loss did not improve from 1.17249\n",
            "Epoch 304/1000\n",
            " - 8s - loss: 1.1808 - acc: 0.5028 - val_loss: 1.1781 - val_acc: 0.4733\n",
            "\n",
            "Epoch 00304: val_loss did not improve from 1.17249\n",
            "Epoch 305/1000\n",
            " - 8s - loss: 1.1872 - acc: 0.4930 - val_loss: 1.1766 - val_acc: 0.4783\n",
            "\n",
            "Epoch 00305: val_loss did not improve from 1.17249\n",
            "Epoch 306/1000\n",
            " - 8s - loss: 1.1877 - acc: 0.4972 - val_loss: 1.2111 - val_acc: 0.4456\n",
            "\n",
            "Epoch 00306: val_loss did not improve from 1.17249\n",
            "Epoch 307/1000\n",
            " - 8s - loss: 1.1866 - acc: 0.4980 - val_loss: 1.2060 - val_acc: 0.4589\n",
            "\n",
            "Epoch 00307: val_loss did not improve from 1.17249\n",
            "Epoch 308/1000\n",
            " - 8s - loss: 1.1853 - acc: 0.4955 - val_loss: 1.1721 - val_acc: 0.4849\n",
            "\n",
            "Epoch 00308: val_loss improved from 1.17249 to 1.17206, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 309/1000\n",
            " - 8s - loss: 1.1864 - acc: 0.4996 - val_loss: 1.1830 - val_acc: 0.4735\n",
            "\n",
            "Epoch 00309: val_loss did not improve from 1.17206\n",
            "Epoch 310/1000\n",
            " - 8s - loss: 1.1822 - acc: 0.5004 - val_loss: 1.1753 - val_acc: 0.4865\n",
            "\n",
            "Epoch 00310: val_loss did not improve from 1.17206\n",
            "Epoch 311/1000\n",
            " - 8s - loss: 1.1860 - acc: 0.4962 - val_loss: 1.1698 - val_acc: 0.4794\n",
            "\n",
            "Epoch 00311: val_loss improved from 1.17206 to 1.16982, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 312/1000\n",
            " - 8s - loss: 1.1932 - acc: 0.4979 - val_loss: 1.1665 - val_acc: 0.4924\n",
            "\n",
            "Epoch 00312: val_loss improved from 1.16982 to 1.16652, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 313/1000\n",
            " - 8s - loss: 1.1823 - acc: 0.4991 - val_loss: 1.1822 - val_acc: 0.4660\n",
            "\n",
            "Epoch 00313: val_loss did not improve from 1.16652\n",
            "Epoch 314/1000\n",
            " - 8s - loss: 1.1833 - acc: 0.5032 - val_loss: 1.1714 - val_acc: 0.4875\n",
            "\n",
            "Epoch 00314: val_loss did not improve from 1.16652\n",
            "Epoch 315/1000\n",
            " - 8s - loss: 1.1840 - acc: 0.4988 - val_loss: 1.1876 - val_acc: 0.4629\n",
            "\n",
            "Epoch 00315: val_loss did not improve from 1.16652\n",
            "Epoch 316/1000\n",
            " - 8s - loss: 1.1908 - acc: 0.4951 - val_loss: 1.2013 - val_acc: 0.4563\n",
            "\n",
            "Epoch 00316: val_loss did not improve from 1.16652\n",
            "Epoch 317/1000\n",
            " - 8s - loss: 1.1819 - acc: 0.5018 - val_loss: 1.1796 - val_acc: 0.4709\n",
            "\n",
            "Epoch 00317: val_loss did not improve from 1.16652\n",
            "Epoch 318/1000\n",
            " - 8s - loss: 1.1898 - acc: 0.4983 - val_loss: 1.1759 - val_acc: 0.4757\n",
            "\n",
            "Epoch 00318: val_loss did not improve from 1.16652\n",
            "Epoch 319/1000\n",
            " - 8s - loss: 1.1877 - acc: 0.5002 - val_loss: 1.2052 - val_acc: 0.4530\n",
            "\n",
            "Epoch 00319: val_loss did not improve from 1.16652\n",
            "Epoch 320/1000\n",
            " - 8s - loss: 1.1878 - acc: 0.4996 - val_loss: 1.1680 - val_acc: 0.4868\n",
            "\n",
            "Epoch 00320: val_loss did not improve from 1.16652\n",
            "Epoch 321/1000\n",
            " - 8s - loss: 1.1872 - acc: 0.4989 - val_loss: 1.1906 - val_acc: 0.4624\n",
            "\n",
            "Epoch 00321: val_loss did not improve from 1.16652\n",
            "Epoch 322/1000\n",
            " - 8s - loss: 1.1808 - acc: 0.5003 - val_loss: 1.1598 - val_acc: 0.5000\n",
            "\n",
            "Epoch 00322: val_loss improved from 1.16652 to 1.15977, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 323/1000\n",
            " - 8s - loss: 1.1826 - acc: 0.5017 - val_loss: 1.1831 - val_acc: 0.4645\n",
            "\n",
            "Epoch 00323: val_loss did not improve from 1.15977\n",
            "Epoch 324/1000\n",
            " - 8s - loss: 1.1789 - acc: 0.5083 - val_loss: 1.1638 - val_acc: 0.4849\n",
            "\n",
            "Epoch 00324: val_loss did not improve from 1.15977\n",
            "Epoch 325/1000\n",
            " - 8s - loss: 1.1857 - acc: 0.5027 - val_loss: 1.1717 - val_acc: 0.4801\n",
            "\n",
            "Epoch 00325: val_loss did not improve from 1.15977\n",
            "Epoch 326/1000\n",
            " - 8s - loss: 1.1809 - acc: 0.5099 - val_loss: 1.1655 - val_acc: 0.4908\n",
            "\n",
            "Epoch 00326: val_loss did not improve from 1.15977\n",
            "Epoch 327/1000\n",
            " - 8s - loss: 1.1852 - acc: 0.4993 - val_loss: 1.1616 - val_acc: 0.5005\n",
            "\n",
            "Epoch 00327: val_loss did not improve from 1.15977\n",
            "Epoch 328/1000\n",
            " - 8s - loss: 1.1869 - acc: 0.5092 - val_loss: 1.1551 - val_acc: 0.4962\n",
            "\n",
            "Epoch 00328: val_loss improved from 1.15977 to 1.15510, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 329/1000\n",
            " - 8s - loss: 1.1844 - acc: 0.5024 - val_loss: 1.1940 - val_acc: 0.4600\n",
            "\n",
            "Epoch 00329: val_loss did not improve from 1.15510\n",
            "Epoch 330/1000\n",
            " - 8s - loss: 1.1879 - acc: 0.4996 - val_loss: 1.1748 - val_acc: 0.4851\n",
            "\n",
            "Epoch 00330: val_loss did not improve from 1.15510\n",
            "Epoch 331/1000\n",
            " - 8s - loss: 1.1783 - acc: 0.5028 - val_loss: 1.1805 - val_acc: 0.4693\n",
            "\n",
            "Epoch 00331: val_loss did not improve from 1.15510\n",
            "Epoch 332/1000\n",
            " - 8s - loss: 1.1844 - acc: 0.5063 - val_loss: 1.1607 - val_acc: 0.5002\n",
            "\n",
            "Epoch 00332: val_loss did not improve from 1.15510\n",
            "Epoch 333/1000\n",
            " - 8s - loss: 1.1772 - acc: 0.5089 - val_loss: 1.1697 - val_acc: 0.4877\n",
            "\n",
            "Epoch 00333: val_loss did not improve from 1.15510\n",
            "Epoch 334/1000\n",
            " - 8s - loss: 1.1847 - acc: 0.5047 - val_loss: 1.1745 - val_acc: 0.4846\n",
            "\n",
            "Epoch 00334: val_loss did not improve from 1.15510\n",
            "Epoch 335/1000\n",
            " - 8s - loss: 1.1742 - acc: 0.5087 - val_loss: 1.1592 - val_acc: 0.5111\n",
            "\n",
            "Epoch 00335: val_loss did not improve from 1.15510\n",
            "Epoch 336/1000\n",
            " - 8s - loss: 1.1821 - acc: 0.5057 - val_loss: 1.1922 - val_acc: 0.4759\n",
            "\n",
            "Epoch 00336: val_loss did not improve from 1.15510\n",
            "Epoch 337/1000\n",
            " - 8s - loss: 1.1755 - acc: 0.5039 - val_loss: 1.2024 - val_acc: 0.4608\n",
            "\n",
            "Epoch 00337: val_loss did not improve from 1.15510\n",
            "Epoch 338/1000\n",
            " - 8s - loss: 1.1721 - acc: 0.5126 - val_loss: 1.1615 - val_acc: 0.4976\n",
            "\n",
            "Epoch 00338: val_loss did not improve from 1.15510\n",
            "Epoch 339/1000\n",
            " - 8s - loss: 1.1777 - acc: 0.5137 - val_loss: 1.1707 - val_acc: 0.4884\n",
            "\n",
            "Epoch 00339: val_loss did not improve from 1.15510\n",
            "Epoch 340/1000\n",
            " - 8s - loss: 1.1759 - acc: 0.5096 - val_loss: 1.1724 - val_acc: 0.4924\n",
            "\n",
            "Epoch 00340: val_loss did not improve from 1.15510\n",
            "Epoch 341/1000\n",
            " - 8s - loss: 1.1736 - acc: 0.5089 - val_loss: 1.1668 - val_acc: 0.4913\n",
            "\n",
            "Epoch 00341: val_loss did not improve from 1.15510\n",
            "Epoch 342/1000\n",
            " - 8s - loss: 1.1724 - acc: 0.5155 - val_loss: 1.1679 - val_acc: 0.4903\n",
            "\n",
            "Epoch 00342: val_loss did not improve from 1.15510\n",
            "Epoch 343/1000\n",
            " - 8s - loss: 1.1824 - acc: 0.5031 - val_loss: 1.1639 - val_acc: 0.5000\n",
            "\n",
            "Epoch 00343: val_loss did not improve from 1.15510\n",
            "Epoch 344/1000\n",
            " - 8s - loss: 1.1737 - acc: 0.5080 - val_loss: 1.1700 - val_acc: 0.4877\n",
            "\n",
            "Epoch 00344: val_loss did not improve from 1.15510\n",
            "Epoch 345/1000\n",
            " - 8s - loss: 1.1735 - acc: 0.5108 - val_loss: 1.1555 - val_acc: 0.5028\n",
            "\n",
            "Epoch 00345: val_loss did not improve from 1.15510\n",
            "Epoch 346/1000\n",
            " - 8s - loss: 1.1739 - acc: 0.5124 - val_loss: 1.1570 - val_acc: 0.5017\n",
            "\n",
            "Epoch 00346: val_loss did not improve from 1.15510\n",
            "Epoch 347/1000\n",
            " - 8s - loss: 1.1735 - acc: 0.5125 - val_loss: 1.1697 - val_acc: 0.4861\n",
            "\n",
            "Epoch 00347: val_loss did not improve from 1.15510\n",
            "Epoch 348/1000\n",
            " - 8s - loss: 1.1765 - acc: 0.5087 - val_loss: 1.1586 - val_acc: 0.5038\n",
            "\n",
            "Epoch 00348: val_loss did not improve from 1.15510\n",
            "Epoch 349/1000\n",
            " - 8s - loss: 1.1668 - acc: 0.5170 - val_loss: 1.1599 - val_acc: 0.4891\n",
            "\n",
            "Epoch 00349: val_loss did not improve from 1.15510\n",
            "Epoch 350/1000\n",
            " - 8s - loss: 1.1706 - acc: 0.5116 - val_loss: 1.1662 - val_acc: 0.4901\n",
            "\n",
            "Epoch 00350: val_loss did not improve from 1.15510\n",
            "Epoch 351/1000\n",
            " - 8s - loss: 1.1631 - acc: 0.5177 - val_loss: 1.1559 - val_acc: 0.4969\n",
            "\n",
            "Epoch 00351: val_loss did not improve from 1.15510\n",
            "Epoch 352/1000\n",
            " - 8s - loss: 1.1764 - acc: 0.5092 - val_loss: 1.1670 - val_acc: 0.4827\n",
            "\n",
            "Epoch 00352: val_loss did not improve from 1.15510\n",
            "Epoch 353/1000\n",
            " - 8s - loss: 1.1692 - acc: 0.5153 - val_loss: 1.1748 - val_acc: 0.4804\n",
            "\n",
            "Epoch 00353: val_loss did not improve from 1.15510\n",
            "Epoch 354/1000\n",
            " - 8s - loss: 1.1801 - acc: 0.5078 - val_loss: 1.1628 - val_acc: 0.4936\n",
            "\n",
            "Epoch 00354: val_loss did not improve from 1.15510\n",
            "Epoch 355/1000\n",
            " - 8s - loss: 1.1746 - acc: 0.5129 - val_loss: 1.1496 - val_acc: 0.5031\n",
            "\n",
            "Epoch 00355: val_loss improved from 1.15510 to 1.14963, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 356/1000\n",
            " - 8s - loss: 1.1827 - acc: 0.5100 - val_loss: 1.1682 - val_acc: 0.4896\n",
            "\n",
            "Epoch 00356: val_loss did not improve from 1.14963\n",
            "Epoch 357/1000\n",
            " - 8s - loss: 1.1622 - acc: 0.5165 - val_loss: 1.1474 - val_acc: 0.5085\n",
            "\n",
            "Epoch 00357: val_loss improved from 1.14963 to 1.14738, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 358/1000\n",
            " - 8s - loss: 1.1682 - acc: 0.5185 - val_loss: 1.1483 - val_acc: 0.5047\n",
            "\n",
            "Epoch 00358: val_loss did not improve from 1.14738\n",
            "Epoch 359/1000\n",
            " - 8s - loss: 1.1628 - acc: 0.5249 - val_loss: 1.1408 - val_acc: 0.5170\n",
            "\n",
            "Epoch 00359: val_loss improved from 1.14738 to 1.14078, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 360/1000\n",
            " - 8s - loss: 1.1663 - acc: 0.5196 - val_loss: 1.1667 - val_acc: 0.4960\n",
            "\n",
            "Epoch 00360: val_loss did not improve from 1.14078\n",
            "Epoch 361/1000\n",
            " - 8s - loss: 1.1660 - acc: 0.5151 - val_loss: 1.1881 - val_acc: 0.4688\n",
            "\n",
            "Epoch 00361: val_loss did not improve from 1.14078\n",
            "Epoch 362/1000\n",
            " - 8s - loss: 1.1819 - acc: 0.5121 - val_loss: 1.1472 - val_acc: 0.5128\n",
            "\n",
            "Epoch 00362: val_loss did not improve from 1.14078\n",
            "Epoch 363/1000\n",
            " - 8s - loss: 1.1653 - acc: 0.5204 - val_loss: 1.1406 - val_acc: 0.5144\n",
            "\n",
            "Epoch 00363: val_loss improved from 1.14078 to 1.14055, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 364/1000\n",
            " - 8s - loss: 1.1688 - acc: 0.5191 - val_loss: 1.1475 - val_acc: 0.5222\n",
            "\n",
            "Epoch 00364: val_loss did not improve from 1.14055\n",
            "Epoch 365/1000\n",
            " - 8s - loss: 1.1820 - acc: 0.5090 - val_loss: 1.1523 - val_acc: 0.5099\n",
            "\n",
            "Epoch 00365: val_loss did not improve from 1.14055\n",
            "Epoch 366/1000\n",
            " - 8s - loss: 1.1704 - acc: 0.5192 - val_loss: 1.1533 - val_acc: 0.5009\n",
            "\n",
            "Epoch 00366: val_loss did not improve from 1.14055\n",
            "Epoch 367/1000\n",
            " - 8s - loss: 1.1695 - acc: 0.5149 - val_loss: 1.1491 - val_acc: 0.5078\n",
            "\n",
            "Epoch 00367: val_loss did not improve from 1.14055\n",
            "Epoch 368/1000\n",
            " - 8s - loss: 1.1584 - acc: 0.5254 - val_loss: 1.1538 - val_acc: 0.4936\n",
            "\n",
            "Epoch 00368: val_loss did not improve from 1.14055\n",
            "Epoch 369/1000\n",
            " - 8s - loss: 1.1677 - acc: 0.5222 - val_loss: 1.1495 - val_acc: 0.5170\n",
            "\n",
            "Epoch 00369: val_loss did not improve from 1.14055\n",
            "Epoch 370/1000\n",
            " - 8s - loss: 1.1743 - acc: 0.5115 - val_loss: 1.1403 - val_acc: 0.5158\n",
            "\n",
            "Epoch 00370: val_loss improved from 1.14055 to 1.14027, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 371/1000\n",
            " - 8s - loss: 1.1658 - acc: 0.5179 - val_loss: 1.1402 - val_acc: 0.5284\n",
            "\n",
            "Epoch 00371: val_loss improved from 1.14027 to 1.14024, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 372/1000\n",
            " - 8s - loss: 1.1668 - acc: 0.5242 - val_loss: 1.1422 - val_acc: 0.5139\n",
            "\n",
            "Epoch 00372: val_loss did not improve from 1.14024\n",
            "Epoch 373/1000\n",
            " - 8s - loss: 1.1590 - acc: 0.5242 - val_loss: 1.1519 - val_acc: 0.5050\n",
            "\n",
            "Epoch 00373: val_loss did not improve from 1.14024\n",
            "Epoch 374/1000\n",
            " - 8s - loss: 1.1638 - acc: 0.5219 - val_loss: 1.1704 - val_acc: 0.4764\n",
            "\n",
            "Epoch 00374: val_loss did not improve from 1.14024\n",
            "Epoch 375/1000\n",
            " - 8s - loss: 1.1610 - acc: 0.5249 - val_loss: 1.1598 - val_acc: 0.4908\n",
            "\n",
            "Epoch 00375: val_loss did not improve from 1.14024\n",
            "Epoch 376/1000\n",
            " - 8s - loss: 1.1618 - acc: 0.5242 - val_loss: 1.1428 - val_acc: 0.5142\n",
            "\n",
            "Epoch 00376: val_loss did not improve from 1.14024\n",
            "Epoch 377/1000\n",
            " - 8s - loss: 1.1629 - acc: 0.5268 - val_loss: 1.1456 - val_acc: 0.5161\n",
            "\n",
            "Epoch 00377: val_loss did not improve from 1.14024\n",
            "Epoch 378/1000\n",
            " - 8s - loss: 1.1640 - acc: 0.5210 - val_loss: 1.1336 - val_acc: 0.5213\n",
            "\n",
            "Epoch 00378: val_loss improved from 1.14024 to 1.13358, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 379/1000\n",
            " - 8s - loss: 1.1591 - acc: 0.5270 - val_loss: 1.1649 - val_acc: 0.5069\n",
            "\n",
            "Epoch 00379: val_loss did not improve from 1.13358\n",
            "Epoch 380/1000\n",
            " - 8s - loss: 1.1625 - acc: 0.5226 - val_loss: 1.1452 - val_acc: 0.5052\n",
            "\n",
            "Epoch 00380: val_loss did not improve from 1.13358\n",
            "Epoch 381/1000\n",
            " - 8s - loss: 1.1637 - acc: 0.5218 - val_loss: 1.1457 - val_acc: 0.5144\n",
            "\n",
            "Epoch 00381: val_loss did not improve from 1.13358\n",
            "Epoch 382/1000\n",
            " - 8s - loss: 1.1636 - acc: 0.5180 - val_loss: 1.1420 - val_acc: 0.5099\n",
            "\n",
            "Epoch 00382: val_loss did not improve from 1.13358\n",
            "Epoch 383/1000\n",
            " - 8s - loss: 1.1543 - acc: 0.5225 - val_loss: 1.1228 - val_acc: 0.5317\n",
            "\n",
            "Epoch 00383: val_loss improved from 1.13358 to 1.12280, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 384/1000\n",
            " - 8s - loss: 1.1586 - acc: 0.5284 - val_loss: 1.1798 - val_acc: 0.4832\n",
            "\n",
            "Epoch 00384: val_loss did not improve from 1.12280\n",
            "Epoch 385/1000\n",
            " - 8s - loss: 1.1591 - acc: 0.5269 - val_loss: 1.1478 - val_acc: 0.5069\n",
            "\n",
            "Epoch 00385: val_loss did not improve from 1.12280\n",
            "Epoch 386/1000\n",
            " - 8s - loss: 1.1650 - acc: 0.5226 - val_loss: 1.1388 - val_acc: 0.5243\n",
            "\n",
            "Epoch 00386: val_loss did not improve from 1.12280\n",
            "Epoch 387/1000\n",
            " - 8s - loss: 1.1606 - acc: 0.5248 - val_loss: 1.1383 - val_acc: 0.5333\n",
            "\n",
            "Epoch 00387: val_loss did not improve from 1.12280\n",
            "Epoch 388/1000\n",
            " - 8s - loss: 1.1608 - acc: 0.5249 - val_loss: 1.1404 - val_acc: 0.5130\n",
            "\n",
            "Epoch 00388: val_loss did not improve from 1.12280\n",
            "Epoch 389/1000\n",
            " - 8s - loss: 1.1625 - acc: 0.5231 - val_loss: 1.1633 - val_acc: 0.4896\n",
            "\n",
            "Epoch 00389: val_loss did not improve from 1.12280\n",
            "Epoch 390/1000\n",
            " - 8s - loss: 1.1642 - acc: 0.5255 - val_loss: 1.1409 - val_acc: 0.5173\n",
            "\n",
            "Epoch 00390: val_loss did not improve from 1.12280\n",
            "Epoch 391/1000\n",
            " - 8s - loss: 1.1638 - acc: 0.5267 - val_loss: 1.1451 - val_acc: 0.5019\n",
            "\n",
            "Epoch 00391: val_loss did not improve from 1.12280\n",
            "Epoch 392/1000\n",
            " - 8s - loss: 1.1528 - acc: 0.5320 - val_loss: 1.1466 - val_acc: 0.5090\n",
            "\n",
            "Epoch 00392: val_loss did not improve from 1.12280\n",
            "Epoch 393/1000\n",
            " - 8s - loss: 1.1500 - acc: 0.5249 - val_loss: 1.1283 - val_acc: 0.5274\n",
            "\n",
            "Epoch 00393: val_loss did not improve from 1.12280\n",
            "Epoch 394/1000\n",
            " - 8s - loss: 1.1535 - acc: 0.5306 - val_loss: 1.1373 - val_acc: 0.5288\n",
            "\n",
            "Epoch 00394: val_loss did not improve from 1.12280\n",
            "Epoch 395/1000\n",
            " - 8s - loss: 1.1524 - acc: 0.5329 - val_loss: 1.1452 - val_acc: 0.5121\n",
            "\n",
            "Epoch 00395: val_loss did not improve from 1.12280\n",
            "Epoch 396/1000\n",
            " - 8s - loss: 1.1523 - acc: 0.5349 - val_loss: 1.1647 - val_acc: 0.4927\n",
            "\n",
            "Epoch 00396: val_loss did not improve from 1.12280\n",
            "Epoch 397/1000\n",
            " - 8s - loss: 1.1596 - acc: 0.5246 - val_loss: 1.1468 - val_acc: 0.5047\n",
            "\n",
            "Epoch 00397: val_loss did not improve from 1.12280\n",
            "Epoch 398/1000\n",
            " - 8s - loss: 1.1477 - acc: 0.5329 - val_loss: 1.1323 - val_acc: 0.5281\n",
            "\n",
            "Epoch 00398: val_loss did not improve from 1.12280\n",
            "Epoch 399/1000\n",
            " - 8s - loss: 1.1512 - acc: 0.5367 - val_loss: 1.1498 - val_acc: 0.5066\n",
            "\n",
            "Epoch 00399: val_loss did not improve from 1.12280\n",
            "Epoch 400/1000\n",
            " - 8s - loss: 1.1541 - acc: 0.5299 - val_loss: 1.1325 - val_acc: 0.5255\n",
            "\n",
            "Epoch 00400: val_loss did not improve from 1.12280\n",
            "Epoch 401/1000\n",
            " - 8s - loss: 1.1517 - acc: 0.5277 - val_loss: 1.1355 - val_acc: 0.5139\n",
            "\n",
            "Epoch 00401: val_loss did not improve from 1.12280\n",
            "Epoch 402/1000\n",
            " - 8s - loss: 1.1543 - acc: 0.5296 - val_loss: 1.1348 - val_acc: 0.5158\n",
            "\n",
            "Epoch 00402: val_loss did not improve from 1.12280\n",
            "Epoch 403/1000\n",
            " - 8s - loss: 1.1493 - acc: 0.5323 - val_loss: 1.1307 - val_acc: 0.5262\n",
            "\n",
            "Epoch 00403: val_loss did not improve from 1.12280\n",
            "Epoch 404/1000\n",
            " - 8s - loss: 1.1562 - acc: 0.5255 - val_loss: 1.1295 - val_acc: 0.5234\n",
            "\n",
            "Epoch 00404: val_loss did not improve from 1.12280\n",
            "Epoch 405/1000\n",
            " - 8s - loss: 1.1587 - acc: 0.5310 - val_loss: 1.1450 - val_acc: 0.5104\n",
            "\n",
            "Epoch 00405: val_loss did not improve from 1.12280\n",
            "Epoch 406/1000\n",
            " - 8s - loss: 1.1460 - acc: 0.5382 - val_loss: 1.1310 - val_acc: 0.5194\n",
            "\n",
            "Epoch 00406: val_loss did not improve from 1.12280\n",
            "Epoch 407/1000\n",
            " - 8s - loss: 1.1515 - acc: 0.5346 - val_loss: 1.1226 - val_acc: 0.5312\n",
            "\n",
            "Epoch 00407: val_loss improved from 1.12280 to 1.12256, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 408/1000\n",
            " - 8s - loss: 1.1497 - acc: 0.5381 - val_loss: 1.1357 - val_acc: 0.5189\n",
            "\n",
            "Epoch 00408: val_loss did not improve from 1.12256\n",
            "Epoch 409/1000\n",
            " - 8s - loss: 1.1627 - acc: 0.5246 - val_loss: 1.1453 - val_acc: 0.5104\n",
            "\n",
            "Epoch 00409: val_loss did not improve from 1.12256\n",
            "Epoch 410/1000\n",
            " - 8s - loss: 1.1586 - acc: 0.5280 - val_loss: 1.1505 - val_acc: 0.5021\n",
            "\n",
            "Epoch 00410: val_loss did not improve from 1.12256\n",
            "Epoch 411/1000\n",
            " - 8s - loss: 1.1485 - acc: 0.5370 - val_loss: 1.1229 - val_acc: 0.5258\n",
            "\n",
            "Epoch 00411: val_loss did not improve from 1.12256\n",
            "Epoch 412/1000\n",
            " - 8s - loss: 1.1499 - acc: 0.5354 - val_loss: 1.1204 - val_acc: 0.5317\n",
            "\n",
            "Epoch 00412: val_loss improved from 1.12256 to 1.12037, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 413/1000\n",
            " - 8s - loss: 1.1432 - acc: 0.5400 - val_loss: 1.1140 - val_acc: 0.5324\n",
            "\n",
            "Epoch 00413: val_loss improved from 1.12037 to 1.11397, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 414/1000\n",
            " - 8s - loss: 1.1401 - acc: 0.5405 - val_loss: 1.1421 - val_acc: 0.5078\n",
            "\n",
            "Epoch 00414: val_loss did not improve from 1.11397\n",
            "Epoch 415/1000\n",
            " - 8s - loss: 1.1412 - acc: 0.5382 - val_loss: 1.1247 - val_acc: 0.5345\n",
            "\n",
            "Epoch 00415: val_loss did not improve from 1.11397\n",
            "Epoch 416/1000\n",
            " - 8s - loss: 1.1404 - acc: 0.5376 - val_loss: 1.1368 - val_acc: 0.5199\n",
            "\n",
            "Epoch 00416: val_loss did not improve from 1.11397\n",
            "Epoch 417/1000\n",
            " - 8s - loss: 1.1411 - acc: 0.5437 - val_loss: 1.1188 - val_acc: 0.5352\n",
            "\n",
            "Epoch 00417: val_loss did not improve from 1.11397\n",
            "Epoch 418/1000\n",
            " - 8s - loss: 1.1470 - acc: 0.5391 - val_loss: 1.1207 - val_acc: 0.5369\n",
            "\n",
            "Epoch 00418: val_loss did not improve from 1.11397\n",
            "Epoch 419/1000\n",
            " - 8s - loss: 1.1410 - acc: 0.5399 - val_loss: 1.1307 - val_acc: 0.5147\n",
            "\n",
            "Epoch 00419: val_loss did not improve from 1.11397\n",
            "Epoch 420/1000\n",
            " - 8s - loss: 1.1399 - acc: 0.5475 - val_loss: 1.1191 - val_acc: 0.5454\n",
            "\n",
            "Epoch 00420: val_loss did not improve from 1.11397\n",
            "Epoch 421/1000\n",
            " - 8s - loss: 1.1443 - acc: 0.5389 - val_loss: 1.1282 - val_acc: 0.5362\n",
            "\n",
            "Epoch 00421: val_loss did not improve from 1.11397\n",
            "Epoch 422/1000\n",
            " - 8s - loss: 1.1362 - acc: 0.5474 - val_loss: 1.1199 - val_acc: 0.5265\n",
            "\n",
            "Epoch 00422: val_loss did not improve from 1.11397\n",
            "Epoch 423/1000\n",
            " - 8s - loss: 1.1358 - acc: 0.5406 - val_loss: 1.1552 - val_acc: 0.5121\n",
            "\n",
            "Epoch 00423: val_loss did not improve from 1.11397\n",
            "Epoch 424/1000\n",
            " - 8s - loss: 1.1414 - acc: 0.5431 - val_loss: 1.1177 - val_acc: 0.5303\n",
            "\n",
            "Epoch 00424: val_loss did not improve from 1.11397\n",
            "Epoch 425/1000\n",
            " - 8s - loss: 1.1422 - acc: 0.5400 - val_loss: 1.1101 - val_acc: 0.5416\n",
            "\n",
            "Epoch 00425: val_loss improved from 1.11397 to 1.11010, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 426/1000\n",
            " - 8s - loss: 1.1373 - acc: 0.5413 - val_loss: 1.1144 - val_acc: 0.5326\n",
            "\n",
            "Epoch 00426: val_loss did not improve from 1.11010\n",
            "Epoch 427/1000\n",
            " - 8s - loss: 1.1290 - acc: 0.5498 - val_loss: 1.1098 - val_acc: 0.5496\n",
            "\n",
            "Epoch 00427: val_loss improved from 1.11010 to 1.10975, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 428/1000\n",
            " - 8s - loss: 1.1412 - acc: 0.5424 - val_loss: 1.1323 - val_acc: 0.5239\n",
            "\n",
            "Epoch 00428: val_loss did not improve from 1.10975\n",
            "Epoch 429/1000\n",
            " - 8s - loss: 1.1389 - acc: 0.5334 - val_loss: 1.1149 - val_acc: 0.5482\n",
            "\n",
            "Epoch 00429: val_loss did not improve from 1.10975\n",
            "Epoch 430/1000\n",
            " - 8s - loss: 1.1395 - acc: 0.5441 - val_loss: 1.1189 - val_acc: 0.5459\n",
            "\n",
            "Epoch 00430: val_loss did not improve from 1.10975\n",
            "Epoch 431/1000\n",
            " - 8s - loss: 1.1399 - acc: 0.5409 - val_loss: 1.1109 - val_acc: 0.5480\n",
            "\n",
            "Epoch 00431: val_loss did not improve from 1.10975\n",
            "Epoch 432/1000\n",
            " - 8s - loss: 1.1420 - acc: 0.5381 - val_loss: 1.1178 - val_acc: 0.5272\n",
            "\n",
            "Epoch 00432: val_loss did not improve from 1.10975\n",
            "Epoch 433/1000\n",
            " - 8s - loss: 1.1372 - acc: 0.5397 - val_loss: 1.1164 - val_acc: 0.5501\n",
            "\n",
            "Epoch 00433: val_loss did not improve from 1.10975\n",
            "Epoch 434/1000\n",
            " - 8s - loss: 1.1408 - acc: 0.5407 - val_loss: 1.0969 - val_acc: 0.5626\n",
            "\n",
            "Epoch 00434: val_loss improved from 1.10975 to 1.09689, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 435/1000\n",
            " - 8s - loss: 1.1327 - acc: 0.5439 - val_loss: 1.1119 - val_acc: 0.5331\n",
            "\n",
            "Epoch 00435: val_loss did not improve from 1.09689\n",
            "Epoch 436/1000\n",
            " - 8s - loss: 1.1400 - acc: 0.5426 - val_loss: 1.0973 - val_acc: 0.5629\n",
            "\n",
            "Epoch 00436: val_loss did not improve from 1.09689\n",
            "Epoch 437/1000\n",
            " - 8s - loss: 1.1349 - acc: 0.5499 - val_loss: 1.1031 - val_acc: 0.5447\n",
            "\n",
            "Epoch 00437: val_loss did not improve from 1.09689\n",
            "Epoch 438/1000\n",
            " - 8s - loss: 1.1351 - acc: 0.5462 - val_loss: 1.1120 - val_acc: 0.5487\n",
            "\n",
            "Epoch 00438: val_loss did not improve from 1.09689\n",
            "Epoch 439/1000\n",
            " - 8s - loss: 1.1350 - acc: 0.5453 - val_loss: 1.1132 - val_acc: 0.5329\n",
            "\n",
            "Epoch 00439: val_loss did not improve from 1.09689\n",
            "Epoch 440/1000\n",
            " - 8s - loss: 1.1340 - acc: 0.5440 - val_loss: 1.1072 - val_acc: 0.5444\n",
            "\n",
            "Epoch 00440: val_loss did not improve from 1.09689\n",
            "Epoch 441/1000\n",
            " - 8s - loss: 1.1310 - acc: 0.5495 - val_loss: 1.1139 - val_acc: 0.5534\n",
            "\n",
            "Epoch 00441: val_loss did not improve from 1.09689\n",
            "Epoch 442/1000\n",
            " - 8s - loss: 1.1257 - acc: 0.5455 - val_loss: 1.0945 - val_acc: 0.5570\n",
            "\n",
            "Epoch 00442: val_loss improved from 1.09689 to 1.09453, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 443/1000\n",
            " - 8s - loss: 1.1270 - acc: 0.5477 - val_loss: 1.1143 - val_acc: 0.5447\n",
            "\n",
            "Epoch 00443: val_loss did not improve from 1.09453\n",
            "Epoch 444/1000\n",
            " - 8s - loss: 1.1339 - acc: 0.5458 - val_loss: 1.1100 - val_acc: 0.5449\n",
            "\n",
            "Epoch 00444: val_loss did not improve from 1.09453\n",
            "Epoch 445/1000\n",
            " - 8s - loss: 1.1242 - acc: 0.5537 - val_loss: 1.1184 - val_acc: 0.5407\n",
            "\n",
            "Epoch 00445: val_loss did not improve from 1.09453\n",
            "Epoch 446/1000\n",
            " - 8s - loss: 1.1308 - acc: 0.5465 - val_loss: 1.1024 - val_acc: 0.5489\n",
            "\n",
            "Epoch 00446: val_loss did not improve from 1.09453\n",
            "Epoch 447/1000\n",
            " - 8s - loss: 1.1204 - acc: 0.5577 - val_loss: 1.1070 - val_acc: 0.5518\n",
            "\n",
            "Epoch 00447: val_loss did not improve from 1.09453\n",
            "Epoch 448/1000\n",
            " - 8s - loss: 1.1341 - acc: 0.5463 - val_loss: 1.1040 - val_acc: 0.5416\n",
            "\n",
            "Epoch 00448: val_loss did not improve from 1.09453\n",
            "Epoch 449/1000\n",
            " - 8s - loss: 1.1261 - acc: 0.5519 - val_loss: 1.1085 - val_acc: 0.5492\n",
            "\n",
            "Epoch 00449: val_loss did not improve from 1.09453\n",
            "Epoch 450/1000\n",
            " - 8s - loss: 1.1345 - acc: 0.5488 - val_loss: 1.1084 - val_acc: 0.5520\n",
            "\n",
            "Epoch 00450: val_loss did not improve from 1.09453\n",
            "Epoch 451/1000\n",
            " - 8s - loss: 1.1294 - acc: 0.5500 - val_loss: 1.1138 - val_acc: 0.5388\n",
            "\n",
            "Epoch 00451: val_loss did not improve from 1.09453\n",
            "Epoch 452/1000\n",
            " - 8s - loss: 1.1346 - acc: 0.5491 - val_loss: 1.0978 - val_acc: 0.5589\n",
            "\n",
            "Epoch 00452: val_loss did not improve from 1.09453\n",
            "Epoch 453/1000\n",
            " - 8s - loss: 1.1198 - acc: 0.5586 - val_loss: 1.0921 - val_acc: 0.5530\n",
            "\n",
            "Epoch 00453: val_loss improved from 1.09453 to 1.09213, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 454/1000\n",
            " - 8s - loss: 1.1236 - acc: 0.5499 - val_loss: 1.1071 - val_acc: 0.5388\n",
            "\n",
            "Epoch 00454: val_loss did not improve from 1.09213\n",
            "Epoch 455/1000\n",
            " - 8s - loss: 1.1363 - acc: 0.5484 - val_loss: 1.0930 - val_acc: 0.5579\n",
            "\n",
            "Epoch 00455: val_loss did not improve from 1.09213\n",
            "Epoch 456/1000\n",
            " - 8s - loss: 1.1202 - acc: 0.5536 - val_loss: 1.0898 - val_acc: 0.5579\n",
            "\n",
            "Epoch 00456: val_loss improved from 1.09213 to 1.08976, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 457/1000\n",
            " - 8s - loss: 1.1192 - acc: 0.5560 - val_loss: 1.1020 - val_acc: 0.5482\n",
            "\n",
            "Epoch 00457: val_loss did not improve from 1.08976\n",
            "Epoch 458/1000\n",
            " - 8s - loss: 1.1184 - acc: 0.5561 - val_loss: 1.1033 - val_acc: 0.5461\n",
            "\n",
            "Epoch 00458: val_loss did not improve from 1.08976\n",
            "Epoch 459/1000\n",
            " - 8s - loss: 1.1258 - acc: 0.5553 - val_loss: 1.0968 - val_acc: 0.5551\n",
            "\n",
            "Epoch 00459: val_loss did not improve from 1.08976\n",
            "Epoch 460/1000\n",
            " - 8s - loss: 1.1159 - acc: 0.5535 - val_loss: 1.0913 - val_acc: 0.5537\n",
            "\n",
            "Epoch 00460: val_loss did not improve from 1.08976\n",
            "Epoch 461/1000\n",
            " - 8s - loss: 1.1201 - acc: 0.5595 - val_loss: 1.0978 - val_acc: 0.5567\n",
            "\n",
            "Epoch 00461: val_loss did not improve from 1.08976\n",
            "Epoch 462/1000\n",
            " - 8s - loss: 1.1189 - acc: 0.5564 - val_loss: 1.0912 - val_acc: 0.5530\n",
            "\n",
            "Epoch 00462: val_loss did not improve from 1.08976\n",
            "Epoch 463/1000\n",
            " - 8s - loss: 1.1149 - acc: 0.5597 - val_loss: 1.0956 - val_acc: 0.5553\n",
            "\n",
            "Epoch 00463: val_loss did not improve from 1.08976\n",
            "Epoch 464/1000\n",
            " - 8s - loss: 1.1251 - acc: 0.5556 - val_loss: 1.0970 - val_acc: 0.5539\n",
            "\n",
            "Epoch 00464: val_loss did not improve from 1.08976\n",
            "Epoch 465/1000\n",
            " - 8s - loss: 1.1290 - acc: 0.5491 - val_loss: 1.1029 - val_acc: 0.5442\n",
            "\n",
            "Epoch 00465: val_loss did not improve from 1.08976\n",
            "Epoch 466/1000\n",
            " - 8s - loss: 1.1142 - acc: 0.5575 - val_loss: 1.1004 - val_acc: 0.5522\n",
            "\n",
            "Epoch 00466: val_loss did not improve from 1.08976\n",
            "Epoch 467/1000\n",
            " - 8s - loss: 1.1261 - acc: 0.5517 - val_loss: 1.1063 - val_acc: 0.5480\n",
            "\n",
            "Epoch 00467: val_loss did not improve from 1.08976\n",
            "Epoch 468/1000\n",
            " - 8s - loss: 1.1171 - acc: 0.5542 - val_loss: 1.0873 - val_acc: 0.5615\n",
            "\n",
            "Epoch 00468: val_loss improved from 1.08976 to 1.08728, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 469/1000\n",
            " - 8s - loss: 1.1206 - acc: 0.5519 - val_loss: 1.0992 - val_acc: 0.5513\n",
            "\n",
            "Epoch 00469: val_loss did not improve from 1.08728\n",
            "Epoch 470/1000\n",
            " - 8s - loss: 1.1218 - acc: 0.5566 - val_loss: 1.1034 - val_acc: 0.5485\n",
            "\n",
            "Epoch 00470: val_loss did not improve from 1.08728\n",
            "Epoch 471/1000\n",
            " - 8s - loss: 1.1159 - acc: 0.5594 - val_loss: 1.0838 - val_acc: 0.5553\n",
            "\n",
            "Epoch 00471: val_loss improved from 1.08728 to 1.08376, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 472/1000\n",
            " - 8s - loss: 1.1137 - acc: 0.5590 - val_loss: 1.0961 - val_acc: 0.5546\n",
            "\n",
            "Epoch 00472: val_loss did not improve from 1.08376\n",
            "Epoch 473/1000\n",
            " - 8s - loss: 1.1100 - acc: 0.5634 - val_loss: 1.1097 - val_acc: 0.5530\n",
            "\n",
            "Epoch 00473: val_loss did not improve from 1.08376\n",
            "Epoch 474/1000\n",
            " - 8s - loss: 1.1208 - acc: 0.5551 - val_loss: 1.0848 - val_acc: 0.5593\n",
            "\n",
            "Epoch 00474: val_loss did not improve from 1.08376\n",
            "Epoch 475/1000\n",
            " - 8s - loss: 1.1170 - acc: 0.5619 - val_loss: 1.0785 - val_acc: 0.5589\n",
            "\n",
            "Epoch 00475: val_loss improved from 1.08376 to 1.07850, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 476/1000\n",
            " - 8s - loss: 1.1172 - acc: 0.5580 - val_loss: 1.0944 - val_acc: 0.5608\n",
            "\n",
            "Epoch 00476: val_loss did not improve from 1.07850\n",
            "Epoch 477/1000\n",
            " - 8s - loss: 1.1192 - acc: 0.5568 - val_loss: 1.0780 - val_acc: 0.5686\n",
            "\n",
            "Epoch 00477: val_loss improved from 1.07850 to 1.07805, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 478/1000\n",
            " - 8s - loss: 1.1117 - acc: 0.5612 - val_loss: 1.0952 - val_acc: 0.5591\n",
            "\n",
            "Epoch 00478: val_loss did not improve from 1.07805\n",
            "Epoch 479/1000\n",
            " - 8s - loss: 1.1183 - acc: 0.5586 - val_loss: 1.0913 - val_acc: 0.5598\n",
            "\n",
            "Epoch 00479: val_loss did not improve from 1.07805\n",
            "Epoch 480/1000\n",
            " - 8s - loss: 1.1212 - acc: 0.5531 - val_loss: 1.0890 - val_acc: 0.5603\n",
            "\n",
            "Epoch 00480: val_loss did not improve from 1.07805\n",
            "Epoch 481/1000\n",
            " - 8s - loss: 1.1088 - acc: 0.5634 - val_loss: 1.0869 - val_acc: 0.5624\n",
            "\n",
            "Epoch 00481: val_loss did not improve from 1.07805\n",
            "Epoch 482/1000\n",
            " - 8s - loss: 1.1146 - acc: 0.5603 - val_loss: 1.0884 - val_acc: 0.5638\n",
            "\n",
            "Epoch 00482: val_loss did not improve from 1.07805\n",
            "Epoch 483/1000\n",
            " - 8s - loss: 1.1175 - acc: 0.5574 - val_loss: 1.1137 - val_acc: 0.5423\n",
            "\n",
            "Epoch 00483: val_loss did not improve from 1.07805\n",
            "Epoch 484/1000\n",
            " - 8s - loss: 1.1132 - acc: 0.5587 - val_loss: 1.0941 - val_acc: 0.5563\n",
            "\n",
            "Epoch 00484: val_loss did not improve from 1.07805\n",
            "Epoch 485/1000\n",
            " - 8s - loss: 1.1162 - acc: 0.5576 - val_loss: 1.0876 - val_acc: 0.5589\n",
            "\n",
            "Epoch 00485: val_loss did not improve from 1.07805\n",
            "Epoch 486/1000\n",
            " - 8s - loss: 1.1075 - acc: 0.5603 - val_loss: 1.0849 - val_acc: 0.5586\n",
            "\n",
            "Epoch 00486: val_loss did not improve from 1.07805\n",
            "Epoch 487/1000\n",
            " - 8s - loss: 1.1057 - acc: 0.5596 - val_loss: 1.0757 - val_acc: 0.5662\n",
            "\n",
            "Epoch 00487: val_loss improved from 1.07805 to 1.07571, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 488/1000\n",
            " - 8s - loss: 1.1059 - acc: 0.5631 - val_loss: 1.0995 - val_acc: 0.5501\n",
            "\n",
            "Epoch 00488: val_loss did not improve from 1.07571\n",
            "Epoch 489/1000\n",
            " - 8s - loss: 1.1191 - acc: 0.5541 - val_loss: 1.1013 - val_acc: 0.5444\n",
            "\n",
            "Epoch 00489: val_loss did not improve from 1.07571\n",
            "Epoch 490/1000\n",
            " - 8s - loss: 1.1095 - acc: 0.5663 - val_loss: 1.0898 - val_acc: 0.5603\n",
            "\n",
            "Epoch 00490: val_loss did not improve from 1.07571\n",
            "Epoch 491/1000\n",
            " - 8s - loss: 1.1098 - acc: 0.5676 - val_loss: 1.1030 - val_acc: 0.5657\n",
            "\n",
            "Epoch 00491: val_loss did not improve from 1.07571\n",
            "Epoch 492/1000\n",
            " - 8s - loss: 1.1353 - acc: 0.5504 - val_loss: 1.1017 - val_acc: 0.5608\n",
            "\n",
            "Epoch 00492: val_loss did not improve from 1.07571\n",
            "Epoch 493/1000\n",
            " - 8s - loss: 1.1123 - acc: 0.5651 - val_loss: 1.0829 - val_acc: 0.5664\n",
            "\n",
            "Epoch 00493: val_loss did not improve from 1.07571\n",
            "Epoch 494/1000\n",
            " - 8s - loss: 1.1094 - acc: 0.5618 - val_loss: 1.0800 - val_acc: 0.5612\n",
            "\n",
            "Epoch 00494: val_loss did not improve from 1.07571\n",
            "Epoch 495/1000\n",
            " - 8s - loss: 1.1038 - acc: 0.5671 - val_loss: 1.0738 - val_acc: 0.5676\n",
            "\n",
            "Epoch 00495: val_loss improved from 1.07571 to 1.07382, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 496/1000\n",
            " - 8s - loss: 1.0999 - acc: 0.5704 - val_loss: 1.0815 - val_acc: 0.5645\n",
            "\n",
            "Epoch 00496: val_loss did not improve from 1.07382\n",
            "Epoch 497/1000\n",
            " - 8s - loss: 1.1067 - acc: 0.5625 - val_loss: 1.0809 - val_acc: 0.5603\n",
            "\n",
            "Epoch 00497: val_loss did not improve from 1.07382\n",
            "Epoch 498/1000\n",
            " - 8s - loss: 1.1045 - acc: 0.5673 - val_loss: 1.0784 - val_acc: 0.5584\n",
            "\n",
            "Epoch 00498: val_loss did not improve from 1.07382\n",
            "Epoch 499/1000\n",
            " - 8s - loss: 1.1086 - acc: 0.5667 - val_loss: 1.0826 - val_acc: 0.5695\n",
            "\n",
            "Epoch 00499: val_loss did not improve from 1.07382\n",
            "Epoch 500/1000\n",
            " - 8s - loss: 1.1042 - acc: 0.5627 - val_loss: 1.0733 - val_acc: 0.5766\n",
            "\n",
            "Epoch 00500: val_loss improved from 1.07382 to 1.07334, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 501/1000\n",
            " - 8s - loss: 1.1024 - acc: 0.5683 - val_loss: 1.0682 - val_acc: 0.5761\n",
            "\n",
            "Epoch 00501: val_loss improved from 1.07334 to 1.06817, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 502/1000\n",
            " - 8s - loss: 1.1056 - acc: 0.5643 - val_loss: 1.0819 - val_acc: 0.5655\n",
            "\n",
            "Epoch 00502: val_loss did not improve from 1.06817\n",
            "Epoch 503/1000\n",
            " - 8s - loss: 1.1066 - acc: 0.5627 - val_loss: 1.0888 - val_acc: 0.5605\n",
            "\n",
            "Epoch 00503: val_loss did not improve from 1.06817\n",
            "Epoch 504/1000\n",
            " - 8s - loss: 1.1020 - acc: 0.5650 - val_loss: 1.0715 - val_acc: 0.5775\n",
            "\n",
            "Epoch 00504: val_loss did not improve from 1.06817\n",
            "Epoch 505/1000\n",
            " - 8s - loss: 1.1052 - acc: 0.5637 - val_loss: 1.0934 - val_acc: 0.5539\n",
            "\n",
            "Epoch 00505: val_loss did not improve from 1.06817\n",
            "Epoch 506/1000\n",
            " - 8s - loss: 1.1046 - acc: 0.5666 - val_loss: 1.0730 - val_acc: 0.5674\n",
            "\n",
            "Epoch 00506: val_loss did not improve from 1.06817\n",
            "Epoch 507/1000\n",
            " - 8s - loss: 1.1006 - acc: 0.5684 - val_loss: 1.0723 - val_acc: 0.5688\n",
            "\n",
            "Epoch 00507: val_loss did not improve from 1.06817\n",
            "Epoch 508/1000\n",
            " - 8s - loss: 1.1013 - acc: 0.5687 - val_loss: 1.0778 - val_acc: 0.5664\n",
            "\n",
            "Epoch 00508: val_loss did not improve from 1.06817\n",
            "Epoch 509/1000\n",
            " - 8s - loss: 1.1127 - acc: 0.5657 - val_loss: 1.0855 - val_acc: 0.5681\n",
            "\n",
            "Epoch 00509: val_loss did not improve from 1.06817\n",
            "Epoch 510/1000\n",
            " - 8s - loss: 1.1192 - acc: 0.5570 - val_loss: 1.0711 - val_acc: 0.5721\n",
            "\n",
            "Epoch 00510: val_loss did not improve from 1.06817\n",
            "Epoch 511/1000\n",
            " - 8s - loss: 1.0981 - acc: 0.5678 - val_loss: 1.0793 - val_acc: 0.5669\n",
            "\n",
            "Epoch 00511: val_loss did not improve from 1.06817\n",
            "Epoch 512/1000\n",
            " - 8s - loss: 1.1092 - acc: 0.5636 - val_loss: 1.0837 - val_acc: 0.5626\n",
            "\n",
            "Epoch 00512: val_loss did not improve from 1.06817\n",
            "Epoch 513/1000\n",
            " - 8s - loss: 1.0967 - acc: 0.5687 - val_loss: 1.0728 - val_acc: 0.5652\n",
            "\n",
            "Epoch 00513: val_loss did not improve from 1.06817\n",
            "Epoch 514/1000\n",
            " - 8s - loss: 1.0983 - acc: 0.5727 - val_loss: 1.0734 - val_acc: 0.5641\n",
            "\n",
            "Epoch 00514: val_loss did not improve from 1.06817\n",
            "Epoch 515/1000\n",
            " - 8s - loss: 1.0980 - acc: 0.5706 - val_loss: 1.0822 - val_acc: 0.5589\n",
            "\n",
            "Epoch 00515: val_loss did not improve from 1.06817\n",
            "Epoch 516/1000\n",
            " - 8s - loss: 1.1054 - acc: 0.5678 - val_loss: 1.0708 - val_acc: 0.5674\n",
            "\n",
            "Epoch 00516: val_loss did not improve from 1.06817\n",
            "Epoch 517/1000\n",
            " - 8s - loss: 1.1051 - acc: 0.5663 - val_loss: 1.0803 - val_acc: 0.5676\n",
            "\n",
            "Epoch 00517: val_loss did not improve from 1.06817\n",
            "Epoch 518/1000\n",
            " - 8s - loss: 1.1016 - acc: 0.5721 - val_loss: 1.0655 - val_acc: 0.5766\n",
            "\n",
            "Epoch 00518: val_loss improved from 1.06817 to 1.06546, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 519/1000\n",
            " - 8s - loss: 1.0966 - acc: 0.5729 - val_loss: 1.0889 - val_acc: 0.5619\n",
            "\n",
            "Epoch 00519: val_loss did not improve from 1.06546\n",
            "Epoch 520/1000\n",
            " - 8s - loss: 1.1008 - acc: 0.5697 - val_loss: 1.0837 - val_acc: 0.5608\n",
            "\n",
            "Epoch 00520: val_loss did not improve from 1.06546\n",
            "Epoch 521/1000\n",
            " - 8s - loss: 1.1042 - acc: 0.5685 - val_loss: 1.0860 - val_acc: 0.5541\n",
            "\n",
            "Epoch 00521: val_loss did not improve from 1.06546\n",
            "Epoch 522/1000\n",
            " - 8s - loss: 1.0992 - acc: 0.5697 - val_loss: 1.0702 - val_acc: 0.5704\n",
            "\n",
            "Epoch 00522: val_loss did not improve from 1.06546\n",
            "Epoch 523/1000\n",
            " - 8s - loss: 1.1022 - acc: 0.5686 - val_loss: 1.1053 - val_acc: 0.5423\n",
            "\n",
            "Epoch 00523: val_loss did not improve from 1.06546\n",
            "Epoch 524/1000\n",
            " - 8s - loss: 1.1010 - acc: 0.5661 - val_loss: 1.0657 - val_acc: 0.5688\n",
            "\n",
            "Epoch 00524: val_loss did not improve from 1.06546\n",
            "Epoch 525/1000\n",
            " - 8s - loss: 1.0967 - acc: 0.5752 - val_loss: 1.0619 - val_acc: 0.5712\n",
            "\n",
            "Epoch 00525: val_loss improved from 1.06546 to 1.06187, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 526/1000\n",
            " - 8s - loss: 1.0944 - acc: 0.5683 - val_loss: 1.0662 - val_acc: 0.5688\n",
            "\n",
            "Epoch 00526: val_loss did not improve from 1.06187\n",
            "Epoch 527/1000\n",
            " - 8s - loss: 1.0974 - acc: 0.5692 - val_loss: 1.0768 - val_acc: 0.5643\n",
            "\n",
            "Epoch 00527: val_loss did not improve from 1.06187\n",
            "Epoch 528/1000\n",
            " - 8s - loss: 1.0957 - acc: 0.5753 - val_loss: 1.0715 - val_acc: 0.5697\n",
            "\n",
            "Epoch 00528: val_loss did not improve from 1.06187\n",
            "Epoch 529/1000\n",
            " - 8s - loss: 1.0877 - acc: 0.5784 - val_loss: 1.0686 - val_acc: 0.5764\n",
            "\n",
            "Epoch 00529: val_loss did not improve from 1.06187\n",
            "Epoch 530/1000\n",
            " - 8s - loss: 1.0875 - acc: 0.5790 - val_loss: 1.0717 - val_acc: 0.5683\n",
            "\n",
            "Epoch 00530: val_loss did not improve from 1.06187\n",
            "Epoch 531/1000\n",
            " - 8s - loss: 1.0939 - acc: 0.5727 - val_loss: 1.0743 - val_acc: 0.5667\n",
            "\n",
            "Epoch 00531: val_loss did not improve from 1.06187\n",
            "Epoch 532/1000\n",
            " - 8s - loss: 1.1015 - acc: 0.5684 - val_loss: 1.0919 - val_acc: 0.5593\n",
            "\n",
            "Epoch 00532: val_loss did not improve from 1.06187\n",
            "Epoch 533/1000\n",
            " - 8s - loss: 1.0959 - acc: 0.5702 - val_loss: 1.0755 - val_acc: 0.5695\n",
            "\n",
            "Epoch 00533: val_loss did not improve from 1.06187\n",
            "Epoch 534/1000\n",
            " - 8s - loss: 1.1036 - acc: 0.5684 - val_loss: 1.0683 - val_acc: 0.5728\n",
            "\n",
            "Epoch 00534: val_loss did not improve from 1.06187\n",
            "Epoch 535/1000\n",
            " - 8s - loss: 1.0934 - acc: 0.5809 - val_loss: 1.0638 - val_acc: 0.5742\n",
            "\n",
            "Epoch 00535: val_loss did not improve from 1.06187\n",
            "Epoch 536/1000\n",
            " - 8s - loss: 1.0942 - acc: 0.5782 - val_loss: 1.0658 - val_acc: 0.5752\n",
            "\n",
            "Epoch 00536: val_loss did not improve from 1.06187\n",
            "Epoch 537/1000\n",
            " - 8s - loss: 1.0896 - acc: 0.5785 - val_loss: 1.0704 - val_acc: 0.5745\n",
            "\n",
            "Epoch 00537: val_loss did not improve from 1.06187\n",
            "Epoch 538/1000\n",
            " - 8s - loss: 1.0878 - acc: 0.5773 - val_loss: 1.0820 - val_acc: 0.5664\n",
            "\n",
            "Epoch 00538: val_loss did not improve from 1.06187\n",
            "Epoch 539/1000\n",
            " - 8s - loss: 1.0896 - acc: 0.5740 - val_loss: 1.0793 - val_acc: 0.5676\n",
            "\n",
            "Epoch 00539: val_loss did not improve from 1.06187\n",
            "Epoch 540/1000\n",
            " - 8s - loss: 1.0943 - acc: 0.5733 - val_loss: 1.0631 - val_acc: 0.5738\n",
            "\n",
            "Epoch 00540: val_loss did not improve from 1.06187\n",
            "Epoch 541/1000\n",
            " - 8s - loss: 1.0852 - acc: 0.5797 - val_loss: 1.0652 - val_acc: 0.5780\n",
            "\n",
            "Epoch 00541: val_loss did not improve from 1.06187\n",
            "Epoch 542/1000\n",
            " - 8s - loss: 1.0949 - acc: 0.5725 - val_loss: 1.0611 - val_acc: 0.5728\n",
            "\n",
            "Epoch 00542: val_loss improved from 1.06187 to 1.06114, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 543/1000\n",
            " - 8s - loss: 1.0939 - acc: 0.5743 - val_loss: 1.0693 - val_acc: 0.5757\n",
            "\n",
            "Epoch 00543: val_loss did not improve from 1.06114\n",
            "Epoch 544/1000\n",
            " - 8s - loss: 1.0910 - acc: 0.5785 - val_loss: 1.0769 - val_acc: 0.5636\n",
            "\n",
            "Epoch 00544: val_loss did not improve from 1.06114\n",
            "Epoch 545/1000\n",
            " - 8s - loss: 1.0925 - acc: 0.5734 - val_loss: 1.0632 - val_acc: 0.5749\n",
            "\n",
            "Epoch 00545: val_loss did not improve from 1.06114\n",
            "Epoch 546/1000\n",
            " - 8s - loss: 1.0949 - acc: 0.5722 - val_loss: 1.0704 - val_acc: 0.5681\n",
            "\n",
            "Epoch 00546: val_loss did not improve from 1.06114\n",
            "Epoch 547/1000\n",
            " - 8s - loss: 1.0858 - acc: 0.5791 - val_loss: 1.0725 - val_acc: 0.5778\n",
            "\n",
            "Epoch 00547: val_loss did not improve from 1.06114\n",
            "Epoch 548/1000\n",
            " - 8s - loss: 1.0934 - acc: 0.5762 - val_loss: 1.0815 - val_acc: 0.5648\n",
            "\n",
            "Epoch 00548: val_loss did not improve from 1.06114\n",
            "Epoch 549/1000\n",
            " - 8s - loss: 1.1039 - acc: 0.5700 - val_loss: 1.0777 - val_acc: 0.5610\n",
            "\n",
            "Epoch 00549: val_loss did not improve from 1.06114\n",
            "Epoch 550/1000\n",
            " - 8s - loss: 1.0929 - acc: 0.5761 - val_loss: 1.0817 - val_acc: 0.5645\n",
            "\n",
            "Epoch 00550: val_loss did not improve from 1.06114\n",
            "Epoch 551/1000\n",
            " - 8s - loss: 1.0950 - acc: 0.5744 - val_loss: 1.0657 - val_acc: 0.5759\n",
            "\n",
            "Epoch 00551: val_loss did not improve from 1.06114\n",
            "Epoch 552/1000\n",
            " - 8s - loss: 1.0877 - acc: 0.5718 - val_loss: 1.0666 - val_acc: 0.5761\n",
            "\n",
            "Epoch 00552: val_loss did not improve from 1.06114\n",
            "Epoch 553/1000\n",
            " - 8s - loss: 1.0916 - acc: 0.5747 - val_loss: 1.0565 - val_acc: 0.5891\n",
            "\n",
            "Epoch 00553: val_loss improved from 1.06114 to 1.05649, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 554/1000\n",
            " - 8s - loss: 1.0848 - acc: 0.5793 - val_loss: 1.0632 - val_acc: 0.5730\n",
            "\n",
            "Epoch 00554: val_loss did not improve from 1.05649\n",
            "Epoch 555/1000\n",
            " - 8s - loss: 1.0785 - acc: 0.5801 - val_loss: 1.0845 - val_acc: 0.5657\n",
            "\n",
            "Epoch 00555: val_loss did not improve from 1.05649\n",
            "Epoch 556/1000\n",
            " - 8s - loss: 1.0866 - acc: 0.5779 - val_loss: 1.0894 - val_acc: 0.5560\n",
            "\n",
            "Epoch 00556: val_loss did not improve from 1.05649\n",
            "Epoch 557/1000\n",
            " - 8s - loss: 1.0953 - acc: 0.5704 - val_loss: 1.0719 - val_acc: 0.5742\n",
            "\n",
            "Epoch 00557: val_loss did not improve from 1.05649\n",
            "Epoch 558/1000\n",
            " - 8s - loss: 1.0889 - acc: 0.5774 - val_loss: 1.0709 - val_acc: 0.5608\n",
            "\n",
            "Epoch 00558: val_loss did not improve from 1.05649\n",
            "Epoch 559/1000\n",
            " - 8s - loss: 1.0805 - acc: 0.5863 - val_loss: 1.0775 - val_acc: 0.5688\n",
            "\n",
            "Epoch 00559: val_loss did not improve from 1.05649\n",
            "Epoch 560/1000\n",
            " - 8s - loss: 1.0797 - acc: 0.5804 - val_loss: 1.0596 - val_acc: 0.5825\n",
            "\n",
            "Epoch 00560: val_loss did not improve from 1.05649\n",
            "Epoch 561/1000\n",
            " - 8s - loss: 1.0904 - acc: 0.5768 - val_loss: 1.0605 - val_acc: 0.5891\n",
            "\n",
            "Epoch 00561: val_loss did not improve from 1.05649\n",
            "Epoch 562/1000\n",
            " - 8s - loss: 1.0884 - acc: 0.5816 - val_loss: 1.0658 - val_acc: 0.5735\n",
            "\n",
            "Epoch 00562: val_loss did not improve from 1.05649\n",
            "Epoch 563/1000\n",
            " - 8s - loss: 1.0821 - acc: 0.5827 - val_loss: 1.0752 - val_acc: 0.5726\n",
            "\n",
            "Epoch 00563: val_loss did not improve from 1.05649\n",
            "Epoch 564/1000\n",
            " - 8s - loss: 1.0852 - acc: 0.5829 - val_loss: 1.0726 - val_acc: 0.5688\n",
            "\n",
            "Epoch 00564: val_loss did not improve from 1.05649\n",
            "Epoch 565/1000\n",
            " - 8s - loss: 1.0830 - acc: 0.5826 - val_loss: 1.0621 - val_acc: 0.5792\n",
            "\n",
            "Epoch 00565: val_loss did not improve from 1.05649\n",
            "Epoch 566/1000\n",
            " - 8s - loss: 1.0840 - acc: 0.5786 - val_loss: 1.0763 - val_acc: 0.5688\n",
            "\n",
            "Epoch 00566: val_loss did not improve from 1.05649\n",
            "Epoch 567/1000\n",
            " - 8s - loss: 1.0848 - acc: 0.5800 - val_loss: 1.0850 - val_acc: 0.5712\n",
            "\n",
            "Epoch 00567: val_loss did not improve from 1.05649\n",
            "Epoch 568/1000\n",
            " - 8s - loss: 1.0910 - acc: 0.5797 - val_loss: 1.0625 - val_acc: 0.5757\n",
            "\n",
            "Epoch 00568: val_loss did not improve from 1.05649\n",
            "Epoch 569/1000\n",
            " - 8s - loss: 1.0857 - acc: 0.5794 - val_loss: 1.0970 - val_acc: 0.5541\n",
            "\n",
            "Epoch 00569: val_loss did not improve from 1.05649\n",
            "Epoch 570/1000\n",
            " - 8s - loss: 1.0950 - acc: 0.5738 - val_loss: 1.0651 - val_acc: 0.5749\n",
            "\n",
            "Epoch 00570: val_loss did not improve from 1.05649\n",
            "Epoch 571/1000\n",
            " - 8s - loss: 1.0826 - acc: 0.5801 - val_loss: 1.0658 - val_acc: 0.5809\n",
            "\n",
            "Epoch 00571: val_loss did not improve from 1.05649\n",
            "Epoch 572/1000\n",
            " - 8s - loss: 1.0858 - acc: 0.5774 - val_loss: 1.0611 - val_acc: 0.5825\n",
            "\n",
            "Epoch 00572: val_loss did not improve from 1.05649\n",
            "Epoch 573/1000\n",
            " - 8s - loss: 1.0789 - acc: 0.5818 - val_loss: 1.0500 - val_acc: 0.5894\n",
            "\n",
            "Epoch 00573: val_loss improved from 1.05649 to 1.05001, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 574/1000\n",
            " - 8s - loss: 1.0850 - acc: 0.5850 - val_loss: 1.0617 - val_acc: 0.5837\n",
            "\n",
            "Epoch 00574: val_loss did not improve from 1.05001\n",
            "Epoch 575/1000\n",
            " - 8s - loss: 1.0855 - acc: 0.5811 - val_loss: 1.0750 - val_acc: 0.5754\n",
            "\n",
            "Epoch 00575: val_loss did not improve from 1.05001\n",
            "Epoch 576/1000\n",
            " - 8s - loss: 1.0830 - acc: 0.5835 - val_loss: 1.0746 - val_acc: 0.5695\n",
            "\n",
            "Epoch 00576: val_loss did not improve from 1.05001\n",
            "Epoch 577/1000\n",
            " - 8s - loss: 1.0767 - acc: 0.5848 - val_loss: 1.0626 - val_acc: 0.5742\n",
            "\n",
            "Epoch 00577: val_loss did not improve from 1.05001\n",
            "Epoch 578/1000\n",
            " - 8s - loss: 1.0800 - acc: 0.5878 - val_loss: 1.0595 - val_acc: 0.5851\n",
            "\n",
            "Epoch 00578: val_loss did not improve from 1.05001\n",
            "Epoch 579/1000\n",
            " - 8s - loss: 1.0809 - acc: 0.5858 - val_loss: 1.0723 - val_acc: 0.5730\n",
            "\n",
            "Epoch 00579: val_loss did not improve from 1.05001\n",
            "Epoch 580/1000\n",
            " - 8s - loss: 1.0894 - acc: 0.5786 - val_loss: 1.0543 - val_acc: 0.5827\n",
            "\n",
            "Epoch 00580: val_loss did not improve from 1.05001\n",
            "Epoch 581/1000\n",
            " - 8s - loss: 1.0696 - acc: 0.5923 - val_loss: 1.0565 - val_acc: 0.5889\n",
            "\n",
            "Epoch 00581: val_loss did not improve from 1.05001\n",
            "Epoch 582/1000\n",
            " - 8s - loss: 1.0763 - acc: 0.5859 - val_loss: 1.0665 - val_acc: 0.5735\n",
            "\n",
            "Epoch 00582: val_loss did not improve from 1.05001\n",
            "Epoch 583/1000\n",
            " - 8s - loss: 1.0809 - acc: 0.5811 - val_loss: 1.0803 - val_acc: 0.5712\n",
            "\n",
            "Epoch 00583: val_loss did not improve from 1.05001\n",
            "Epoch 584/1000\n",
            " - 8s - loss: 1.0792 - acc: 0.5835 - val_loss: 1.0678 - val_acc: 0.5740\n",
            "\n",
            "Epoch 00584: val_loss did not improve from 1.05001\n",
            "Epoch 585/1000\n",
            " - 8s - loss: 1.0910 - acc: 0.5760 - val_loss: 1.0790 - val_acc: 0.5671\n",
            "\n",
            "Epoch 00585: val_loss did not improve from 1.05001\n",
            "Epoch 586/1000\n",
            " - 8s - loss: 1.0815 - acc: 0.5786 - val_loss: 1.0789 - val_acc: 0.5730\n",
            "\n",
            "Epoch 00586: val_loss did not improve from 1.05001\n",
            "Epoch 587/1000\n",
            " - 8s - loss: 1.0848 - acc: 0.5757 - val_loss: 1.0638 - val_acc: 0.5697\n",
            "\n",
            "Epoch 00587: val_loss did not improve from 1.05001\n",
            "Epoch 588/1000\n",
            " - 8s - loss: 1.0806 - acc: 0.5802 - val_loss: 1.0560 - val_acc: 0.5740\n",
            "\n",
            "Epoch 00588: val_loss did not improve from 1.05001\n",
            "Epoch 589/1000\n",
            " - 8s - loss: 1.0777 - acc: 0.5863 - val_loss: 1.0650 - val_acc: 0.5759\n",
            "\n",
            "Epoch 00589: val_loss did not improve from 1.05001\n",
            "Epoch 590/1000\n",
            " - 8s - loss: 1.0900 - acc: 0.5790 - val_loss: 1.0606 - val_acc: 0.5745\n",
            "\n",
            "Epoch 00590: val_loss did not improve from 1.05001\n",
            "Epoch 591/1000\n",
            " - 8s - loss: 1.0837 - acc: 0.5856 - val_loss: 1.0654 - val_acc: 0.5730\n",
            "\n",
            "Epoch 00591: val_loss did not improve from 1.05001\n",
            "Epoch 592/1000\n",
            " - 8s - loss: 1.0814 - acc: 0.5832 - val_loss: 1.0577 - val_acc: 0.5768\n",
            "\n",
            "Epoch 00592: val_loss did not improve from 1.05001\n",
            "Epoch 593/1000\n",
            " - 8s - loss: 1.0688 - acc: 0.5899 - val_loss: 1.0593 - val_acc: 0.5816\n",
            "\n",
            "Epoch 00593: val_loss did not improve from 1.05001\n",
            "Epoch 594/1000\n",
            " - 8s - loss: 1.0707 - acc: 0.5894 - val_loss: 1.0613 - val_acc: 0.5827\n",
            "\n",
            "Epoch 00594: val_loss did not improve from 1.05001\n",
            "Epoch 595/1000\n",
            " - 8s - loss: 1.0840 - acc: 0.5835 - val_loss: 1.0727 - val_acc: 0.5683\n",
            "\n",
            "Epoch 00595: val_loss did not improve from 1.05001\n",
            "Epoch 596/1000\n",
            " - 8s - loss: 1.0809 - acc: 0.5825 - val_loss: 1.0648 - val_acc: 0.5733\n",
            "\n",
            "Epoch 00596: val_loss did not improve from 1.05001\n",
            "Epoch 597/1000\n",
            " - 8s - loss: 1.0749 - acc: 0.5858 - val_loss: 1.0701 - val_acc: 0.5804\n",
            "\n",
            "Epoch 00597: val_loss did not improve from 1.05001\n",
            "Epoch 598/1000\n",
            " - 8s - loss: 1.0805 - acc: 0.5822 - val_loss: 1.0796 - val_acc: 0.5678\n",
            "\n",
            "Epoch 00598: val_loss did not improve from 1.05001\n",
            "Epoch 599/1000\n",
            " - 8s - loss: 1.0822 - acc: 0.5812 - val_loss: 1.0640 - val_acc: 0.5846\n",
            "\n",
            "Epoch 00599: val_loss did not improve from 1.05001\n",
            "Epoch 600/1000\n",
            " - 8s - loss: 1.0792 - acc: 0.5823 - val_loss: 1.0611 - val_acc: 0.5884\n",
            "\n",
            "Epoch 00600: val_loss did not improve from 1.05001\n",
            "Epoch 601/1000\n",
            " - 8s - loss: 1.0734 - acc: 0.5856 - val_loss: 1.0628 - val_acc: 0.5794\n",
            "\n",
            "Epoch 00601: val_loss did not improve from 1.05001\n",
            "Epoch 602/1000\n",
            " - 8s - loss: 1.0728 - acc: 0.5856 - val_loss: 1.0533 - val_acc: 0.5872\n",
            "\n",
            "Epoch 00602: val_loss did not improve from 1.05001\n",
            "Epoch 603/1000\n",
            " - 8s - loss: 1.0725 - acc: 0.5902 - val_loss: 1.0710 - val_acc: 0.5638\n",
            "\n",
            "Epoch 00603: val_loss did not improve from 1.05001\n",
            "Epoch 604/1000\n",
            " - 8s - loss: 1.0776 - acc: 0.5848 - val_loss: 1.0552 - val_acc: 0.5693\n",
            "\n",
            "Epoch 00604: val_loss did not improve from 1.05001\n",
            "Epoch 605/1000\n",
            " - 8s - loss: 1.0736 - acc: 0.5849 - val_loss: 1.0544 - val_acc: 0.5790\n",
            "\n",
            "Epoch 00605: val_loss did not improve from 1.05001\n",
            "Epoch 606/1000\n",
            " - 8s - loss: 1.0719 - acc: 0.5865 - val_loss: 1.0607 - val_acc: 0.5846\n",
            "\n",
            "Epoch 00606: val_loss did not improve from 1.05001\n",
            "Epoch 607/1000\n",
            " - 8s - loss: 1.0690 - acc: 0.5902 - val_loss: 1.0654 - val_acc: 0.5801\n",
            "\n",
            "Epoch 00607: val_loss did not improve from 1.05001\n",
            "Epoch 608/1000\n",
            " - 8s - loss: 1.0695 - acc: 0.5884 - val_loss: 1.0675 - val_acc: 0.5792\n",
            "\n",
            "Epoch 00608: val_loss did not improve from 1.05001\n",
            "Epoch 609/1000\n",
            " - 8s - loss: 1.0706 - acc: 0.5882 - val_loss: 1.0480 - val_acc: 0.5832\n",
            "\n",
            "Epoch 00609: val_loss improved from 1.05001 to 1.04798, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 610/1000\n",
            " - 8s - loss: 1.0754 - acc: 0.5890 - val_loss: 1.0640 - val_acc: 0.5745\n",
            "\n",
            "Epoch 00610: val_loss did not improve from 1.04798\n",
            "Epoch 611/1000\n",
            " - 8s - loss: 1.0737 - acc: 0.5815 - val_loss: 1.0662 - val_acc: 0.5674\n",
            "\n",
            "Epoch 00611: val_loss did not improve from 1.04798\n",
            "Epoch 612/1000\n",
            " - 8s - loss: 1.0776 - acc: 0.5848 - val_loss: 1.0575 - val_acc: 0.5905\n",
            "\n",
            "Epoch 00612: val_loss did not improve from 1.04798\n",
            "Epoch 613/1000\n",
            " - 8s - loss: 1.0705 - acc: 0.5851 - val_loss: 1.0628 - val_acc: 0.5778\n",
            "\n",
            "Epoch 00613: val_loss did not improve from 1.04798\n",
            "Epoch 614/1000\n",
            " - 8s - loss: 1.0704 - acc: 0.5884 - val_loss: 1.0609 - val_acc: 0.5764\n",
            "\n",
            "Epoch 00614: val_loss did not improve from 1.04798\n",
            "Epoch 615/1000\n",
            " - 8s - loss: 1.0728 - acc: 0.5901 - val_loss: 1.0587 - val_acc: 0.5804\n",
            "\n",
            "Epoch 00615: val_loss did not improve from 1.04798\n",
            "Epoch 616/1000\n",
            " - 8s - loss: 1.0805 - acc: 0.5827 - val_loss: 1.0605 - val_acc: 0.5742\n",
            "\n",
            "Epoch 00616: val_loss did not improve from 1.04798\n",
            "Epoch 617/1000\n",
            " - 8s - loss: 1.0739 - acc: 0.5873 - val_loss: 1.0609 - val_acc: 0.5738\n",
            "\n",
            "Epoch 00617: val_loss did not improve from 1.04798\n",
            "Epoch 618/1000\n",
            " - 8s - loss: 1.0654 - acc: 0.5907 - val_loss: 1.0570 - val_acc: 0.5858\n",
            "\n",
            "Epoch 00618: val_loss did not improve from 1.04798\n",
            "Epoch 619/1000\n",
            " - 8s - loss: 1.0748 - acc: 0.5918 - val_loss: 1.0558 - val_acc: 0.5764\n",
            "\n",
            "Epoch 00619: val_loss did not improve from 1.04798\n",
            "Epoch 620/1000\n",
            " - 8s - loss: 1.0769 - acc: 0.5840 - val_loss: 1.0560 - val_acc: 0.5792\n",
            "\n",
            "Epoch 00620: val_loss did not improve from 1.04798\n",
            "Epoch 621/1000\n",
            " - 8s - loss: 1.0723 - acc: 0.5907 - val_loss: 1.0509 - val_acc: 0.5872\n",
            "\n",
            "Epoch 00621: val_loss did not improve from 1.04798\n",
            "Epoch 622/1000\n",
            " - 8s - loss: 1.0762 - acc: 0.5894 - val_loss: 1.0609 - val_acc: 0.5861\n",
            "\n",
            "Epoch 00622: val_loss did not improve from 1.04798\n",
            "Epoch 623/1000\n",
            " - 8s - loss: 1.0762 - acc: 0.5845 - val_loss: 1.0553 - val_acc: 0.5806\n",
            "\n",
            "Epoch 00623: val_loss did not improve from 1.04798\n",
            "Epoch 624/1000\n",
            " - 8s - loss: 1.0675 - acc: 0.5921 - val_loss: 1.0523 - val_acc: 0.5811\n",
            "\n",
            "Epoch 00624: val_loss did not improve from 1.04798\n",
            "Epoch 625/1000\n",
            " - 8s - loss: 1.0764 - acc: 0.5829 - val_loss: 1.0650 - val_acc: 0.5742\n",
            "\n",
            "Epoch 00625: val_loss did not improve from 1.04798\n",
            "Epoch 626/1000\n",
            " - 8s - loss: 1.0730 - acc: 0.5875 - val_loss: 1.0626 - val_acc: 0.5735\n",
            "\n",
            "Epoch 00626: val_loss did not improve from 1.04798\n",
            "Epoch 627/1000\n",
            " - 8s - loss: 1.0764 - acc: 0.5866 - val_loss: 1.0693 - val_acc: 0.5761\n",
            "\n",
            "Epoch 00627: val_loss did not improve from 1.04798\n",
            "Epoch 628/1000\n",
            " - 8s - loss: 1.0656 - acc: 0.5871 - val_loss: 1.0743 - val_acc: 0.5733\n",
            "\n",
            "Epoch 00628: val_loss did not improve from 1.04798\n",
            "Epoch 629/1000\n",
            " - 8s - loss: 1.0730 - acc: 0.5911 - val_loss: 1.0854 - val_acc: 0.5721\n",
            "\n",
            "Epoch 00629: val_loss did not improve from 1.04798\n",
            "Epoch 630/1000\n",
            " - 8s - loss: 1.0787 - acc: 0.5829 - val_loss: 1.0766 - val_acc: 0.5662\n",
            "\n",
            "Epoch 00630: val_loss did not improve from 1.04798\n",
            "Epoch 631/1000\n",
            " - 8s - loss: 1.0683 - acc: 0.5889 - val_loss: 1.0710 - val_acc: 0.5723\n",
            "\n",
            "Epoch 00631: val_loss did not improve from 1.04798\n",
            "Epoch 632/1000\n",
            " - 8s - loss: 1.0648 - acc: 0.5905 - val_loss: 1.0625 - val_acc: 0.5723\n",
            "\n",
            "Epoch 00632: val_loss did not improve from 1.04798\n",
            "Epoch 633/1000\n",
            " - 8s - loss: 1.0595 - acc: 0.5986 - val_loss: 1.0506 - val_acc: 0.5962\n",
            "\n",
            "Epoch 00633: val_loss did not improve from 1.04798\n",
            "Epoch 634/1000\n",
            " - 8s - loss: 1.0717 - acc: 0.5907 - val_loss: 1.0667 - val_acc: 0.5761\n",
            "\n",
            "Epoch 00634: val_loss did not improve from 1.04798\n",
            "Epoch 635/1000\n",
            " - 8s - loss: 1.0709 - acc: 0.5855 - val_loss: 1.0552 - val_acc: 0.5889\n",
            "\n",
            "Epoch 00635: val_loss did not improve from 1.04798\n",
            "Epoch 636/1000\n",
            " - 8s - loss: 1.0640 - acc: 0.5919 - val_loss: 1.0556 - val_acc: 0.5830\n",
            "\n",
            "Epoch 00636: val_loss did not improve from 1.04798\n",
            "Epoch 637/1000\n",
            " - 8s - loss: 1.0657 - acc: 0.5939 - val_loss: 1.0563 - val_acc: 0.5872\n",
            "\n",
            "Epoch 00637: val_loss did not improve from 1.04798\n",
            "Epoch 638/1000\n",
            " - 8s - loss: 1.0709 - acc: 0.5870 - val_loss: 1.0587 - val_acc: 0.5856\n",
            "\n",
            "Epoch 00638: val_loss did not improve from 1.04798\n",
            "Epoch 639/1000\n",
            " - 8s - loss: 1.0646 - acc: 0.5940 - val_loss: 1.0498 - val_acc: 0.5934\n",
            "\n",
            "Epoch 00639: val_loss did not improve from 1.04798\n",
            "Epoch 640/1000\n",
            " - 8s - loss: 1.0666 - acc: 0.5965 - val_loss: 1.0527 - val_acc: 0.5801\n",
            "\n",
            "Epoch 00640: val_loss did not improve from 1.04798\n",
            "Epoch 641/1000\n",
            " - 8s - loss: 1.0619 - acc: 0.5908 - val_loss: 1.0674 - val_acc: 0.5799\n",
            "\n",
            "Epoch 00641: val_loss did not improve from 1.04798\n",
            "Epoch 642/1000\n",
            " - 8s - loss: 1.0678 - acc: 0.5921 - val_loss: 1.0468 - val_acc: 0.5922\n",
            "\n",
            "Epoch 00642: val_loss improved from 1.04798 to 1.04683, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 643/1000\n",
            " - 8s - loss: 1.0581 - acc: 0.5971 - val_loss: 1.0568 - val_acc: 0.5858\n",
            "\n",
            "Epoch 00643: val_loss did not improve from 1.04683\n",
            "Epoch 644/1000\n",
            " - 8s - loss: 1.0626 - acc: 0.5924 - val_loss: 1.0586 - val_acc: 0.5749\n",
            "\n",
            "Epoch 00644: val_loss did not improve from 1.04683\n",
            "Epoch 645/1000\n",
            " - 8s - loss: 1.0675 - acc: 0.5940 - val_loss: 1.0544 - val_acc: 0.5901\n",
            "\n",
            "Epoch 00645: val_loss did not improve from 1.04683\n",
            "Epoch 646/1000\n",
            " - 8s - loss: 1.0566 - acc: 0.5946 - val_loss: 1.0616 - val_acc: 0.5809\n",
            "\n",
            "Epoch 00646: val_loss did not improve from 1.04683\n",
            "Epoch 647/1000\n",
            " - 8s - loss: 1.0634 - acc: 0.5965 - val_loss: 1.0444 - val_acc: 0.5901\n",
            "\n",
            "Epoch 00647: val_loss improved from 1.04683 to 1.04439, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 648/1000\n",
            " - 8s - loss: 1.0641 - acc: 0.5885 - val_loss: 1.0517 - val_acc: 0.5891\n",
            "\n",
            "Epoch 00648: val_loss did not improve from 1.04439\n",
            "Epoch 649/1000\n",
            " - 8s - loss: 1.0649 - acc: 0.5917 - val_loss: 1.0636 - val_acc: 0.5759\n",
            "\n",
            "Epoch 00649: val_loss did not improve from 1.04439\n",
            "Epoch 650/1000\n",
            " - 8s - loss: 1.0609 - acc: 0.5920 - val_loss: 1.0508 - val_acc: 0.5913\n",
            "\n",
            "Epoch 00650: val_loss did not improve from 1.04439\n",
            "Epoch 651/1000\n",
            " - 8s - loss: 1.0714 - acc: 0.5853 - val_loss: 1.0602 - val_acc: 0.5768\n",
            "\n",
            "Epoch 00651: val_loss did not improve from 1.04439\n",
            "Epoch 652/1000\n",
            " - 8s - loss: 1.0715 - acc: 0.5954 - val_loss: 1.0562 - val_acc: 0.5764\n",
            "\n",
            "Epoch 00652: val_loss did not improve from 1.04439\n",
            "Epoch 653/1000\n",
            " - 8s - loss: 1.0677 - acc: 0.5897 - val_loss: 1.0554 - val_acc: 0.5809\n",
            "\n",
            "Epoch 00653: val_loss did not improve from 1.04439\n",
            "Epoch 654/1000\n",
            " - 8s - loss: 1.0683 - acc: 0.5933 - val_loss: 1.0460 - val_acc: 0.5877\n",
            "\n",
            "Epoch 00654: val_loss did not improve from 1.04439\n",
            "Epoch 655/1000\n",
            " - 8s - loss: 1.0600 - acc: 0.5944 - val_loss: 1.0624 - val_acc: 0.5809\n",
            "\n",
            "Epoch 00655: val_loss did not improve from 1.04439\n",
            "Epoch 656/1000\n",
            " - 8s - loss: 1.0696 - acc: 0.5918 - val_loss: 1.0499 - val_acc: 0.5877\n",
            "\n",
            "Epoch 00656: val_loss did not improve from 1.04439\n",
            "Epoch 657/1000\n",
            " - 8s - loss: 1.0559 - acc: 0.6020 - val_loss: 1.0797 - val_acc: 0.5690\n",
            "\n",
            "Epoch 00657: val_loss did not improve from 1.04439\n",
            "Epoch 658/1000\n",
            " - 8s - loss: 1.0694 - acc: 0.5874 - val_loss: 1.0506 - val_acc: 0.5929\n",
            "\n",
            "Epoch 00658: val_loss did not improve from 1.04439\n",
            "Epoch 659/1000\n",
            " - 8s - loss: 1.0630 - acc: 0.5895 - val_loss: 1.0606 - val_acc: 0.5811\n",
            "\n",
            "Epoch 00659: val_loss did not improve from 1.04439\n",
            "Epoch 660/1000\n",
            " - 8s - loss: 1.0685 - acc: 0.5909 - val_loss: 1.0573 - val_acc: 0.5780\n",
            "\n",
            "Epoch 00660: val_loss did not improve from 1.04439\n",
            "Epoch 661/1000\n",
            " - 8s - loss: 1.0593 - acc: 0.5942 - val_loss: 1.0543 - val_acc: 0.5882\n",
            "\n",
            "Epoch 00661: val_loss did not improve from 1.04439\n",
            "Epoch 662/1000\n",
            " - 8s - loss: 1.0607 - acc: 0.5947 - val_loss: 1.0597 - val_acc: 0.5832\n",
            "\n",
            "Epoch 00662: val_loss did not improve from 1.04439\n",
            "Epoch 663/1000\n",
            " - 8s - loss: 1.0567 - acc: 0.5969 - val_loss: 1.0510 - val_acc: 0.5901\n",
            "\n",
            "Epoch 00663: val_loss did not improve from 1.04439\n",
            "Epoch 664/1000\n",
            " - 8s - loss: 1.0643 - acc: 0.5956 - val_loss: 1.0576 - val_acc: 0.5839\n",
            "\n",
            "Epoch 00664: val_loss did not improve from 1.04439\n",
            "Epoch 665/1000\n",
            " - 8s - loss: 1.0582 - acc: 0.5994 - val_loss: 1.0675 - val_acc: 0.5775\n",
            "\n",
            "Epoch 00665: val_loss did not improve from 1.04439\n",
            "Epoch 666/1000\n",
            " - 8s - loss: 1.0621 - acc: 0.5945 - val_loss: 1.0581 - val_acc: 0.5858\n",
            "\n",
            "Epoch 00666: val_loss did not improve from 1.04439\n",
            "Epoch 667/1000\n",
            " - 8s - loss: 1.0522 - acc: 0.5941 - val_loss: 1.1122 - val_acc: 0.5636\n",
            "\n",
            "Epoch 00667: val_loss did not improve from 1.04439\n",
            "Epoch 668/1000\n",
            " - 8s - loss: 1.0519 - acc: 0.5974 - val_loss: 1.0818 - val_acc: 0.5700\n",
            "\n",
            "Epoch 00668: val_loss did not improve from 1.04439\n",
            "Epoch 669/1000\n",
            " - 8s - loss: 1.0559 - acc: 0.6008 - val_loss: 1.0591 - val_acc: 0.5870\n",
            "\n",
            "Epoch 00669: val_loss did not improve from 1.04439\n",
            "Epoch 670/1000\n",
            " - 8s - loss: 1.0689 - acc: 0.5910 - val_loss: 1.0681 - val_acc: 0.5811\n",
            "\n",
            "Epoch 00670: val_loss did not improve from 1.04439\n",
            "Epoch 671/1000\n",
            " - 8s - loss: 1.0581 - acc: 0.5957 - val_loss: 1.0594 - val_acc: 0.5903\n",
            "\n",
            "Epoch 00671: val_loss did not improve from 1.04439\n",
            "Epoch 672/1000\n",
            " - 8s - loss: 1.0458 - acc: 0.5998 - val_loss: 1.0455 - val_acc: 0.5842\n",
            "\n",
            "Epoch 00672: val_loss did not improve from 1.04439\n",
            "Epoch 673/1000\n",
            " - 8s - loss: 1.0481 - acc: 0.5969 - val_loss: 1.0704 - val_acc: 0.5797\n",
            "\n",
            "Epoch 00673: val_loss did not improve from 1.04439\n",
            "Epoch 674/1000\n",
            " - 8s - loss: 1.0594 - acc: 0.5972 - val_loss: 1.0639 - val_acc: 0.5823\n",
            "\n",
            "Epoch 00674: val_loss did not improve from 1.04439\n",
            "Epoch 675/1000\n",
            " - 8s - loss: 1.0488 - acc: 0.6011 - val_loss: 1.0534 - val_acc: 0.5943\n",
            "\n",
            "Epoch 00675: val_loss did not improve from 1.04439\n",
            "Epoch 676/1000\n",
            " - 8s - loss: 1.0519 - acc: 0.5967 - val_loss: 1.0715 - val_acc: 0.5787\n",
            "\n",
            "Epoch 00676: val_loss did not improve from 1.04439\n",
            "Epoch 677/1000\n",
            " - 8s - loss: 1.0622 - acc: 0.5928 - val_loss: 1.0592 - val_acc: 0.5827\n",
            "\n",
            "Epoch 00677: val_loss did not improve from 1.04439\n",
            "Epoch 678/1000\n",
            " - 8s - loss: 1.0592 - acc: 0.5957 - val_loss: 1.0551 - val_acc: 0.5898\n",
            "\n",
            "Epoch 00678: val_loss did not improve from 1.04439\n",
            "Epoch 679/1000\n",
            " - 8s - loss: 1.0489 - acc: 0.6014 - val_loss: 1.0714 - val_acc: 0.5771\n",
            "\n",
            "Epoch 00679: val_loss did not improve from 1.04439\n",
            "Epoch 680/1000\n",
            " - 8s - loss: 1.0578 - acc: 0.5976 - val_loss: 1.0580 - val_acc: 0.5801\n",
            "\n",
            "Epoch 00680: val_loss did not improve from 1.04439\n",
            "Epoch 681/1000\n",
            " - 8s - loss: 1.0524 - acc: 0.5960 - val_loss: 1.0636 - val_acc: 0.5754\n",
            "\n",
            "Epoch 00681: val_loss did not improve from 1.04439\n",
            "Epoch 682/1000\n",
            " - 8s - loss: 1.0502 - acc: 0.6000 - val_loss: 1.0915 - val_acc: 0.5745\n",
            "\n",
            "Epoch 00682: val_loss did not improve from 1.04439\n",
            "Epoch 683/1000\n",
            " - 8s - loss: 1.0663 - acc: 0.5905 - val_loss: 1.0570 - val_acc: 0.5839\n",
            "\n",
            "Epoch 00683: val_loss did not improve from 1.04439\n",
            "Epoch 684/1000\n",
            " - 8s - loss: 1.0574 - acc: 0.5963 - val_loss: 1.0566 - val_acc: 0.5832\n",
            "\n",
            "Epoch 00684: val_loss did not improve from 1.04439\n",
            "Epoch 685/1000\n",
            " - 8s - loss: 1.0612 - acc: 0.5940 - val_loss: 1.0735 - val_acc: 0.5768\n",
            "\n",
            "Epoch 00685: val_loss did not improve from 1.04439\n",
            "Epoch 686/1000\n",
            " - 8s - loss: 1.0576 - acc: 0.5943 - val_loss: 1.0555 - val_acc: 0.5858\n",
            "\n",
            "Epoch 00686: val_loss did not improve from 1.04439\n",
            "Epoch 687/1000\n",
            " - 8s - loss: 1.0487 - acc: 0.6017 - val_loss: 1.0396 - val_acc: 0.5950\n",
            "\n",
            "Epoch 00687: val_loss improved from 1.04439 to 1.03957, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 688/1000\n",
            " - 8s - loss: 1.0586 - acc: 0.5959 - val_loss: 1.0457 - val_acc: 0.5853\n",
            "\n",
            "Epoch 00688: val_loss did not improve from 1.03957\n",
            "Epoch 689/1000\n",
            " - 8s - loss: 1.0649 - acc: 0.5918 - val_loss: 1.0586 - val_acc: 0.5835\n",
            "\n",
            "Epoch 00689: val_loss did not improve from 1.03957\n",
            "Epoch 690/1000\n",
            " - 8s - loss: 1.0553 - acc: 0.5959 - val_loss: 1.0624 - val_acc: 0.5887\n",
            "\n",
            "Epoch 00690: val_loss did not improve from 1.03957\n",
            "Epoch 691/1000\n",
            " - 8s - loss: 1.0585 - acc: 0.5958 - val_loss: 1.0469 - val_acc: 0.5953\n",
            "\n",
            "Epoch 00691: val_loss did not improve from 1.03957\n",
            "Epoch 692/1000\n",
            " - 8s - loss: 1.0609 - acc: 0.5960 - val_loss: 1.0675 - val_acc: 0.5820\n",
            "\n",
            "Epoch 00692: val_loss did not improve from 1.03957\n",
            "Epoch 693/1000\n",
            " - 8s - loss: 1.0428 - acc: 0.6001 - val_loss: 1.0781 - val_acc: 0.5707\n",
            "\n",
            "Epoch 00693: val_loss did not improve from 1.03957\n",
            "Epoch 694/1000\n",
            " - 8s - loss: 1.0472 - acc: 0.5993 - val_loss: 1.0553 - val_acc: 0.5891\n",
            "\n",
            "Epoch 00694: val_loss did not improve from 1.03957\n",
            "Epoch 695/1000\n",
            " - 8s - loss: 1.0523 - acc: 0.5999 - val_loss: 1.0593 - val_acc: 0.5820\n",
            "\n",
            "Epoch 00695: val_loss did not improve from 1.03957\n",
            "Epoch 696/1000\n",
            " - 8s - loss: 1.0588 - acc: 0.5985 - val_loss: 1.0616 - val_acc: 0.5827\n",
            "\n",
            "Epoch 00696: val_loss did not improve from 1.03957\n",
            "Epoch 697/1000\n",
            " - 8s - loss: 1.0510 - acc: 0.5960 - val_loss: 1.0432 - val_acc: 0.6028\n",
            "\n",
            "Epoch 00697: val_loss did not improve from 1.03957\n",
            "Epoch 698/1000\n",
            " - 8s - loss: 1.0504 - acc: 0.5953 - val_loss: 1.0598 - val_acc: 0.5879\n",
            "\n",
            "Epoch 00698: val_loss did not improve from 1.03957\n",
            "Epoch 699/1000\n",
            " - 8s - loss: 1.0547 - acc: 0.6013 - val_loss: 1.0629 - val_acc: 0.5804\n",
            "\n",
            "Epoch 00699: val_loss did not improve from 1.03957\n",
            "Epoch 700/1000\n",
            " - 8s - loss: 1.0507 - acc: 0.5978 - val_loss: 1.0539 - val_acc: 0.5872\n",
            "\n",
            "Epoch 00700: val_loss did not improve from 1.03957\n",
            "Epoch 701/1000\n",
            " - 8s - loss: 1.0439 - acc: 0.6021 - val_loss: 1.0502 - val_acc: 0.5908\n",
            "\n",
            "Epoch 00701: val_loss did not improve from 1.03957\n",
            "Epoch 702/1000\n",
            " - 8s - loss: 1.0499 - acc: 0.6021 - val_loss: 1.0715 - val_acc: 0.5825\n",
            "\n",
            "Epoch 00702: val_loss did not improve from 1.03957\n",
            "Epoch 703/1000\n",
            " - 8s - loss: 1.0520 - acc: 0.6021 - val_loss: 1.0568 - val_acc: 0.5837\n",
            "\n",
            "Epoch 00703: val_loss did not improve from 1.03957\n",
            "Epoch 704/1000\n",
            " - 8s - loss: 1.0505 - acc: 0.5969 - val_loss: 1.0759 - val_acc: 0.5761\n",
            "\n",
            "Epoch 00704: val_loss did not improve from 1.03957\n",
            "Epoch 705/1000\n",
            " - 8s - loss: 1.0544 - acc: 0.5998 - val_loss: 1.0678 - val_acc: 0.5804\n",
            "\n",
            "Epoch 00705: val_loss did not improve from 1.03957\n",
            "Epoch 706/1000\n",
            " - 8s - loss: 1.0568 - acc: 0.6035 - val_loss: 1.0570 - val_acc: 0.5889\n",
            "\n",
            "Epoch 00706: val_loss did not improve from 1.03957\n",
            "Epoch 707/1000\n",
            " - 8s - loss: 1.0461 - acc: 0.6021 - val_loss: 1.0390 - val_acc: 0.5953\n",
            "\n",
            "Epoch 00707: val_loss improved from 1.03957 to 1.03895, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 708/1000\n",
            " - 8s - loss: 1.0423 - acc: 0.6015 - val_loss: 1.0675 - val_acc: 0.5766\n",
            "\n",
            "Epoch 00708: val_loss did not improve from 1.03895\n",
            "Epoch 709/1000\n",
            " - 8s - loss: 1.0415 - acc: 0.6057 - val_loss: 1.0474 - val_acc: 0.5846\n",
            "\n",
            "Epoch 00709: val_loss did not improve from 1.03895\n",
            "Epoch 710/1000\n",
            " - 8s - loss: 1.0530 - acc: 0.5972 - val_loss: 1.0441 - val_acc: 0.5962\n",
            "\n",
            "Epoch 00710: val_loss did not improve from 1.03895\n",
            "Epoch 711/1000\n",
            " - 8s - loss: 1.0531 - acc: 0.6035 - val_loss: 1.0649 - val_acc: 0.5693\n",
            "\n",
            "Epoch 00711: val_loss did not improve from 1.03895\n",
            "Epoch 712/1000\n",
            " - 8s - loss: 1.0520 - acc: 0.5994 - val_loss: 1.0704 - val_acc: 0.5790\n",
            "\n",
            "Epoch 00712: val_loss did not improve from 1.03895\n",
            "Epoch 713/1000\n",
            " - 8s - loss: 1.0610 - acc: 0.5957 - val_loss: 1.0436 - val_acc: 0.5962\n",
            "\n",
            "Epoch 00713: val_loss did not improve from 1.03895\n",
            "Epoch 714/1000\n",
            " - 8s - loss: 1.0565 - acc: 0.5970 - val_loss: 1.0506 - val_acc: 0.5879\n",
            "\n",
            "Epoch 00714: val_loss did not improve from 1.03895\n",
            "Epoch 715/1000\n",
            " - 8s - loss: 1.0439 - acc: 0.6025 - val_loss: 1.0428 - val_acc: 0.5967\n",
            "\n",
            "Epoch 00715: val_loss did not improve from 1.03895\n",
            "Epoch 716/1000\n",
            " - 8s - loss: 1.0496 - acc: 0.5976 - val_loss: 1.0753 - val_acc: 0.5766\n",
            "\n",
            "Epoch 00716: val_loss did not improve from 1.03895\n",
            "Epoch 717/1000\n",
            " - 8s - loss: 1.0497 - acc: 0.6020 - val_loss: 1.0788 - val_acc: 0.5764\n",
            "\n",
            "Epoch 00717: val_loss did not improve from 1.03895\n",
            "Epoch 718/1000\n",
            " - 8s - loss: 1.0500 - acc: 0.5976 - val_loss: 1.0503 - val_acc: 0.5884\n",
            "\n",
            "Epoch 00718: val_loss did not improve from 1.03895\n",
            "Epoch 719/1000\n",
            " - 8s - loss: 1.0511 - acc: 0.6001 - val_loss: 1.0637 - val_acc: 0.5832\n",
            "\n",
            "Epoch 00719: val_loss did not improve from 1.03895\n",
            "Epoch 720/1000\n",
            " - 8s - loss: 1.0404 - acc: 0.6063 - val_loss: 1.0488 - val_acc: 0.5898\n",
            "\n",
            "Epoch 00720: val_loss did not improve from 1.03895\n",
            "Epoch 721/1000\n",
            " - 8s - loss: 1.0436 - acc: 0.6048 - val_loss: 1.0508 - val_acc: 0.5953\n",
            "\n",
            "Epoch 00721: val_loss did not improve from 1.03895\n",
            "Epoch 722/1000\n",
            " - 8s - loss: 1.0461 - acc: 0.5994 - val_loss: 1.0600 - val_acc: 0.5849\n",
            "\n",
            "Epoch 00722: val_loss did not improve from 1.03895\n",
            "Epoch 723/1000\n",
            " - 8s - loss: 1.0441 - acc: 0.6042 - val_loss: 1.0539 - val_acc: 0.5858\n",
            "\n",
            "Epoch 00723: val_loss did not improve from 1.03895\n",
            "Epoch 724/1000\n",
            " - 8s - loss: 1.0502 - acc: 0.6028 - val_loss: 1.0376 - val_acc: 0.6017\n",
            "\n",
            "Epoch 00724: val_loss improved from 1.03895 to 1.03756, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 725/1000\n",
            " - 8s - loss: 1.0453 - acc: 0.6015 - val_loss: 1.0435 - val_acc: 0.5884\n",
            "\n",
            "Epoch 00725: val_loss did not improve from 1.03756\n",
            "Epoch 726/1000\n",
            " - 8s - loss: 1.0380 - acc: 0.6093 - val_loss: 1.0733 - val_acc: 0.5697\n",
            "\n",
            "Epoch 00726: val_loss did not improve from 1.03756\n",
            "Epoch 727/1000\n",
            " - 8s - loss: 1.0440 - acc: 0.6031 - val_loss: 1.0490 - val_acc: 0.5835\n",
            "\n",
            "Epoch 00727: val_loss did not improve from 1.03756\n",
            "Epoch 728/1000\n",
            " - 8s - loss: 1.0457 - acc: 0.6017 - val_loss: 1.0870 - val_acc: 0.5712\n",
            "\n",
            "Epoch 00728: val_loss did not improve from 1.03756\n",
            "Epoch 729/1000\n",
            " - 8s - loss: 1.0420 - acc: 0.6053 - val_loss: 1.0622 - val_acc: 0.5839\n",
            "\n",
            "Epoch 00729: val_loss did not improve from 1.03756\n",
            "Epoch 730/1000\n",
            " - 8s - loss: 1.0402 - acc: 0.6048 - val_loss: 1.0435 - val_acc: 0.5896\n",
            "\n",
            "Epoch 00730: val_loss did not improve from 1.03756\n",
            "Epoch 731/1000\n",
            " - 8s - loss: 1.0484 - acc: 0.6028 - val_loss: 1.0429 - val_acc: 0.5946\n",
            "\n",
            "Epoch 00731: val_loss did not improve from 1.03756\n",
            "Epoch 732/1000\n",
            " - 8s - loss: 1.0338 - acc: 0.6078 - val_loss: 1.0699 - val_acc: 0.5865\n",
            "\n",
            "Epoch 00732: val_loss did not improve from 1.03756\n",
            "Epoch 733/1000\n",
            " - 8s - loss: 1.0475 - acc: 0.5988 - val_loss: 1.0513 - val_acc: 0.5946\n",
            "\n",
            "Epoch 00733: val_loss did not improve from 1.03756\n",
            "Epoch 734/1000\n",
            " - 8s - loss: 1.0411 - acc: 0.6022 - val_loss: 1.0541 - val_acc: 0.5839\n",
            "\n",
            "Epoch 00734: val_loss did not improve from 1.03756\n",
            "Epoch 735/1000\n",
            " - 8s - loss: 1.0508 - acc: 0.6000 - val_loss: 1.0530 - val_acc: 0.5863\n",
            "\n",
            "Epoch 00735: val_loss did not improve from 1.03756\n",
            "Epoch 736/1000\n",
            " - 8s - loss: 1.0409 - acc: 0.6054 - val_loss: 1.0545 - val_acc: 0.5927\n",
            "\n",
            "Epoch 00736: val_loss did not improve from 1.03756\n",
            "Epoch 737/1000\n",
            " - 8s - loss: 1.0389 - acc: 0.6086 - val_loss: 1.0572 - val_acc: 0.5896\n",
            "\n",
            "Epoch 00737: val_loss did not improve from 1.03756\n",
            "Epoch 738/1000\n",
            " - 8s - loss: 1.0550 - acc: 0.5988 - val_loss: 1.0436 - val_acc: 0.5858\n",
            "\n",
            "Epoch 00738: val_loss did not improve from 1.03756\n",
            "Epoch 739/1000\n",
            " - 8s - loss: 1.0447 - acc: 0.6017 - val_loss: 1.0402 - val_acc: 0.6040\n",
            "\n",
            "Epoch 00739: val_loss did not improve from 1.03756\n",
            "Epoch 740/1000\n",
            " - 8s - loss: 1.0492 - acc: 0.6012 - val_loss: 1.0512 - val_acc: 0.5939\n",
            "\n",
            "Epoch 00740: val_loss did not improve from 1.03756\n",
            "Epoch 741/1000\n",
            " - 8s - loss: 1.0514 - acc: 0.6004 - val_loss: 1.0555 - val_acc: 0.5863\n",
            "\n",
            "Epoch 00741: val_loss did not improve from 1.03756\n",
            "Epoch 742/1000\n",
            " - 8s - loss: 1.0453 - acc: 0.5992 - val_loss: 1.0485 - val_acc: 0.5917\n",
            "\n",
            "Epoch 00742: val_loss did not improve from 1.03756\n",
            "Epoch 743/1000\n",
            " - 8s - loss: 1.0570 - acc: 0.5957 - val_loss: 1.0755 - val_acc: 0.5719\n",
            "\n",
            "Epoch 00743: val_loss did not improve from 1.03756\n",
            "Epoch 744/1000\n",
            " - 8s - loss: 1.0450 - acc: 0.6034 - val_loss: 1.0483 - val_acc: 0.5903\n",
            "\n",
            "Epoch 00744: val_loss did not improve from 1.03756\n",
            "Epoch 745/1000\n",
            " - 8s - loss: 1.0370 - acc: 0.6013 - val_loss: 1.0569 - val_acc: 0.5917\n",
            "\n",
            "Epoch 00745: val_loss did not improve from 1.03756\n",
            "Epoch 746/1000\n",
            " - 8s - loss: 1.0432 - acc: 0.6033 - val_loss: 1.0756 - val_acc: 0.5761\n",
            "\n",
            "Epoch 00746: val_loss did not improve from 1.03756\n",
            "Epoch 747/1000\n",
            " - 8s - loss: 1.0451 - acc: 0.6025 - val_loss: 1.0515 - val_acc: 0.5849\n",
            "\n",
            "Epoch 00747: val_loss did not improve from 1.03756\n",
            "Epoch 748/1000\n",
            " - 8s - loss: 1.0365 - acc: 0.6053 - val_loss: 1.0635 - val_acc: 0.5863\n",
            "\n",
            "Epoch 00748: val_loss did not improve from 1.03756\n",
            "Epoch 749/1000\n",
            " - 8s - loss: 1.0450 - acc: 0.6059 - val_loss: 1.0294 - val_acc: 0.6028\n",
            "\n",
            "Epoch 00749: val_loss improved from 1.03756 to 1.02945, saving model to gdrive/My Drive/EEG_Project/checkpoints/EEG_RNN.ckpt\n",
            "Epoch 750/1000\n",
            " - 8s - loss: 1.0468 - acc: 0.6043 - val_loss: 1.0608 - val_acc: 0.5813\n",
            "\n",
            "Epoch 00750: val_loss did not improve from 1.02945\n",
            "Epoch 751/1000\n",
            " - 8s - loss: 1.0388 - acc: 0.6034 - val_loss: 1.0461 - val_acc: 0.5969\n",
            "\n",
            "Epoch 00751: val_loss did not improve from 1.02945\n",
            "Epoch 752/1000\n",
            " - 8s - loss: 1.0415 - acc: 0.6079 - val_loss: 1.0487 - val_acc: 0.5957\n",
            "\n",
            "Epoch 00752: val_loss did not improve from 1.02945\n",
            "Epoch 753/1000\n",
            " - 8s - loss: 1.0398 - acc: 0.6074 - val_loss: 1.0757 - val_acc: 0.5780\n",
            "\n",
            "Epoch 00753: val_loss did not improve from 1.02945\n",
            "Epoch 754/1000\n",
            " - 8s - loss: 1.0509 - acc: 0.5983 - val_loss: 1.0618 - val_acc: 0.5816\n",
            "\n",
            "Epoch 00754: val_loss did not improve from 1.02945\n",
            "Epoch 755/1000\n",
            " - 8s - loss: 1.0480 - acc: 0.6014 - val_loss: 1.0343 - val_acc: 0.6061\n",
            "\n",
            "Epoch 00755: val_loss did not improve from 1.02945\n",
            "Epoch 756/1000\n",
            " - 8s - loss: 1.0478 - acc: 0.6017 - val_loss: 1.0472 - val_acc: 0.5924\n",
            "\n",
            "Epoch 00756: val_loss did not improve from 1.02945\n",
            "Epoch 757/1000\n",
            " - 8s - loss: 1.0336 - acc: 0.6059 - val_loss: 1.0615 - val_acc: 0.5934\n",
            "\n",
            "Epoch 00757: val_loss did not improve from 1.02945\n",
            "Epoch 758/1000\n",
            " - 8s - loss: 1.0467 - acc: 0.6036 - val_loss: 1.0540 - val_acc: 0.5863\n",
            "\n",
            "Epoch 00758: val_loss did not improve from 1.02945\n",
            "Epoch 759/1000\n",
            " - 8s - loss: 1.0388 - acc: 0.6060 - val_loss: 1.0544 - val_acc: 0.5934\n",
            "\n",
            "Epoch 00759: val_loss did not improve from 1.02945\n",
            "Epoch 760/1000\n",
            " - 8s - loss: 1.0343 - acc: 0.6064 - val_loss: 1.0562 - val_acc: 0.5879\n",
            "\n",
            "Epoch 00760: val_loss did not improve from 1.02945\n",
            "Epoch 761/1000\n",
            " - 8s - loss: 1.0570 - acc: 0.5983 - val_loss: 1.0595 - val_acc: 0.5868\n",
            "\n",
            "Epoch 00761: val_loss did not improve from 1.02945\n",
            "Epoch 762/1000\n",
            " - 8s - loss: 1.0472 - acc: 0.6024 - val_loss: 1.0441 - val_acc: 0.5946\n",
            "\n",
            "Epoch 00762: val_loss did not improve from 1.02945\n",
            "Epoch 763/1000\n",
            " - 8s - loss: 1.0387 - acc: 0.6083 - val_loss: 1.0518 - val_acc: 0.5896\n",
            "\n",
            "Epoch 00763: val_loss did not improve from 1.02945\n",
            "Epoch 764/1000\n",
            " - 8s - loss: 1.0363 - acc: 0.6119 - val_loss: 1.0504 - val_acc: 0.5872\n",
            "\n",
            "Epoch 00764: val_loss did not improve from 1.02945\n",
            "Epoch 765/1000\n",
            " - 8s - loss: 1.0490 - acc: 0.5991 - val_loss: 1.0510 - val_acc: 0.5818\n",
            "\n",
            "Epoch 00765: val_loss did not improve from 1.02945\n",
            "Epoch 766/1000\n",
            " - 8s - loss: 1.0419 - acc: 0.6050 - val_loss: 1.0732 - val_acc: 0.5726\n",
            "\n",
            "Epoch 00766: val_loss did not improve from 1.02945\n",
            "Epoch 767/1000\n",
            " - 8s - loss: 1.0372 - acc: 0.6057 - val_loss: 1.0514 - val_acc: 0.5974\n",
            "\n",
            "Epoch 00767: val_loss did not improve from 1.02945\n",
            "Epoch 768/1000\n",
            " - 8s - loss: 1.0395 - acc: 0.6084 - val_loss: 1.0715 - val_acc: 0.5773\n",
            "\n",
            "Epoch 00768: val_loss did not improve from 1.02945\n",
            "Epoch 769/1000\n",
            " - 8s - loss: 1.0547 - acc: 0.5981 - val_loss: 1.0752 - val_acc: 0.5785\n",
            "\n",
            "Epoch 00769: val_loss did not improve from 1.02945\n",
            "Epoch 770/1000\n",
            " - 8s - loss: 1.0365 - acc: 0.6056 - val_loss: 1.0767 - val_acc: 0.5716\n",
            "\n",
            "Epoch 00770: val_loss did not improve from 1.02945\n",
            "Epoch 771/1000\n",
            " - 8s - loss: 1.0388 - acc: 0.6054 - val_loss: 1.1366 - val_acc: 0.5475\n",
            "\n",
            "Epoch 00771: val_loss did not improve from 1.02945\n",
            "Epoch 772/1000\n",
            " - 8s - loss: 1.0960 - acc: 0.5754 - val_loss: 1.0668 - val_acc: 0.5823\n",
            "\n",
            "Epoch 00772: val_loss did not improve from 1.02945\n",
            "Epoch 773/1000\n",
            " - 8s - loss: 1.0473 - acc: 0.6005 - val_loss: 1.0578 - val_acc: 0.5820\n",
            "\n",
            "Epoch 00773: val_loss did not improve from 1.02945\n",
            "Epoch 774/1000\n",
            " - 8s - loss: 1.0476 - acc: 0.5989 - val_loss: 1.0483 - val_acc: 0.5887\n",
            "\n",
            "Epoch 00774: val_loss did not improve from 1.02945\n",
            "Epoch 775/1000\n",
            " - 8s - loss: 1.0362 - acc: 0.6035 - val_loss: 1.0624 - val_acc: 0.5835\n",
            "\n",
            "Epoch 00775: val_loss did not improve from 1.02945\n",
            "Epoch 776/1000\n",
            " - 8s - loss: 1.0424 - acc: 0.6053 - val_loss: 1.0614 - val_acc: 0.5830\n",
            "\n",
            "Epoch 00776: val_loss did not improve from 1.02945\n",
            "Epoch 777/1000\n",
            " - 8s - loss: 1.0410 - acc: 0.6082 - val_loss: 1.0412 - val_acc: 0.5948\n",
            "\n",
            "Epoch 00777: val_loss did not improve from 1.02945\n",
            "Epoch 778/1000\n",
            " - 8s - loss: 1.0265 - acc: 0.6124 - val_loss: 1.0548 - val_acc: 0.5879\n",
            "\n",
            "Epoch 00778: val_loss did not improve from 1.02945\n",
            "Epoch 779/1000\n",
            " - 8s - loss: 1.0315 - acc: 0.6152 - val_loss: 1.0653 - val_acc: 0.5745\n",
            "\n",
            "Epoch 00779: val_loss did not improve from 1.02945\n",
            "Epoch 780/1000\n",
            " - 8s - loss: 1.0424 - acc: 0.6099 - val_loss: 1.0415 - val_acc: 0.6009\n",
            "\n",
            "Epoch 00780: val_loss did not improve from 1.02945\n",
            "Epoch 781/1000\n",
            " - 8s - loss: 1.0420 - acc: 0.6060 - val_loss: 1.0728 - val_acc: 0.5868\n",
            "\n",
            "Epoch 00781: val_loss did not improve from 1.02945\n",
            "Epoch 782/1000\n",
            " - 8s - loss: 1.0394 - acc: 0.6105 - val_loss: 1.0672 - val_acc: 0.5842\n",
            "\n",
            "Epoch 00782: val_loss did not improve from 1.02945\n",
            "Epoch 783/1000\n",
            " - 8s - loss: 1.0356 - acc: 0.6078 - val_loss: 1.0546 - val_acc: 0.5844\n",
            "\n",
            "Epoch 00783: val_loss did not improve from 1.02945\n",
            "Epoch 784/1000\n",
            " - 8s - loss: 1.0422 - acc: 0.5990 - val_loss: 1.0494 - val_acc: 0.5939\n",
            "\n",
            "Epoch 00784: val_loss did not improve from 1.02945\n",
            "Epoch 785/1000\n",
            " - 8s - loss: 1.0340 - acc: 0.6052 - val_loss: 1.0664 - val_acc: 0.5790\n",
            "\n",
            "Epoch 00785: val_loss did not improve from 1.02945\n",
            "Epoch 786/1000\n",
            " - 8s - loss: 1.0578 - acc: 0.6007 - val_loss: 1.0504 - val_acc: 0.5965\n",
            "\n",
            "Epoch 00786: val_loss did not improve from 1.02945\n",
            "Epoch 787/1000\n",
            " - 8s - loss: 1.0431 - acc: 0.6059 - val_loss: 1.0536 - val_acc: 0.5887\n",
            "\n",
            "Epoch 00787: val_loss did not improve from 1.02945\n",
            "Epoch 788/1000\n",
            " - 8s - loss: 1.0441 - acc: 0.6077 - val_loss: 1.0523 - val_acc: 0.5908\n",
            "\n",
            "Epoch 00788: val_loss did not improve from 1.02945\n",
            "Epoch 789/1000\n",
            " - 8s - loss: 1.0432 - acc: 0.6080 - val_loss: 1.0827 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00789: val_loss did not improve from 1.02945\n",
            "Epoch 790/1000\n",
            " - 8s - loss: 1.0419 - acc: 0.6041 - val_loss: 1.0463 - val_acc: 0.5983\n",
            "\n",
            "Epoch 00790: val_loss did not improve from 1.02945\n",
            "Epoch 791/1000\n",
            " - 8s - loss: 1.0328 - acc: 0.6160 - val_loss: 1.0600 - val_acc: 0.5924\n",
            "\n",
            "Epoch 00791: val_loss did not improve from 1.02945\n",
            "Epoch 792/1000\n",
            " - 8s - loss: 1.0363 - acc: 0.6099 - val_loss: 1.0465 - val_acc: 0.5953\n",
            "\n",
            "Epoch 00792: val_loss did not improve from 1.02945\n",
            "Epoch 793/1000\n",
            " - 8s - loss: 1.0477 - acc: 0.6048 - val_loss: 1.0449 - val_acc: 0.5953\n",
            "\n",
            "Epoch 00793: val_loss did not improve from 1.02945\n",
            "Epoch 794/1000\n",
            " - 8s - loss: 1.0394 - acc: 0.6070 - val_loss: 1.0607 - val_acc: 0.5849\n",
            "\n",
            "Epoch 00794: val_loss did not improve from 1.02945\n",
            "Epoch 795/1000\n",
            " - 8s - loss: 1.0361 - acc: 0.6069 - val_loss: 1.0563 - val_acc: 0.5941\n",
            "\n",
            "Epoch 00795: val_loss did not improve from 1.02945\n",
            "Epoch 796/1000\n",
            " - 8s - loss: 1.0361 - acc: 0.6044 - val_loss: 1.0790 - val_acc: 0.5797\n",
            "\n",
            "Epoch 00796: val_loss did not improve from 1.02945\n",
            "Epoch 797/1000\n",
            " - 8s - loss: 1.0432 - acc: 0.6050 - val_loss: 1.0505 - val_acc: 0.5861\n",
            "\n",
            "Epoch 00797: val_loss did not improve from 1.02945\n",
            "Epoch 798/1000\n",
            " - 8s - loss: 1.0355 - acc: 0.6098 - val_loss: 1.0635 - val_acc: 0.5953\n",
            "\n",
            "Epoch 00798: val_loss did not improve from 1.02945\n",
            "Epoch 799/1000\n",
            " - 8s - loss: 1.0298 - acc: 0.6147 - val_loss: 1.0689 - val_acc: 0.5861\n",
            "\n",
            "Epoch 00799: val_loss did not improve from 1.02945\n",
            "Epoch 800/1000\n",
            " - 8s - loss: 1.0404 - acc: 0.6067 - val_loss: 1.0542 - val_acc: 0.6007\n",
            "\n",
            "Epoch 00800: val_loss did not improve from 1.02945\n",
            "Epoch 801/1000\n",
            " - 8s - loss: 1.0493 - acc: 0.6066 - val_loss: 1.1028 - val_acc: 0.5641\n",
            "\n",
            "Epoch 00801: val_loss did not improve from 1.02945\n",
            "Epoch 802/1000\n",
            " - 8s - loss: 1.0313 - acc: 0.6134 - val_loss: 1.0686 - val_acc: 0.5799\n",
            "\n",
            "Epoch 00802: val_loss did not improve from 1.02945\n",
            "Epoch 803/1000\n",
            " - 8s - loss: 1.0362 - acc: 0.6058 - val_loss: 1.0590 - val_acc: 0.5842\n",
            "\n",
            "Epoch 00803: val_loss did not improve from 1.02945\n",
            "Epoch 804/1000\n",
            " - 8s - loss: 1.0349 - acc: 0.6108 - val_loss: 1.0738 - val_acc: 0.5806\n",
            "\n",
            "Epoch 00804: val_loss did not improve from 1.02945\n",
            "Epoch 805/1000\n",
            " - 8s - loss: 1.0270 - acc: 0.6099 - val_loss: 1.0601 - val_acc: 0.5865\n",
            "\n",
            "Epoch 00805: val_loss did not improve from 1.02945\n",
            "Epoch 806/1000\n",
            " - 8s - loss: 1.0292 - acc: 0.6110 - val_loss: 1.0583 - val_acc: 0.5844\n",
            "\n",
            "Epoch 00806: val_loss did not improve from 1.02945\n",
            "Epoch 807/1000\n",
            " - 8s - loss: 1.0310 - acc: 0.6072 - val_loss: 1.0618 - val_acc: 0.5856\n",
            "\n",
            "Epoch 00807: val_loss did not improve from 1.02945\n",
            "Epoch 808/1000\n",
            " - 8s - loss: 1.0327 - acc: 0.6088 - val_loss: 1.0475 - val_acc: 0.5993\n",
            "\n",
            "Epoch 00808: val_loss did not improve from 1.02945\n",
            "Epoch 809/1000\n",
            " - 8s - loss: 1.0356 - acc: 0.6112 - val_loss: 1.0544 - val_acc: 0.5950\n",
            "\n",
            "Epoch 00809: val_loss did not improve from 1.02945\n",
            "Epoch 810/1000\n",
            " - 8s - loss: 1.0178 - acc: 0.6232 - val_loss: 1.0484 - val_acc: 0.5965\n",
            "\n",
            "Epoch 00810: val_loss did not improve from 1.02945\n",
            "Epoch 811/1000\n",
            " - 8s - loss: 1.0299 - acc: 0.6108 - val_loss: 1.0448 - val_acc: 0.5991\n",
            "\n",
            "Epoch 00811: val_loss did not improve from 1.02945\n",
            "Epoch 812/1000\n",
            " - 8s - loss: 1.0320 - acc: 0.6150 - val_loss: 1.0502 - val_acc: 0.5946\n",
            "\n",
            "Epoch 00812: val_loss did not improve from 1.02945\n",
            "Epoch 813/1000\n",
            " - 8s - loss: 1.0334 - acc: 0.6106 - val_loss: 1.0555 - val_acc: 0.5856\n",
            "\n",
            "Epoch 00813: val_loss did not improve from 1.02945\n",
            "Epoch 814/1000\n",
            " - 8s - loss: 1.0358 - acc: 0.6112 - val_loss: 1.0477 - val_acc: 0.6026\n",
            "\n",
            "Epoch 00814: val_loss did not improve from 1.02945\n",
            "Epoch 815/1000\n",
            " - 8s - loss: 1.0218 - acc: 0.6155 - val_loss: 1.0643 - val_acc: 0.5882\n",
            "\n",
            "Epoch 00815: val_loss did not improve from 1.02945\n",
            "Epoch 816/1000\n",
            " - 8s - loss: 1.0380 - acc: 0.6077 - val_loss: 1.0476 - val_acc: 0.5986\n",
            "\n",
            "Epoch 00816: val_loss did not improve from 1.02945\n",
            "Epoch 817/1000\n",
            " - 8s - loss: 1.0341 - acc: 0.6066 - val_loss: 1.0527 - val_acc: 0.5960\n",
            "\n",
            "Epoch 00817: val_loss did not improve from 1.02945\n",
            "Epoch 818/1000\n",
            " - 8s - loss: 1.0224 - acc: 0.6170 - val_loss: 1.0641 - val_acc: 0.5972\n",
            "\n",
            "Epoch 00818: val_loss did not improve from 1.02945\n",
            "Epoch 819/1000\n",
            " - 8s - loss: 1.0287 - acc: 0.6131 - val_loss: 1.0799 - val_acc: 0.5844\n",
            "\n",
            "Epoch 00819: val_loss did not improve from 1.02945\n",
            "Epoch 820/1000\n",
            " - 8s - loss: 1.0439 - acc: 0.6002 - val_loss: 1.0568 - val_acc: 0.5816\n",
            "\n",
            "Epoch 00820: val_loss did not improve from 1.02945\n",
            "Epoch 821/1000\n",
            " - 8s - loss: 1.0386 - acc: 0.6096 - val_loss: 1.0339 - val_acc: 0.6024\n",
            "\n",
            "Epoch 00821: val_loss did not improve from 1.02945\n",
            "Epoch 822/1000\n",
            " - 8s - loss: 1.0297 - acc: 0.6100 - val_loss: 1.0597 - val_acc: 0.5894\n",
            "\n",
            "Epoch 00822: val_loss did not improve from 1.02945\n",
            "Epoch 823/1000\n",
            " - 8s - loss: 1.0263 - acc: 0.6089 - val_loss: 1.0448 - val_acc: 0.5969\n",
            "\n",
            "Epoch 00823: val_loss did not improve from 1.02945\n",
            "Epoch 824/1000\n",
            " - 8s - loss: 1.0335 - acc: 0.6066 - val_loss: 1.0502 - val_acc: 0.5898\n",
            "\n",
            "Epoch 00824: val_loss did not improve from 1.02945\n",
            "Epoch 825/1000\n",
            " - 8s - loss: 1.0271 - acc: 0.6123 - val_loss: 1.0788 - val_acc: 0.5778\n",
            "\n",
            "Epoch 00825: val_loss did not improve from 1.02945\n",
            "Epoch 826/1000\n",
            " - 8s - loss: 1.0349 - acc: 0.6088 - val_loss: 1.0793 - val_acc: 0.5757\n",
            "\n",
            "Epoch 00826: val_loss did not improve from 1.02945\n",
            "Epoch 827/1000\n",
            " - 8s - loss: 1.0291 - acc: 0.6092 - val_loss: 1.0441 - val_acc: 0.6000\n",
            "\n",
            "Epoch 00827: val_loss did not improve from 1.02945\n",
            "Epoch 828/1000\n",
            " - 8s - loss: 1.0398 - acc: 0.6060 - val_loss: 1.0607 - val_acc: 0.5842\n",
            "\n",
            "Epoch 00828: val_loss did not improve from 1.02945\n",
            "Epoch 829/1000\n",
            " - 8s - loss: 1.0246 - acc: 0.6119 - val_loss: 1.0577 - val_acc: 0.5851\n",
            "\n",
            "Epoch 00829: val_loss did not improve from 1.02945\n",
            "Epoch 830/1000\n",
            " - 8s - loss: 1.0342 - acc: 0.6092 - val_loss: 1.0573 - val_acc: 0.5853\n",
            "\n",
            "Epoch 00830: val_loss did not improve from 1.02945\n",
            "Epoch 831/1000\n",
            " - 8s - loss: 1.0292 - acc: 0.6082 - val_loss: 1.0609 - val_acc: 0.5837\n",
            "\n",
            "Epoch 00831: val_loss did not improve from 1.02945\n",
            "Epoch 832/1000\n",
            " - 8s - loss: 1.0245 - acc: 0.6106 - val_loss: 1.0517 - val_acc: 0.6009\n",
            "\n",
            "Epoch 00832: val_loss did not improve from 1.02945\n",
            "Epoch 833/1000\n",
            " - 8s - loss: 1.0390 - acc: 0.6043 - val_loss: 1.0575 - val_acc: 0.5960\n",
            "\n",
            "Epoch 00833: val_loss did not improve from 1.02945\n",
            "Epoch 834/1000\n",
            " - 8s - loss: 1.0392 - acc: 0.6064 - val_loss: 1.0578 - val_acc: 0.5865\n",
            "\n",
            "Epoch 00834: val_loss did not improve from 1.02945\n",
            "Epoch 835/1000\n",
            " - 8s - loss: 1.0234 - acc: 0.6161 - val_loss: 1.0649 - val_acc: 0.5853\n",
            "\n",
            "Epoch 00835: val_loss did not improve from 1.02945\n",
            "Epoch 836/1000\n",
            " - 8s - loss: 1.0369 - acc: 0.6062 - val_loss: 1.0656 - val_acc: 0.5799\n",
            "\n",
            "Epoch 00836: val_loss did not improve from 1.02945\n",
            "Epoch 837/1000\n",
            " - 8s - loss: 1.0360 - acc: 0.6084 - val_loss: 1.0641 - val_acc: 0.5875\n",
            "\n",
            "Epoch 00837: val_loss did not improve from 1.02945\n",
            "Epoch 838/1000\n",
            " - 8s - loss: 1.0197 - acc: 0.6170 - val_loss: 1.0540 - val_acc: 0.5946\n",
            "\n",
            "Epoch 00838: val_loss did not improve from 1.02945\n",
            "Epoch 839/1000\n",
            " - 8s - loss: 1.0335 - acc: 0.6149 - val_loss: 1.0703 - val_acc: 0.5792\n",
            "\n",
            "Epoch 00839: val_loss did not improve from 1.02945\n",
            "Epoch 840/1000\n",
            " - 8s - loss: 1.0235 - acc: 0.6187 - val_loss: 1.0576 - val_acc: 0.5922\n",
            "\n",
            "Epoch 00840: val_loss did not improve from 1.02945\n",
            "Epoch 841/1000\n",
            " - 8s - loss: 1.0302 - acc: 0.6109 - val_loss: 1.0410 - val_acc: 0.5962\n",
            "\n",
            "Epoch 00841: val_loss did not improve from 1.02945\n",
            "Epoch 842/1000\n",
            " - 8s - loss: 1.0239 - acc: 0.6107 - val_loss: 1.0624 - val_acc: 0.5858\n",
            "\n",
            "Epoch 00842: val_loss did not improve from 1.02945\n",
            "Epoch 843/1000\n",
            " - 8s - loss: 1.0363 - acc: 0.6094 - val_loss: 1.0621 - val_acc: 0.5910\n",
            "\n",
            "Epoch 00843: val_loss did not improve from 1.02945\n",
            "Epoch 844/1000\n",
            " - 8s - loss: 1.0341 - acc: 0.6102 - val_loss: 1.0603 - val_acc: 0.5915\n",
            "\n",
            "Epoch 00844: val_loss did not improve from 1.02945\n",
            "Epoch 845/1000\n",
            " - 8s - loss: 1.0195 - acc: 0.6165 - val_loss: 1.0696 - val_acc: 0.5908\n",
            "\n",
            "Epoch 00845: val_loss did not improve from 1.02945\n",
            "Epoch 846/1000\n",
            " - 8s - loss: 1.0294 - acc: 0.6082 - val_loss: 1.0719 - val_acc: 0.5832\n",
            "\n",
            "Epoch 00846: val_loss did not improve from 1.02945\n",
            "Epoch 847/1000\n",
            " - 8s - loss: 1.0244 - acc: 0.6162 - val_loss: 1.0795 - val_acc: 0.5759\n",
            "\n",
            "Epoch 00847: val_loss did not improve from 1.02945\n",
            "Epoch 848/1000\n",
            " - 8s - loss: 1.0247 - acc: 0.6069 - val_loss: 1.0520 - val_acc: 0.5913\n",
            "\n",
            "Epoch 00848: val_loss did not improve from 1.02945\n",
            "Epoch 849/1000\n",
            " - 8s - loss: 1.0272 - acc: 0.6141 - val_loss: 1.0698 - val_acc: 0.5768\n",
            "\n",
            "Epoch 00849: val_loss did not improve from 1.02945\n",
            "Epoch 850/1000\n",
            " - 8s - loss: 1.0230 - acc: 0.6146 - val_loss: 1.0540 - val_acc: 0.5967\n",
            "\n",
            "Epoch 00850: val_loss did not improve from 1.02945\n",
            "Epoch 851/1000\n",
            " - 8s - loss: 1.0263 - acc: 0.6129 - val_loss: 1.0392 - val_acc: 0.6040\n",
            "\n",
            "Epoch 00851: val_loss did not improve from 1.02945\n",
            "Epoch 852/1000\n",
            " - 8s - loss: 1.0263 - acc: 0.6161 - val_loss: 1.0468 - val_acc: 0.5913\n",
            "\n",
            "Epoch 00852: val_loss did not improve from 1.02945\n",
            "Epoch 853/1000\n",
            " - 8s - loss: 1.0275 - acc: 0.6135 - val_loss: 1.0382 - val_acc: 0.6064\n",
            "\n",
            "Epoch 00853: val_loss did not improve from 1.02945\n",
            "Epoch 854/1000\n",
            " - 8s - loss: 1.0200 - acc: 0.6168 - val_loss: 1.0650 - val_acc: 0.5915\n",
            "\n",
            "Epoch 00854: val_loss did not improve from 1.02945\n",
            "Epoch 855/1000\n",
            " - 8s - loss: 1.0264 - acc: 0.6139 - val_loss: 1.0415 - val_acc: 0.6014\n",
            "\n",
            "Epoch 00855: val_loss did not improve from 1.02945\n",
            "Epoch 856/1000\n",
            " - 8s - loss: 1.0278 - acc: 0.6136 - val_loss: 1.0431 - val_acc: 0.6005\n",
            "\n",
            "Epoch 00856: val_loss did not improve from 1.02945\n",
            "Epoch 857/1000\n",
            " - 8s - loss: 1.0244 - acc: 0.6138 - val_loss: 1.0524 - val_acc: 0.5939\n",
            "\n",
            "Epoch 00857: val_loss did not improve from 1.02945\n",
            "Epoch 858/1000\n",
            " - 8s - loss: 1.0302 - acc: 0.6106 - val_loss: 1.0548 - val_acc: 0.5877\n",
            "\n",
            "Epoch 00858: val_loss did not improve from 1.02945\n",
            "Epoch 859/1000\n",
            " - 8s - loss: 1.0344 - acc: 0.6064 - val_loss: 1.0434 - val_acc: 0.5998\n",
            "\n",
            "Epoch 00859: val_loss did not improve from 1.02945\n",
            "Epoch 860/1000\n",
            " - 8s - loss: 1.0453 - acc: 0.6016 - val_loss: 1.0594 - val_acc: 0.5858\n",
            "\n",
            "Epoch 00860: val_loss did not improve from 1.02945\n",
            "Epoch 861/1000\n",
            " - 8s - loss: 1.0363 - acc: 0.6066 - val_loss: 1.0621 - val_acc: 0.5813\n",
            "\n",
            "Epoch 00861: val_loss did not improve from 1.02945\n",
            "Epoch 862/1000\n",
            " - 8s - loss: 1.0370 - acc: 0.6079 - val_loss: 1.0467 - val_acc: 0.5957\n",
            "\n",
            "Epoch 00862: val_loss did not improve from 1.02945\n",
            "Epoch 863/1000\n",
            " - 8s - loss: 1.0296 - acc: 0.6121 - val_loss: 1.0392 - val_acc: 0.6024\n",
            "\n",
            "Epoch 00863: val_loss did not improve from 1.02945\n",
            "Epoch 864/1000\n",
            " - 8s - loss: 1.0222 - acc: 0.6150 - val_loss: 1.0810 - val_acc: 0.5757\n",
            "\n",
            "Epoch 00864: val_loss did not improve from 1.02945\n",
            "Epoch 865/1000\n",
            " - 8s - loss: 1.0333 - acc: 0.6061 - val_loss: 1.0515 - val_acc: 0.5969\n",
            "\n",
            "Epoch 00865: val_loss did not improve from 1.02945\n",
            "Epoch 866/1000\n",
            " - 8s - loss: 1.0262 - acc: 0.6119 - val_loss: 1.0424 - val_acc: 0.6028\n",
            "\n",
            "Epoch 00866: val_loss did not improve from 1.02945\n",
            "Epoch 867/1000\n",
            " - 8s - loss: 1.0246 - acc: 0.6131 - val_loss: 1.0640 - val_acc: 0.5835\n",
            "\n",
            "Epoch 00867: val_loss did not improve from 1.02945\n",
            "Epoch 868/1000\n",
            " - 8s - loss: 1.0206 - acc: 0.6143 - val_loss: 1.0557 - val_acc: 0.5988\n",
            "\n",
            "Epoch 00868: val_loss did not improve from 1.02945\n",
            "Epoch 869/1000\n",
            " - 8s - loss: 1.0315 - acc: 0.6126 - val_loss: 1.0486 - val_acc: 0.5877\n",
            "\n",
            "Epoch 00869: val_loss did not improve from 1.02945\n",
            "Epoch 870/1000\n",
            " - 8s - loss: 1.0196 - acc: 0.6163 - val_loss: 1.0399 - val_acc: 0.5998\n",
            "\n",
            "Epoch 00870: val_loss did not improve from 1.02945\n",
            "Epoch 871/1000\n",
            " - 8s - loss: 1.0330 - acc: 0.6072 - val_loss: 1.0413 - val_acc: 0.6043\n",
            "\n",
            "Epoch 00871: val_loss did not improve from 1.02945\n",
            "Epoch 872/1000\n",
            " - 8s - loss: 1.0236 - acc: 0.6164 - val_loss: 1.0468 - val_acc: 0.5917\n",
            "\n",
            "Epoch 00872: val_loss did not improve from 1.02945\n",
            "Epoch 873/1000\n",
            " - 8s - loss: 1.0245 - acc: 0.6126 - val_loss: 1.0400 - val_acc: 0.5993\n",
            "\n",
            "Epoch 00873: val_loss did not improve from 1.02945\n",
            "Epoch 874/1000\n",
            " - 8s - loss: 1.0206 - acc: 0.6216 - val_loss: 1.0394 - val_acc: 0.6038\n",
            "\n",
            "Epoch 00874: val_loss did not improve from 1.02945\n",
            "Epoch 875/1000\n",
            " - 8s - loss: 1.0226 - acc: 0.6135 - val_loss: 1.0461 - val_acc: 0.6009\n",
            "\n",
            "Epoch 00875: val_loss did not improve from 1.02945\n",
            "Epoch 876/1000\n",
            " - 8s - loss: 1.0385 - acc: 0.6102 - val_loss: 1.0554 - val_acc: 0.5976\n",
            "\n",
            "Epoch 00876: val_loss did not improve from 1.02945\n",
            "Epoch 877/1000\n",
            " - 8s - loss: 1.0217 - acc: 0.6160 - val_loss: 1.0398 - val_acc: 0.6012\n",
            "\n",
            "Epoch 00877: val_loss did not improve from 1.02945\n",
            "Epoch 878/1000\n",
            " - 8s - loss: 1.0313 - acc: 0.6070 - val_loss: 1.0416 - val_acc: 0.5981\n",
            "\n",
            "Epoch 00878: val_loss did not improve from 1.02945\n",
            "Epoch 879/1000\n",
            " - 8s - loss: 1.0174 - acc: 0.6166 - val_loss: 1.0642 - val_acc: 0.5901\n",
            "\n",
            "Epoch 00879: val_loss did not improve from 1.02945\n",
            "Epoch 880/1000\n",
            " - 8s - loss: 1.0181 - acc: 0.6145 - val_loss: 1.0433 - val_acc: 0.5995\n",
            "\n",
            "Epoch 00880: val_loss did not improve from 1.02945\n",
            "Epoch 881/1000\n",
            " - 8s - loss: 1.0172 - acc: 0.6210 - val_loss: 1.0761 - val_acc: 0.5825\n",
            "\n",
            "Epoch 00881: val_loss did not improve from 1.02945\n",
            "Epoch 882/1000\n",
            " - 8s - loss: 1.0209 - acc: 0.6215 - val_loss: 1.0534 - val_acc: 0.5967\n",
            "\n",
            "Epoch 00882: val_loss did not improve from 1.02945\n",
            "Epoch 883/1000\n",
            " - 8s - loss: 1.0147 - acc: 0.6174 - val_loss: 1.0407 - val_acc: 0.6033\n",
            "\n",
            "Epoch 00883: val_loss did not improve from 1.02945\n",
            "Epoch 884/1000\n",
            " - 8s - loss: 1.0328 - acc: 0.6077 - val_loss: 1.0381 - val_acc: 0.5955\n",
            "\n",
            "Epoch 00884: val_loss did not improve from 1.02945\n",
            "Epoch 885/1000\n",
            " - 8s - loss: 1.0162 - acc: 0.6184 - val_loss: 1.0564 - val_acc: 0.5915\n",
            "\n",
            "Epoch 00885: val_loss did not improve from 1.02945\n",
            "Epoch 886/1000\n",
            " - 8s - loss: 1.0153 - acc: 0.6190 - val_loss: 1.0447 - val_acc: 0.5962\n",
            "\n",
            "Epoch 00886: val_loss did not improve from 1.02945\n",
            "Epoch 887/1000\n",
            " - 8s - loss: 1.0227 - acc: 0.6151 - val_loss: 1.0570 - val_acc: 0.5936\n",
            "\n",
            "Epoch 00887: val_loss did not improve from 1.02945\n",
            "Epoch 888/1000\n",
            " - 8s - loss: 1.0210 - acc: 0.6174 - val_loss: 1.0880 - val_acc: 0.5757\n",
            "\n",
            "Epoch 00888: val_loss did not improve from 1.02945\n",
            "Epoch 889/1000\n",
            " - 8s - loss: 1.0142 - acc: 0.6216 - val_loss: 1.0437 - val_acc: 0.5979\n",
            "\n",
            "Epoch 00889: val_loss did not improve from 1.02945\n",
            "Epoch 890/1000\n",
            " - 8s - loss: 1.0347 - acc: 0.6104 - val_loss: 1.0492 - val_acc: 0.5910\n",
            "\n",
            "Epoch 00890: val_loss did not improve from 1.02945\n",
            "Epoch 891/1000\n",
            " - 8s - loss: 1.0141 - acc: 0.6196 - val_loss: 1.0601 - val_acc: 0.5882\n",
            "\n",
            "Epoch 00891: val_loss did not improve from 1.02945\n",
            "Epoch 892/1000\n",
            " - 8s - loss: 1.0066 - acc: 0.6254 - val_loss: 1.0397 - val_acc: 0.5991\n",
            "\n",
            "Epoch 00892: val_loss did not improve from 1.02945\n",
            "Epoch 893/1000\n",
            " - 8s - loss: 1.0214 - acc: 0.6170 - val_loss: 1.0523 - val_acc: 0.6043\n",
            "\n",
            "Epoch 00893: val_loss did not improve from 1.02945\n",
            "Epoch 894/1000\n",
            " - 8s - loss: 1.0216 - acc: 0.6157 - val_loss: 1.0579 - val_acc: 0.5901\n",
            "\n",
            "Epoch 00894: val_loss did not improve from 1.02945\n",
            "Epoch 895/1000\n",
            " - 8s - loss: 1.0213 - acc: 0.6138 - val_loss: 1.0363 - val_acc: 0.6073\n",
            "\n",
            "Epoch 00895: val_loss did not improve from 1.02945\n",
            "Epoch 896/1000\n",
            " - 8s - loss: 1.0213 - acc: 0.6177 - val_loss: 1.0554 - val_acc: 0.5943\n",
            "\n",
            "Epoch 00896: val_loss did not improve from 1.02945\n",
            "Epoch 897/1000\n",
            " - 8s - loss: 1.0248 - acc: 0.6163 - val_loss: 1.0455 - val_acc: 0.5976\n",
            "\n",
            "Epoch 00897: val_loss did not improve from 1.02945\n",
            "Epoch 898/1000\n",
            " - 8s - loss: 1.0151 - acc: 0.6220 - val_loss: 1.0544 - val_acc: 0.5896\n",
            "\n",
            "Epoch 00898: val_loss did not improve from 1.02945\n",
            "Epoch 899/1000\n",
            " - 8s - loss: 1.0175 - acc: 0.6167 - val_loss: 1.0317 - val_acc: 0.5991\n",
            "\n",
            "Epoch 00899: val_loss did not improve from 1.02945\n",
            "Epoch 900/1000\n",
            " - 8s - loss: 1.0241 - acc: 0.6154 - val_loss: 1.0385 - val_acc: 0.6061\n",
            "\n",
            "Epoch 00900: val_loss did not improve from 1.02945\n",
            "Epoch 901/1000\n",
            " - 8s - loss: 1.0252 - acc: 0.6168 - val_loss: 1.0530 - val_acc: 0.5955\n",
            "\n",
            "Epoch 00901: val_loss did not improve from 1.02945\n",
            "Epoch 902/1000\n",
            " - 8s - loss: 1.0191 - acc: 0.6212 - val_loss: 1.0430 - val_acc: 0.5939\n",
            "\n",
            "Epoch 00902: val_loss did not improve from 1.02945\n",
            "Epoch 903/1000\n",
            " - 8s - loss: 1.0288 - acc: 0.6118 - val_loss: 1.0383 - val_acc: 0.6069\n",
            "\n",
            "Epoch 00903: val_loss did not improve from 1.02945\n",
            "Epoch 904/1000\n",
            " - 8s - loss: 1.0156 - acc: 0.6196 - val_loss: 1.0478 - val_acc: 0.5995\n",
            "\n",
            "Epoch 00904: val_loss did not improve from 1.02945\n",
            "Epoch 905/1000\n",
            " - 8s - loss: 1.0188 - acc: 0.6158 - val_loss: 1.0486 - val_acc: 0.5953\n",
            "\n",
            "Epoch 00905: val_loss did not improve from 1.02945\n",
            "Epoch 906/1000\n",
            " - 8s - loss: 1.0108 - acc: 0.6207 - val_loss: 1.0835 - val_acc: 0.5799\n",
            "\n",
            "Epoch 00906: val_loss did not improve from 1.02945\n",
            "Epoch 907/1000\n",
            " - 8s - loss: 1.0187 - acc: 0.6154 - val_loss: 1.0577 - val_acc: 0.5939\n",
            "\n",
            "Epoch 00907: val_loss did not improve from 1.02945\n",
            "Epoch 908/1000\n",
            " - 8s - loss: 1.0214 - acc: 0.6157 - val_loss: 1.0835 - val_acc: 0.5766\n",
            "\n",
            "Epoch 00908: val_loss did not improve from 1.02945\n",
            "Epoch 909/1000\n",
            " - 8s - loss: 1.0221 - acc: 0.6182 - val_loss: 1.0344 - val_acc: 0.6014\n",
            "\n",
            "Epoch 00909: val_loss did not improve from 1.02945\n",
            "Epoch 910/1000\n",
            " - 8s - loss: 1.0238 - acc: 0.6157 - val_loss: 1.0563 - val_acc: 0.5943\n",
            "\n",
            "Epoch 00910: val_loss did not improve from 1.02945\n",
            "Epoch 911/1000\n",
            " - 8s - loss: 1.0182 - acc: 0.6207 - val_loss: 1.0593 - val_acc: 0.5993\n",
            "\n",
            "Epoch 00911: val_loss did not improve from 1.02945\n",
            "Epoch 912/1000\n",
            " - 8s - loss: 1.0150 - acc: 0.6216 - val_loss: 1.0355 - val_acc: 0.6090\n",
            "\n",
            "Epoch 00912: val_loss did not improve from 1.02945\n",
            "Epoch 913/1000\n",
            " - 8s - loss: 1.0191 - acc: 0.6132 - val_loss: 1.0520 - val_acc: 0.5936\n",
            "\n",
            "Epoch 00913: val_loss did not improve from 1.02945\n",
            "Epoch 914/1000\n",
            " - 8s - loss: 1.0125 - acc: 0.6258 - val_loss: 1.0405 - val_acc: 0.5969\n",
            "\n",
            "Epoch 00914: val_loss did not improve from 1.02945\n",
            "Epoch 915/1000\n",
            " - 9s - loss: 1.0171 - acc: 0.6213 - val_loss: 1.0612 - val_acc: 0.5887\n",
            "\n",
            "Epoch 00915: val_loss did not improve from 1.02945\n",
            "Epoch 916/1000\n",
            " - 8s - loss: 1.0129 - acc: 0.6217 - val_loss: 1.0410 - val_acc: 0.6043\n",
            "\n",
            "Epoch 00916: val_loss did not improve from 1.02945\n",
            "Epoch 917/1000\n",
            " - 8s - loss: 1.0170 - acc: 0.6164 - val_loss: 1.0493 - val_acc: 0.5870\n",
            "\n",
            "Epoch 00917: val_loss did not improve from 1.02945\n",
            "Epoch 918/1000\n",
            " - 8s - loss: 1.0156 - acc: 0.6181 - val_loss: 1.0687 - val_acc: 0.5801\n",
            "\n",
            "Epoch 00918: val_loss did not improve from 1.02945\n",
            "Epoch 919/1000\n",
            " - 8s - loss: 1.0063 - acc: 0.6204 - val_loss: 1.0461 - val_acc: 0.5986\n",
            "\n",
            "Epoch 00919: val_loss did not improve from 1.02945\n",
            "Epoch 920/1000\n",
            " - 8s - loss: 1.0261 - acc: 0.6154 - val_loss: 1.0496 - val_acc: 0.6061\n",
            "\n",
            "Epoch 00920: val_loss did not improve from 1.02945\n",
            "Epoch 921/1000\n",
            " - 8s - loss: 1.0131 - acc: 0.6177 - val_loss: 1.0458 - val_acc: 0.5927\n",
            "\n",
            "Epoch 00921: val_loss did not improve from 1.02945\n",
            "Epoch 922/1000\n",
            " - 8s - loss: 1.0255 - acc: 0.6107 - val_loss: 1.0410 - val_acc: 0.6019\n",
            "\n",
            "Epoch 00922: val_loss did not improve from 1.02945\n",
            "Epoch 923/1000\n",
            " - 8s - loss: 1.0109 - acc: 0.6228 - val_loss: 1.0604 - val_acc: 0.5844\n",
            "\n",
            "Epoch 00923: val_loss did not improve from 1.02945\n",
            "Epoch 924/1000\n",
            " - 8s - loss: 1.0152 - acc: 0.6164 - val_loss: 1.0516 - val_acc: 0.5955\n",
            "\n",
            "Epoch 00924: val_loss did not improve from 1.02945\n",
            "Epoch 925/1000\n",
            " - 8s - loss: 1.0029 - acc: 0.6237 - val_loss: 1.0558 - val_acc: 0.5879\n",
            "\n",
            "Epoch 00925: val_loss did not improve from 1.02945\n",
            "Epoch 926/1000\n",
            " - 8s - loss: 1.0127 - acc: 0.6204 - val_loss: 1.0556 - val_acc: 0.5861\n",
            "\n",
            "Epoch 00926: val_loss did not improve from 1.02945\n",
            "Epoch 927/1000\n",
            " - 8s - loss: 1.0197 - acc: 0.6174 - val_loss: 1.0468 - val_acc: 0.5946\n",
            "\n",
            "Epoch 00927: val_loss did not improve from 1.02945\n",
            "Epoch 928/1000\n",
            " - 8s - loss: 1.0071 - acc: 0.6228 - val_loss: 1.0705 - val_acc: 0.5870\n",
            "\n",
            "Epoch 00928: val_loss did not improve from 1.02945\n",
            "Epoch 929/1000\n",
            " - 8s - loss: 1.0228 - acc: 0.6174 - val_loss: 1.0454 - val_acc: 0.5896\n",
            "\n",
            "Epoch 00929: val_loss did not improve from 1.02945\n",
            "Epoch 930/1000\n",
            " - 8s - loss: 1.0176 - acc: 0.6193 - val_loss: 1.0690 - val_acc: 0.5879\n",
            "\n",
            "Epoch 00930: val_loss did not improve from 1.02945\n",
            "Epoch 931/1000\n",
            " - 8s - loss: 1.0205 - acc: 0.6193 - val_loss: 1.0480 - val_acc: 0.5913\n",
            "\n",
            "Epoch 00931: val_loss did not improve from 1.02945\n",
            "Epoch 932/1000\n",
            " - 8s - loss: 1.0244 - acc: 0.6118 - val_loss: 1.0395 - val_acc: 0.5981\n",
            "\n",
            "Epoch 00932: val_loss did not improve from 1.02945\n",
            "Epoch 933/1000\n",
            " - 8s - loss: 1.0204 - acc: 0.6160 - val_loss: 1.0698 - val_acc: 0.5849\n",
            "\n",
            "Epoch 00933: val_loss did not improve from 1.02945\n",
            "Epoch 934/1000\n",
            " - 8s - loss: 1.0085 - acc: 0.6261 - val_loss: 1.0547 - val_acc: 0.5851\n",
            "\n",
            "Epoch 00934: val_loss did not improve from 1.02945\n",
            "Epoch 935/1000\n",
            " - 8s - loss: 1.0204 - acc: 0.6154 - val_loss: 1.0407 - val_acc: 0.6050\n",
            "\n",
            "Epoch 00935: val_loss did not improve from 1.02945\n",
            "Epoch 936/1000\n",
            " - 8s - loss: 1.0178 - acc: 0.6229 - val_loss: 1.0486 - val_acc: 0.5993\n",
            "\n",
            "Epoch 00936: val_loss did not improve from 1.02945\n",
            "Epoch 937/1000\n",
            " - 8s - loss: 1.0168 - acc: 0.6202 - val_loss: 1.0628 - val_acc: 0.5896\n",
            "\n",
            "Epoch 00937: val_loss did not improve from 1.02945\n",
            "Epoch 938/1000\n",
            " - 8s - loss: 1.0121 - acc: 0.6230 - val_loss: 1.0614 - val_acc: 0.5844\n",
            "\n",
            "Epoch 00938: val_loss did not improve from 1.02945\n",
            "Epoch 939/1000\n",
            " - 8s - loss: 1.0131 - acc: 0.6226 - val_loss: 1.0663 - val_acc: 0.5875\n",
            "\n",
            "Epoch 00939: val_loss did not improve from 1.02945\n",
            "Epoch 940/1000\n",
            " - 8s - loss: 1.0275 - acc: 0.6143 - val_loss: 1.0571 - val_acc: 0.5927\n",
            "\n",
            "Epoch 00940: val_loss did not improve from 1.02945\n",
            "Epoch 941/1000\n",
            " - 8s - loss: 1.0212 - acc: 0.6204 - val_loss: 1.0606 - val_acc: 0.5908\n",
            "\n",
            "Epoch 00941: val_loss did not improve from 1.02945\n",
            "Epoch 942/1000\n",
            " - 8s - loss: 1.0125 - acc: 0.6251 - val_loss: 1.0895 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00942: val_loss did not improve from 1.02945\n",
            "Epoch 943/1000\n",
            " - 8s - loss: 1.0137 - acc: 0.6202 - val_loss: 1.0561 - val_acc: 0.5941\n",
            "\n",
            "Epoch 00943: val_loss did not improve from 1.02945\n",
            "Epoch 944/1000\n",
            " - 8s - loss: 1.0076 - acc: 0.6290 - val_loss: 1.0574 - val_acc: 0.6007\n",
            "\n",
            "Epoch 00944: val_loss did not improve from 1.02945\n",
            "Epoch 945/1000\n",
            " - 8s - loss: 1.0131 - acc: 0.6233 - val_loss: 1.0672 - val_acc: 0.5790\n",
            "\n",
            "Epoch 00945: val_loss did not improve from 1.02945\n",
            "Epoch 946/1000\n",
            " - 8s - loss: 1.0281 - acc: 0.6142 - val_loss: 1.0547 - val_acc: 0.5910\n",
            "\n",
            "Epoch 00946: val_loss did not improve from 1.02945\n",
            "Epoch 947/1000\n",
            " - 8s - loss: 1.0039 - acc: 0.6268 - val_loss: 1.0564 - val_acc: 0.5974\n",
            "\n",
            "Epoch 00947: val_loss did not improve from 1.02945\n",
            "Epoch 948/1000\n",
            " - 8s - loss: 1.0150 - acc: 0.6201 - val_loss: 1.0404 - val_acc: 0.6035\n",
            "\n",
            "Epoch 00948: val_loss did not improve from 1.02945\n",
            "Epoch 949/1000\n",
            " - 8s - loss: 1.0238 - acc: 0.6159 - val_loss: 1.0515 - val_acc: 0.5816\n",
            "\n",
            "Epoch 00949: val_loss did not improve from 1.02945\n",
            "Epoch 950/1000\n",
            " - 8s - loss: 1.0167 - acc: 0.6149 - val_loss: 1.0541 - val_acc: 0.5861\n",
            "\n",
            "Epoch 00950: val_loss did not improve from 1.02945\n",
            "Epoch 951/1000\n",
            " - 8s - loss: 1.0179 - acc: 0.6168 - val_loss: 1.0471 - val_acc: 0.6014\n",
            "\n",
            "Epoch 00951: val_loss did not improve from 1.02945\n",
            "Epoch 952/1000\n",
            " - 8s - loss: 1.0117 - acc: 0.6248 - val_loss: 1.0585 - val_acc: 0.5965\n",
            "\n",
            "Epoch 00952: val_loss did not improve from 1.02945\n",
            "Epoch 953/1000\n",
            " - 8s - loss: 1.0160 - acc: 0.6214 - val_loss: 1.0462 - val_acc: 0.5957\n",
            "\n",
            "Epoch 00953: val_loss did not improve from 1.02945\n",
            "Epoch 954/1000\n",
            " - 8s - loss: 1.0119 - acc: 0.6194 - val_loss: 1.0479 - val_acc: 0.5953\n",
            "\n",
            "Epoch 00954: val_loss did not improve from 1.02945\n",
            "Epoch 955/1000\n",
            " - 8s - loss: 1.0116 - acc: 0.6156 - val_loss: 1.0638 - val_acc: 0.5927\n",
            "\n",
            "Epoch 00955: val_loss did not improve from 1.02945\n",
            "Epoch 956/1000\n",
            " - 8s - loss: 1.0182 - acc: 0.6208 - val_loss: 1.0742 - val_acc: 0.5875\n",
            "\n",
            "Epoch 00956: val_loss did not improve from 1.02945\n",
            "Epoch 957/1000\n",
            " - 8s - loss: 1.0063 - acc: 0.6285 - val_loss: 1.0481 - val_acc: 0.5931\n",
            "\n",
            "Epoch 00957: val_loss did not improve from 1.02945\n",
            "Epoch 958/1000\n",
            " - 8s - loss: 1.0099 - acc: 0.6205 - val_loss: 1.0412 - val_acc: 0.6017\n",
            "\n",
            "Epoch 00958: val_loss did not improve from 1.02945\n",
            "Epoch 959/1000\n",
            " - 8s - loss: 1.0112 - acc: 0.6240 - val_loss: 1.0400 - val_acc: 0.6007\n",
            "\n",
            "Epoch 00959: val_loss did not improve from 1.02945\n",
            "Epoch 960/1000\n",
            " - 8s - loss: 1.0140 - acc: 0.6193 - val_loss: 1.0422 - val_acc: 0.5983\n",
            "\n",
            "Epoch 00960: val_loss did not improve from 1.02945\n",
            "Epoch 961/1000\n",
            " - 8s - loss: 1.0129 - acc: 0.6228 - val_loss: 1.1171 - val_acc: 0.5664\n",
            "\n",
            "Epoch 00961: val_loss did not improve from 1.02945\n",
            "Epoch 962/1000\n",
            " - 8s - loss: 1.0293 - acc: 0.6144 - val_loss: 1.0426 - val_acc: 0.5993\n",
            "\n",
            "Epoch 00962: val_loss did not improve from 1.02945\n",
            "Epoch 963/1000\n",
            " - 8s - loss: 1.0194 - acc: 0.6153 - val_loss: 1.0717 - val_acc: 0.5875\n",
            "\n",
            "Epoch 00963: val_loss did not improve from 1.02945\n",
            "Epoch 964/1000\n",
            " - 8s - loss: 1.0107 - acc: 0.6229 - val_loss: 1.0485 - val_acc: 0.5931\n",
            "\n",
            "Epoch 00964: val_loss did not improve from 1.02945\n",
            "Epoch 965/1000\n",
            " - 8s - loss: 1.0141 - acc: 0.6229 - val_loss: 1.0481 - val_acc: 0.6028\n",
            "\n",
            "Epoch 00965: val_loss did not improve from 1.02945\n",
            "Epoch 966/1000\n",
            " - 8s - loss: 1.0191 - acc: 0.6194 - val_loss: 1.1086 - val_acc: 0.5702\n",
            "\n",
            "Epoch 00966: val_loss did not improve from 1.02945\n",
            "Epoch 967/1000\n",
            " - 8s - loss: 1.0221 - acc: 0.6176 - val_loss: 1.0525 - val_acc: 0.5955\n",
            "\n",
            "Epoch 00967: val_loss did not improve from 1.02945\n",
            "Epoch 968/1000\n",
            " - 8s - loss: 1.0227 - acc: 0.6181 - val_loss: 1.1147 - val_acc: 0.5681\n",
            "\n",
            "Epoch 00968: val_loss did not improve from 1.02945\n",
            "Epoch 969/1000\n",
            " - 8s - loss: 1.0185 - acc: 0.6192 - val_loss: 1.0558 - val_acc: 0.5851\n",
            "\n",
            "Epoch 00969: val_loss did not improve from 1.02945\n",
            "Epoch 970/1000\n",
            " - 8s - loss: 1.0212 - acc: 0.6195 - val_loss: 1.0625 - val_acc: 0.5863\n",
            "\n",
            "Epoch 00970: val_loss did not improve from 1.02945\n",
            "Epoch 971/1000\n",
            " - 8s - loss: 1.0126 - acc: 0.6203 - val_loss: 1.0558 - val_acc: 0.5969\n",
            "\n",
            "Epoch 00971: val_loss did not improve from 1.02945\n",
            "Epoch 972/1000\n",
            " - 8s - loss: 1.0127 - acc: 0.6198 - val_loss: 1.0525 - val_acc: 0.5981\n",
            "\n",
            "Epoch 00972: val_loss did not improve from 1.02945\n",
            "Epoch 973/1000\n",
            " - 8s - loss: 1.0111 - acc: 0.6214 - val_loss: 1.0537 - val_acc: 0.5941\n",
            "\n",
            "Epoch 00973: val_loss did not improve from 1.02945\n",
            "Epoch 974/1000\n",
            " - 8s - loss: 1.0202 - acc: 0.6219 - val_loss: 1.0672 - val_acc: 0.5835\n",
            "\n",
            "Epoch 00974: val_loss did not improve from 1.02945\n",
            "Epoch 975/1000\n",
            " - 8s - loss: 1.0117 - acc: 0.6220 - val_loss: 1.0644 - val_acc: 0.5835\n",
            "\n",
            "Epoch 00975: val_loss did not improve from 1.02945\n",
            "Epoch 976/1000\n",
            " - 8s - loss: 1.0129 - acc: 0.6265 - val_loss: 1.0689 - val_acc: 0.5872\n",
            "\n",
            "Epoch 00976: val_loss did not improve from 1.02945\n",
            "Epoch 977/1000\n",
            " - 8s - loss: 1.0106 - acc: 0.6206 - val_loss: 1.0421 - val_acc: 0.5998\n",
            "\n",
            "Epoch 00977: val_loss did not improve from 1.02945\n",
            "Epoch 978/1000\n",
            " - 8s - loss: 0.9999 - acc: 0.6257 - val_loss: 1.0648 - val_acc: 0.5929\n",
            "\n",
            "Epoch 00978: val_loss did not improve from 1.02945\n",
            "Epoch 979/1000\n",
            " - 8s - loss: 1.0151 - acc: 0.6188 - val_loss: 1.0610 - val_acc: 0.5891\n",
            "\n",
            "Epoch 00979: val_loss did not improve from 1.02945\n",
            "Epoch 980/1000\n",
            " - 8s - loss: 1.0057 - acc: 0.6248 - val_loss: 1.0540 - val_acc: 0.5917\n",
            "\n",
            "Epoch 00980: val_loss did not improve from 1.02945\n",
            "Epoch 981/1000\n",
            " - 8s - loss: 1.0142 - acc: 0.6197 - val_loss: 1.0569 - val_acc: 0.5865\n",
            "\n",
            "Epoch 00981: val_loss did not improve from 1.02945\n",
            "Epoch 982/1000\n",
            " - 8s - loss: 1.0023 - acc: 0.6224 - val_loss: 1.0692 - val_acc: 0.5820\n",
            "\n",
            "Epoch 00982: val_loss did not improve from 1.02945\n",
            "Epoch 983/1000\n",
            " - 8s - loss: 1.0038 - acc: 0.6259 - val_loss: 1.0724 - val_acc: 0.5790\n",
            "\n",
            "Epoch 00983: val_loss did not improve from 1.02945\n",
            "Epoch 984/1000\n",
            " - 8s - loss: 1.0056 - acc: 0.6240 - val_loss: 1.0596 - val_acc: 0.5896\n",
            "\n",
            "Epoch 00984: val_loss did not improve from 1.02945\n",
            "Epoch 985/1000\n",
            " - 8s - loss: 1.0286 - acc: 0.6139 - val_loss: 1.0572 - val_acc: 0.5837\n",
            "\n",
            "Epoch 00985: val_loss did not improve from 1.02945\n",
            "Epoch 986/1000\n",
            " - 8s - loss: 1.0135 - acc: 0.6248 - val_loss: 1.0578 - val_acc: 0.5898\n",
            "\n",
            "Epoch 00986: val_loss did not improve from 1.02945\n",
            "Epoch 987/1000\n",
            " - 8s - loss: 1.0102 - acc: 0.6225 - val_loss: 1.0486 - val_acc: 0.5943\n",
            "\n",
            "Epoch 00987: val_loss did not improve from 1.02945\n",
            "Epoch 988/1000\n",
            " - 8s - loss: 1.0063 - acc: 0.6218 - val_loss: 1.0409 - val_acc: 0.6071\n",
            "\n",
            "Epoch 00988: val_loss did not improve from 1.02945\n",
            "Epoch 989/1000\n",
            " - 8s - loss: 1.0070 - acc: 0.6225 - val_loss: 1.0305 - val_acc: 0.6080\n",
            "\n",
            "Epoch 00989: val_loss did not improve from 1.02945\n",
            "Epoch 990/1000\n",
            " - 8s - loss: 1.0068 - acc: 0.6233 - val_loss: 1.0421 - val_acc: 0.6024\n",
            "\n",
            "Epoch 00990: val_loss did not improve from 1.02945\n",
            "Epoch 991/1000\n",
            " - 8s - loss: 1.0131 - acc: 0.6232 - val_loss: 1.0616 - val_acc: 0.5853\n",
            "\n",
            "Epoch 00991: val_loss did not improve from 1.02945\n",
            "Epoch 992/1000\n",
            " - 8s - loss: 1.0077 - acc: 0.6228 - val_loss: 1.0713 - val_acc: 0.5813\n",
            "\n",
            "Epoch 00992: val_loss did not improve from 1.02945\n",
            "Epoch 993/1000\n",
            " - 8s - loss: 1.0113 - acc: 0.6225 - val_loss: 1.0493 - val_acc: 0.5962\n",
            "\n",
            "Epoch 00993: val_loss did not improve from 1.02945\n",
            "Epoch 994/1000\n",
            " - 8s - loss: 1.0199 - acc: 0.6209 - val_loss: 1.0546 - val_acc: 0.6021\n",
            "\n",
            "Epoch 00994: val_loss did not improve from 1.02945\n",
            "Epoch 995/1000\n",
            " - 8s - loss: 1.0069 - acc: 0.6193 - val_loss: 1.0614 - val_acc: 0.5948\n",
            "\n",
            "Epoch 00995: val_loss did not improve from 1.02945\n",
            "Epoch 996/1000\n",
            " - 8s - loss: 1.0145 - acc: 0.6180 - val_loss: 1.0316 - val_acc: 0.6102\n",
            "\n",
            "Epoch 00996: val_loss did not improve from 1.02945\n",
            "Epoch 997/1000\n",
            " - 8s - loss: 1.0066 - acc: 0.6220 - val_loss: 1.0615 - val_acc: 0.5920\n",
            "\n",
            "Epoch 00997: val_loss did not improve from 1.02945\n",
            "Epoch 998/1000\n",
            " - 8s - loss: 1.0076 - acc: 0.6220 - val_loss: 1.0407 - val_acc: 0.6052\n",
            "\n",
            "Epoch 00998: val_loss did not improve from 1.02945\n",
            "Epoch 999/1000\n",
            " - 8s - loss: 1.0135 - acc: 0.6205 - val_loss: 1.0345 - val_acc: 0.6139\n",
            "\n",
            "Epoch 00999: val_loss did not improve from 1.02945\n",
            "Epoch 1000/1000\n",
            " - 8s - loss: 1.0013 - acc: 0.6239 - val_loss: 1.0654 - val_acc: 0.5884\n",
            "\n",
            "Epoch 01000: val_loss did not improve from 1.02945\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IS5KURW9be_u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vGgACLfybe_x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "90c87abc-67c7-4625-aaa5-857eb447521f"
      },
      "cell_type": "code",
      "source": [
        "# plot train and validation loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model train vs validation loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEVCAYAAADpbDJPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "2HQF6p_paPZ7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Test RNN Model"
      ]
    },
    {
      "metadata": {
        "id": "N6nBK5gMf7zi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import model_from_json\n",
        "\n",
        "# Model reconstruction from JSON file\n",
        "with open(data_dir + 'checkpoints/EEG_RNN.json', 'r') as f:\n",
        "    model = model_from_json(f.read())\n",
        "model.load_weights(data_dir + 'checkpoints/EEG_RNN.ckpt')\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uUQtvUvHbuWq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "84a3dd4d-3374-4583-d066-2f268a2fc30c"
      },
      "cell_type": "code",
      "source": [
        "testResults = model.evaluate(X_test_processed, y_test_processed)\n",
        "print(\"Test Loss: {}, Test Accuracy: {}\".format(testResults[0], testResults[1]))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4430/4430 [==============================] - 20s 4ms/step\n",
            "Test Loss: 1.1481360724494365, Test Accuracy: 0.5415349886864087\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nqPL78jmYoP0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Eo2uQFiRZDAH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}