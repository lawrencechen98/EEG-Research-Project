{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "First import the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_test = np.load(\"project/X_test.npy\")\n",
    "y_test = np.load(\"project/y_test.npy\")\n",
    "person_train_valid = np.load(\"project/person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"project/X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"project/y_train_valid.npy\")\n",
    "person_test = np.load(\"project/person_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore EOG data from last 3 of 25 electrodes\n",
    "# Transpose data so that the second dimension is timesteps\n",
    "X_test = X_test[:, :-3, :]\n",
    "X_test = X_test.transpose([0, 2, 1])\n",
    "X_train_valid = X_train_valid[:, :-3, :]\n",
    "X_train_valid = X_train_valid.transpose([0, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid data shape: (2115, 1000, 22)\n",
      "Test data shape: (443, 1000, 22)\n",
      "Training/Valid target shape: (2115,)\n",
      "Test target shape: (443,)\n",
      "Person train/valid shape: (2115, 1)\n",
      "Person test shape: (443, 1)\n"
     ]
    }
   ],
   "source": [
    "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
    "print ('Person test shape: {}'.format(person_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = X_train_valid.shape[0]\n",
    "num_timesteps = X_train_valid.shape[1]\n",
    "num_features = X_train_valid.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn labels into categories, i.e. y values of 0-3\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_train_valid)\n",
    "y_train_valid_classes = le.transform(y_train_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1593,  463,  901, ..., 1091,  880, 1750])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_idx = np.random.permutation(num_trials)\n",
    "rand_idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create randomized train and validation dataset split\n",
    "split = int(num_trials * 0.80)\n",
    "X_train = X_train_valid[rand_idx][:split]\n",
    "y_train = y_train_valid_classes[rand_idx][:split]\n",
    "person_train = person_train_valid[rand_idx][:split]\n",
    "\n",
    "X_valid = X_train_valid[rand_idx][split:]\n",
    "y_valid = y_train_valid_classes[rand_idx][split:]\n",
    "person_valid = person_train_valid[rand_idx][split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import GRU, Dense, Dropout\n",
    "from keras import optimizers\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'checkpoints/EEG_prediction.ckpt'\n",
    "import keras.callbacks\n",
    "\n",
    "# Create checkpoint callback\n",
    "cp_callback = keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
    "                                                 save_weights_only=True, \n",
    "                                                 monitor='val_loss',\n",
    "                                                 save_best_only=True, \n",
    "                                                 mode='auto',\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model architecture\n",
    "model = Sequential()\n",
    "\n",
    "model.add(GRU(256, dropout=0.3, input_shape=(num_timesteps, num_features), return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(GRU(128, dropout=0.3))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "#model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1692 samples, validate on 423 samples\n",
      "Epoch 1/200\n",
      "1692/1692 [==============================] - 174s 103ms/step - loss: 1.8630 - acc: 0.2441 - val_loss: 1.6254 - val_acc: 0.2435\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.62544, saving model to checkpoints/EEG_prediction.ckpt\n",
      "Epoch 2/200\n",
      "1692/1692 [==============================] - 175s 103ms/step - loss: 1.6733 - acc: 0.2683 - val_loss: 1.5072 - val_acc: 0.2364\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.62544 to 1.50717, saving model to checkpoints/EEG_prediction.ckpt\n",
      "Epoch 3/200\n",
      "1692/1692 [==============================] - 168s 99ms/step - loss: 1.6398 - acc: 0.2547 - val_loss: 1.5243 - val_acc: 0.2317\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.50717\n",
      "Epoch 4/200\n",
      "1692/1692 [==============================] - 196s 116ms/step - loss: 1.5664 - acc: 0.2766 - val_loss: 1.5132 - val_acc: 0.2459\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.50717\n",
      "Epoch 5/200\n",
      "1692/1692 [==============================] - 194s 115ms/step - loss: 1.5576 - acc: 0.2748 - val_loss: 1.4877 - val_acc: 0.2317\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.50717 to 1.48774, saving model to checkpoints/EEG_prediction.ckpt\n",
      "Epoch 6/200\n",
      "1692/1692 [==============================] - 201s 119ms/step - loss: 1.5469 - acc: 0.2730 - val_loss: 1.4691 - val_acc: 0.2317\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.48774 to 1.46909, saving model to checkpoints/EEG_prediction.ckpt\n",
      "Epoch 7/200\n",
      "1692/1692 [==============================] - 186s 110ms/step - loss: 1.5106 - acc: 0.2695 - val_loss: 1.4674 - val_acc: 0.2128\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.46909 to 1.46738, saving model to checkpoints/EEG_prediction.ckpt\n",
      "Epoch 8/200\n",
      "1692/1692 [==============================] - 166s 98ms/step - loss: 1.5090 - acc: 0.2813 - val_loss: 1.4697 - val_acc: 0.2340\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.46738\n",
      "Epoch 9/200\n",
      "1692/1692 [==============================] - 190s 112ms/step - loss: 1.4619 - acc: 0.2920 - val_loss: 1.4636 - val_acc: 0.2600\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.46738 to 1.46363, saving model to checkpoints/EEG_prediction.ckpt\n",
      "Epoch 10/200\n",
      "1692/1692 [==============================] - 200s 118ms/step - loss: 1.4532 - acc: 0.2908 - val_loss: 1.4492 - val_acc: 0.2364\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.46363 to 1.44916, saving model to checkpoints/EEG_prediction.ckpt\n",
      "Epoch 11/200\n",
      "1692/1692 [==============================] - 168s 99ms/step - loss: 1.4213 - acc: 0.2985 - val_loss: 1.4620 - val_acc: 0.2411\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.44916\n",
      "Epoch 12/200\n",
      "1692/1692 [==============================] - 168s 99ms/step - loss: 1.4164 - acc: 0.3050 - val_loss: 1.4695 - val_acc: 0.2435\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.44916\n",
      "Epoch 13/200\n",
      "1692/1692 [==============================] - 167s 98ms/step - loss: 1.3979 - acc: 0.3363 - val_loss: 1.4924 - val_acc: 0.2270\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.44916\n",
      "Epoch 14/200\n",
      "1692/1692 [==============================] - 164s 97ms/step - loss: 1.4053 - acc: 0.3304 - val_loss: 1.4483 - val_acc: 0.2435\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.44916 to 1.44829, saving model to checkpoints/EEG_prediction.ckpt\n",
      "Epoch 15/200\n",
      "1692/1692 [==============================] - 165s 97ms/step - loss: 1.3759 - acc: 0.3369 - val_loss: 1.4441 - val_acc: 0.2648\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.44829 to 1.44411, saving model to checkpoints/EEG_prediction.ckpt\n",
      "Epoch 16/200\n",
      "1692/1692 [==============================] - 181s 107ms/step - loss: 1.3864 - acc: 0.3251 - val_loss: 1.4520 - val_acc: 0.2861\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.44411\n",
      "Epoch 17/200\n",
      "1692/1692 [==============================] - 203s 120ms/step - loss: 1.3739 - acc: 0.3428 - val_loss: 1.4290 - val_acc: 0.2719\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.44411 to 1.42895, saving model to checkpoints/EEG_prediction.ckpt\n",
      "Epoch 18/200\n",
      "1692/1692 [==============================] - 195s 115ms/step - loss: 1.3502 - acc: 0.3540 - val_loss: 1.4260 - val_acc: 0.2766\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.42895 to 1.42605, saving model to checkpoints/EEG_prediction.ckpt\n",
      "Epoch 19/200\n",
      "1692/1692 [==============================] - 186s 110ms/step - loss: 1.3530 - acc: 0.3652 - val_loss: 1.4370 - val_acc: 0.2364\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.42605\n",
      "Epoch 20/200\n",
      "1692/1692 [==============================] - 206s 122ms/step - loss: 1.3352 - acc: 0.3670 - val_loss: 1.4364 - val_acc: 0.2908\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.42605\n",
      "Epoch 21/200\n",
      "1692/1692 [==============================] - 215s 127ms/step - loss: 1.3356 - acc: 0.3706 - val_loss: 1.4412 - val_acc: 0.2719\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.42605\n",
      "Epoch 22/200\n",
      "1692/1692 [==============================] - 188s 111ms/step - loss: 1.3167 - acc: 0.3712 - val_loss: 1.4392 - val_acc: 0.2908\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.42605\n",
      "Epoch 23/200\n",
      " 128/1692 [=>............................] - ETA: 2:50 - loss: 1.3574 - acc: 0.2891"
     ]
    }
   ],
   "source": [
    "# Fit model on training set, validate with validation data\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=200, batch_size=64, verbose=1, callbacks = [cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
