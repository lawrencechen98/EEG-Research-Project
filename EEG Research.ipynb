{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "First import the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_test = np.load(\"project/X_test.npy\")\n",
    "y_test = np.load(\"project/y_test.npy\")\n",
    "person_train_valid = np.load(\"project/person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"project/X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"project/y_train_valid.npy\")\n",
    "person_test = np.load(\"project/person_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore EOG data from last 3 of 25 electrodes\n",
    "# Transpose data so that the second dimension is timesteps\n",
    "X_test = X_test[:, :-3, :]\n",
    "X_test = X_test.transpose([0, 2, 1])\n",
    "X_train_valid = X_train_valid[:, :-3, :]\n",
    "X_train_valid = X_train_valid.transpose([0, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid data shape: (2115, 1000, 22)\n",
      "Test data shape: (443, 1000, 22)\n",
      "Training/Valid target shape: (2115,)\n",
      "Test target shape: (443,)\n",
      "Person train/valid shape: (2115, 1)\n",
      "Person test shape: (443, 1)\n"
     ]
    }
   ],
   "source": [
    "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
    "print ('Person test shape: {}'.format(person_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = X_train_valid.shape[0]\n",
    "num_timesteps = X_train_valid.shape[1]\n",
    "num_features = X_train_valid.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn labels into categories, i.e. y values of 0-3\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_train_valid)\n",
    "y_train_valid_classes = le.transform(y_train_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1593,  463,  901, ..., 1091,  880, 1750])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_idx = np.random.permutation(num_trials)\n",
    "rand_idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create randomized train and validation dataset split\n",
    "split = int(num_trials * 0.80)\n",
    "X_train = X_train_valid[rand_idx][:split]\n",
    "y_train = y_train_valid_classes[rand_idx][:split]\n",
    "person_train = person_train_valid[rand_idx][:split]\n",
    "\n",
    "X_valid = X_train_valid[rand_idx][split:]\n",
    "y_valid = y_train_valid_classes[rand_idx][split:]\n",
    "person_valid = person_train_valid[rand_idx][split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import GRU, Dense, Dropout\n",
    "from keras import optimizers\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'checkpoints/EEG_prediction.ckpt'\n",
    "import keras.callbacks\n",
    "\n",
    "# Create checkpoint callback\n",
    "cp_callback = keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
    "                                                 save_weights_only=True, \n",
    "                                                 monitor='val_loss',\n",
    "                                                 save_best_only=True, \n",
    "                                                 mode='auto',\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model architecture\n",
    "model = Sequential()\n",
    "\n",
    "model.add(GRU(40, dropout=0.2, input_shape=(num_timesteps, num_features), return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(GRU(20, dropout=0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "#model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1692 samples, validate on 423 samples\n",
      "Epoch 1/200\n",
      "1692/1692 [==============================] - 62s 37ms/step - loss: 1.8440 - acc: 0.2630 - val_loss: 1.6986 - val_acc: 0.2388\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.69855, saving model to checkpoints/EEG_prediction.ckpt\n",
      "Epoch 2/200\n",
      "1692/1692 [==============================] - 54s 32ms/step - loss: 1.7224 - acc: 0.2541 - val_loss: 1.6458 - val_acc: 0.2411\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.69855 to 1.64580, saving model to checkpoints/EEG_prediction.ckpt\n",
      "Epoch 3/200\n",
      "1692/1692 [==============================] - 54s 32ms/step - loss: 1.6031 - acc: 0.2595 - val_loss: 1.5699 - val_acc: 0.2553\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.64580 to 1.56987, saving model to checkpoints/EEG_prediction.ckpt\n",
      "Epoch 4/200\n",
      "1692/1692 [==============================] - 55s 32ms/step - loss: 1.5852 - acc: 0.2577 - val_loss: 1.5339 - val_acc: 0.2435\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.56987 to 1.53394, saving model to checkpoints/EEG_prediction.ckpt\n",
      "Epoch 5/200\n",
      "1692/1692 [==============================] - 55s 33ms/step - loss: 1.5459 - acc: 0.2695 - val_loss: 1.5130 - val_acc: 0.2530\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.53394 to 1.51295, saving model to checkpoints/EEG_prediction.ckpt\n",
      "Epoch 6/200\n",
      "1692/1692 [==============================] - 54s 32ms/step - loss: 1.4950 - acc: 0.2642 - val_loss: 1.4971 - val_acc: 0.2388\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.51295 to 1.49711, saving model to checkpoints/EEG_prediction.ckpt\n",
      "Epoch 7/200\n",
      "1692/1692 [==============================] - 54s 32ms/step - loss: 1.5242 - acc: 0.2547 - val_loss: 1.4836 - val_acc: 0.2364\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.49711 to 1.48365, saving model to checkpoints/EEG_prediction.ckpt\n",
      "Epoch 8/200\n",
      "1692/1692 [==============================] - 55s 32ms/step - loss: 1.4759 - acc: 0.2754 - val_loss: 1.4753 - val_acc: 0.2340\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.48365 to 1.47534, saving model to checkpoints/EEG_prediction.ckpt\n",
      "Epoch 9/200\n",
      "1692/1692 [==============================] - 55s 32ms/step - loss: 1.4722 - acc: 0.2796 - val_loss: 1.4677 - val_acc: 0.2340\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.47534 to 1.46773, saving model to checkpoints/EEG_prediction.ckpt\n",
      "Epoch 10/200\n",
      "1692/1692 [==============================] - 55s 33ms/step - loss: 1.4569 - acc: 0.2630 - val_loss: 1.4530 - val_acc: 0.2340\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.46773 to 1.45298, saving model to checkpoints/EEG_prediction.ckpt\n",
      "Epoch 11/200\n",
      "1692/1692 [==============================] - 54s 32ms/step - loss: 1.4456 - acc: 0.2837 - val_loss: 1.4442 - val_acc: 0.2364\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.45298 to 1.44421, saving model to checkpoints/EEG_prediction.ckpt\n",
      "Epoch 12/200\n",
      "1692/1692 [==============================] - 54s 32ms/step - loss: 1.4281 - acc: 0.2801 - val_loss: 1.4348 - val_acc: 0.2388\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.44421 to 1.43480, saving model to checkpoints/EEG_prediction.ckpt\n",
      "Epoch 13/200\n",
      "1216/1692 [====================>.........] - ETA: 14s - loss: 1.4234 - acc: 0.2928"
     ]
    }
   ],
   "source": [
    "# Fit model on training set, validate with validation data\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=200, batch_size=64, verbose=1, callbacks = [cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot train and validation loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model train vs validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
